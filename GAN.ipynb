{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gongbing/anaconda3/envs/GAN_practice/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/gongbing/anaconda3/envs/GAN_practice/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/gongbing/anaconda3/envs/GAN_practice/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/gongbing/anaconda3/envs/GAN_practice/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/gongbing/anaconda3/envs/GAN_practice/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/gongbing/anaconda3/envs/GAN_practice/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.slim import fully_connected as fc\n",
    "import matplotlib.pyplot as plt \n",
    "import glob\n",
    "from collections import OrderedDict\n",
    "%matplotlib inline\n",
    "from datetime import datetime\n",
    "import os\n",
    "from pathlib import Path\n",
    "#Ref : https://blog.paperspace.com/implementing-gans-in-tensorflow/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-6c2586edc443>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0mZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "train_files = \"/Users/gongbing/PycharmProjects/video_prediction_savp/data/era5_size_64_64_3_3t_norm/train\"\n",
    "test_files = \"/Users/gongbing/PycharmProjects/video_prediction_savp/data/era5_size_64_64_3_3t_norm/test\"\n",
    "val_files = \"/Users/gongbing/PycharmProjects/video_prediction_savp/data/era5_size_64_64_3_3t_norm/train\"\n",
    "\n",
    "num_epochs = 50\n",
    "batch_size=40\n",
    "\n",
    "def make_dataset(type=\"train\"):\n",
    "    if type==\"train\": filenames = glob.glob(\"/Users/gongbing/PycharmProjects/video_prediction_savp/data/era5_size_64_64_3_3t_norm/train/*.tfrecords\")\n",
    "    if type==\"val\":filenames = glob.glob(\"/Users/gongbing/PycharmProjects/video_prediction_savp/data/era5_size_64_64_3_3t_norm/val/*.tfrecords\")\n",
    "    if type==\"test\":filenames = glob.glob(\"/Users/gongbing/PycharmProjects/video_prediction_savp/data/era5_size_64_64_3_3t_norm/test/*.tfrecords\")\n",
    "    \n",
    "    def parser(serialized_example):\n",
    "            seqs = OrderedDict()\n",
    "            keys_to_features = {\n",
    "                # 'width': tf.FixedLenFeature([], tf.int64),\n",
    "                # 'height': tf.FixedLenFeature([], tf.int64),\n",
    "                'sequence_length': tf.FixedLenFeature([], tf.int64),\n",
    "                # 'channels': tf.FixedLenFeature([],tf.int64),\n",
    "                # 'images/encoded':  tf.FixedLenFeature([], tf.string)\n",
    "                'images/encoded': tf.VarLenFeature(tf.float32)\n",
    "            }\n",
    "            parsed_features = tf.parse_single_example(serialized_example, keys_to_features)\n",
    "            seq = tf.sparse_tensor_to_dense(parsed_features[\"images/encoded\"])\n",
    "            print(\"Seq= \",seq.shape)\n",
    "            images = tf.reshape(seq, [20,64, 64,3], name = \"reshape_new\")\n",
    "            seqs[\"images\"] = images\n",
    "            return seqs\n",
    "    dataset = tf.data.TFRecordDataset(filenames, buffer_size = 8 * 1024 * 1024)\n",
    "    dataset = dataset.repeat(num_epochs)\n",
    "    dataset = dataset.apply(tf.contrib.data.map_and_batch(\n",
    "            parser, batch_size, drop_remainder = True, num_parallel_calls = None))\n",
    "    #dataset = dataset.map(parser)\n",
    "    # num_parallel_calls = None if shuffle else 1  # for reproducibility (e.g. sampled subclips from the test set)\n",
    "    # dataset = dataset.apply(tf.contrib.data.map_and_batch(\n",
    "    #    _parser, batch_size, drop_remainder=True, num_parallel_calls=num_parallel_calls)) #  Bing: Parallel data mapping, num_parallel_calls normally depends on the hardware, however, normally should be equal to be the usalbe number of CPUs\n",
    "    dataset = dataset.prefetch(batch_size)  # Bing: Take the data to buffer inorder to save the waiting time for GPU\n",
    "    print(\"dataset\",dataset)\n",
    "    #dataset = dataset.repeat(max_step)\n",
    "    #dataset = dataset.batch(batch_size)\n",
    "    #iterator = dataset.make_one_shot_iterator() #One shot iterator will pool all the data once and memery issue\n",
    "    iterator = dataset.make_initializable_iterator()\n",
    "    return iterator\n",
    "\n",
    "\n",
    "X = tf.placeholder(tf.float32,[None,2])\n",
    "Z = tf.placeholder(tf.float32,[None,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class VariantionalAutoencoder(object):\n",
    "\n",
    "    def __init__(self, learning_rate=1e-4, batch_size=64, n_z=16):\n",
    "        # Set hyperparameters\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.n_z = n_z\n",
    "        # Build the graph\n",
    "        self.build()\n",
    "        # Initialize paramters\n",
    "        self.sess = tf.InteractiveSession()\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        # Summary op\n",
    "        self.loss_summary = tf.summary.scalar(\"losses\", self.recon_loss)\n",
    "        self.summary_op = tf.summary.merge_all()\n",
    "        self.summary_dir = \"./\"\n",
    "        self.base_dir = \"VAE\"\n",
    "        self.checkpoint_dir =  \"VAE\" + \"/checkpoint\"\n",
    "        Path(self.checkpoint_dir).mkdir(parents=True, exist_ok=True)\n",
    "        self.train_log_file = self.base_dir + \"/train_\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        self.val_log_file = self.base_dir + \"/val_\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        self.train_writer = tf.summary.FileWriter(self.train_log_file, self.sess.graph)\n",
    "        self.val_writer = tf.summary.FileWriter(self.val_log_file, self.sess.graph)\n",
    "        self.sess.run(self.train_iterator.initializer)\n",
    "        self.sess.run(self.val_iterator.initializer)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def generator(self,Z,hsize=[16, 16],reuse=False):\n",
    "        with tf.variable_scope(\"GAN/Generator\",reuse=reuse):\n",
    "            h1 = tf.layers.dense(Z,hsize[0],activation=tf.nn.leaky_relu)\n",
    "            h2 = tf.layers.dense(h1,hsize[1],activation=tf.nn.leaky_relu)\n",
    "            out = tf.layers.dense(h2,2)\n",
    "        return out\n",
    "\n",
    "    def discriminator(self,X,hsize=[16, 16],reuse=False):\n",
    "        with tf.variable_scope(\"GAN/Discriminator\",reuse=reuse):\n",
    "            h1 = tf.layers.dense(X,hsize[0],activation=tf.nn.leaky_relu)\n",
    "            h2 = tf.layers.dense(h1,hsize[1],activation=tf.nn.leaky_relu)\n",
    "            h3 = tf.layers.dense(h2,2)\n",
    "            out = tf.layers.dense(h3,1)\n",
    "        return out, h3\n",
    "       \n",
    "        \n",
    "        \n",
    "    # Build the netowrk and the loss functions\n",
    "    def build(self):\n",
    "        \n",
    "        tf.reset_default_graph()\n",
    "        self.train_iterator = make_dataset(type=\"train\")\n",
    "        self.val_iterator = make_dataset(type=\"val\")\n",
    "        self.test_iterator = make_dataset(type=\"test\")\n",
    "        self.x = tf.placeholder(tf.float32, [None,20,64,64,3])\n",
    "        self.global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "        self.increment_global_step = tf.assign_add(self.global_step,1,name = 'increment_global_step')\n",
    "        #ARCHITECTURE\n",
    "        self.mymodel()\n",
    "\n",
    "        # Loss\n",
    "        # Reconstruction loss\n",
    "        # Minimize the cross-entropy loss\n",
    "        epsilon = 1e-10\n",
    "        recon_loss = -tf.reduce_sum(\n",
    "            self.x[:,1:,:,:,:] * tf.log(epsilon+self.x_hat[:,:-1,:,:,:]) + \n",
    "            (1-self.x[:,1:,:,:,:]) * tf.log(epsilon+1-self.x_hat[:,:-1,:,:,:]), \n",
    "            axis=1\n",
    "        )\n",
    "        self.recon_loss = tf.reduce_mean(recon_loss)\n",
    "\n",
    "        # Latent loss\n",
    "        # KL divergence: measure the difference between two distributions\n",
    "        # Here we measure the divergence between \n",
    "        # the latent distribution and N(0, 1)\n",
    "        self.disc_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                                    logits=r_logits,labels=tf.ones_like(r_logits)) + \n",
    "                                    tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                                        logits=f_logits,labels=tf.zeros_like(f_logits)))\n",
    "        self.gen_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=f_logits,labels=tf.ones_like(f_logits)))\n",
    "\n",
    "        latent_loss = -0.5 * tf.reduce_sum(\n",
    "            1 + self.z_log_sigma_sq - tf.square(self.z_mu) - \n",
    "            tf.exp(self.z_log_sigma_sq), axis=1)\n",
    "        self.latent_loss = tf.reduce_mean(latent_loss)\n",
    "\n",
    "        self.total_loss = self.recon_loss + self.latent_loss\n",
    "        self.train_op = tf.train.AdamOptimizer(\n",
    "            learning_rate=self.learning_rate).minimize(self.total_loss,global_step=self.global_step)\n",
    "        \n",
    "        # Build a saver\n",
    "        self.saver = tf.train.Saver(tf.global_variables())\n",
    "        \n",
    "        self.losses = {\n",
    "            'recon_loss': self.recon_loss,\n",
    "            'latent_loss': self.latent_loss,\n",
    "            'total_loss': self.total_loss,\n",
    "        }      # H(x, x_hat) = -\\Sigma x*log(x_hat) + (1-x)*log(1-x_hat)\n",
    "\n",
    "        \n",
    "        #self.ckpt = tf.train.Checkpoint(model=self.vae_arc2())\n",
    "        #self.manager = tf.train.CheckpointManager(self.ckpt,self.checkpoint_dir,max_to_keep=3)\n",
    "        return\n",
    "\n",
    "    # Execute the forward and the backward pass\n",
    "    def run_single_step(self):\n",
    "        global_step = self.sess.run(self.global_step)\n",
    "        try:\n",
    "            train_batch = self.sess.run(self.train_iterator.get_next())\n",
    "            print(\"Train_batch shape\",train_batch[\"images\"].shape)\n",
    "            #print(\"global_step\",global_step)\n",
    "            x_hat, train_summary, _, train_losses = self.sess.run([self.x_hat,self.summary_op,self.train_op, self.recon_loss], feed_dict={self.x: train_batch[\"images\"]})\n",
    "            self.train_writer.add_summary(train_summary, global_step)\n",
    "            print(\"x_hat.shape\",x_hat.shape)\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print(\"train out of range error\")\n",
    "        \n",
    "        try:\n",
    "            val_batch = self.sess.run(self.val_iterator.get_next())\n",
    "            val_summary, _, val_losses = self.sess.run([self.summary_op,self.train_op, self.recon_loss], feed_dict={self.x: val_batch[\"images\"]})\n",
    "            self.val_writer.add_summary(val_summary, global_step)\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print(\"train out of range error\")\n",
    "        \n",
    "        return train_losses,val_losses\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
