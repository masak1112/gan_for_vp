{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Ref: https://github.com/loliverhennigh/Convolutional-LSTM-in-Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gongbing/anaconda3/envs/GAN_practice/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/gongbing/anaconda3/envs/GAN_practice/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/gongbing/anaconda3/envs/GAN_practice/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/gongbing/anaconda3/envs/GAN_practice/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/gongbing/anaconda3/envs/GAN_practice/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/gongbing/anaconda3/envs/GAN_practice/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import importlib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.slim import fully_connected as fc\n",
    "import matplotlib.pyplot as plt \n",
    "import glob\n",
    "from collections import OrderedDict\n",
    "%matplotlib inline\n",
    "from datetime import datetime\n",
    "import os\n",
    "from pathlib import Path\n",
    "import layer_def as ld\n",
    "from BasicConvLSTMCell import BasicConvLSTMCell\n",
    "importlib.reload(ld)\n",
    "\n",
    "#hyparameters\n",
    "num_epochs = 50\n",
    "batch_size=40\n",
    "input_dim=3\n",
    "num_sample = 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(type=\"train\"):\n",
    "    if type==\"train\": filenames = glob.glob(\"/Users/gongbing/PycharmProjects/video_prediction_savp/data/era5_size_64_64_3_3t_norm/train/*.tfrecords\")\n",
    "    if type==\"val\":filenames = glob.glob(\"/Users/gongbing/PycharmProjects/video_prediction_savp/data/era5_size_64_64_3_3t_norm/val/*.tfrecords\")\n",
    "    if type==\"test\":filenames = glob.glob(\"/Users/gongbing/PycharmProjects/video_prediction_savp/data/era5_size_64_64_3_3t_norm/test/*.tfrecords\")\n",
    "    def parser(serialized_example):\n",
    "            seqs = OrderedDict()\n",
    "            keys_to_features = {\n",
    "                # 'width': tf.FixedLenFeature([], tf.int64),\n",
    "                # 'height': tf.FixedLenFeature([], tf.int64),\n",
    "                'sequence_length': tf.FixedLenFeature([], tf.int64),\n",
    "                # 'channels': tf.FixedLenFeature([],tf.int64),\n",
    "                # 'images/encoded':  tf.FixedLenFeature([], tf.string)\n",
    "                'images/encoded': tf.VarLenFeature(tf.float32)\n",
    "            }\n",
    "            parsed_features = tf.parse_single_example(serialized_example, keys_to_features)\n",
    "            seq = tf.sparse_tensor_to_dense(parsed_features[\"images/encoded\"])\n",
    "            images = tf.reshape(seq, [20,64, 64,3], name = \"reshape_new\")\n",
    "            seqs[\"images\"] = images\n",
    "            return seqs\n",
    "    dataset = tf.data.TFRecordDataset(filenames, buffer_size = 8 * 1024 * 1024)\n",
    "    dataset = dataset.repeat(num_epochs)\n",
    "    dataset = dataset.apply(tf.contrib.data.map_and_batch(\n",
    "            parser, batch_size, drop_remainder = True, num_parallel_calls = None))\n",
    "    \n",
    "    dataset = dataset.prefetch(batch_size) \n",
    "    iterator = dataset.make_initializable_iterator()\n",
    "    return iterator\n",
    "\n",
    "\n",
    "class convLSTM(object):\n",
    "\n",
    "    def __init__(self, lr=1e-2, batch_size=64,nz=0,model_name=\"convLSTM1\",context_frames=10,sequence_length=20):\n",
    "        # Set hyperparameters\n",
    "        self.lr = lr\n",
    "        self.batch_size = batch_size\n",
    "        self.nz=0\n",
    "        self.model_name = model_name\n",
    "        self.context_frames = context_frames\n",
    "        self.sequence_length = sequence_length\n",
    "        self.predict_frames = sequence_length -  context_frames\n",
    "        \n",
    "        # Build the graph\n",
    "        self.build()\n",
    "        # Initialize paramters\n",
    "        self.sess = tf.InteractiveSession()\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        # Summary op\n",
    "        self.loss_summary = tf.summary.scalar(\"total_losses\", self.total_loss)\n",
    "        self.summary_op = tf.summary.merge_all()\n",
    "        self.summary_dir = \"./\"\n",
    "        self.output_dir = model_name\n",
    "        self.checkpoint_dir = self.output_dir + \"/checkpoint\"\n",
    "        Path(self.checkpoint_dir).mkdir(parents=True, exist_ok=True)\n",
    "        self.train_log_file = self.output_dir + \"/train_\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        self.val_log_file = self.output_dir + \"/val_\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        self.train_writer = tf.summary.FileWriter(self.train_log_file, self.sess.graph)\n",
    "        self.val_writer = tf.summary.FileWriter(self.val_log_file, self.sess.graph)\n",
    "        \n",
    "        \n",
    "    def myModel(self,model_name=\"convLSTM1\",*args):\n",
    "        modelsDic = {\n",
    "             \"convLSTM1\": self.convLSTM_network(*args),\n",
    "               }\n",
    "        self.model = modelsDic[model_name]\n",
    "        return self.model\n",
    "         \n",
    "    @staticmethod\n",
    "    def convLSTM_cell(inputs, hidden, nz=16):\n",
    "        print(\"Inputs shape\", inputs.shape)\n",
    "        conv1 = ld.conv_layer(inputs, 3, 2, 8, \"encode_1\",activate=\"leaky_relu\")\n",
    "        print(\"Encode_1_shape\",conv1.shape) \n",
    "        conv2 = ld.conv_layer(conv1, 3, 1, 8, \"encode_2\",activate=\"leaky_relu\")\n",
    "        print(\"Encode 2_shape,\",conv2.shape)\n",
    "        conv3 = ld.conv_layer(conv2, 3, 2, 8, \"encode_3\",activate=\"leaky_relu\") \n",
    "        print(\"Encode 3_shape, \", conv3.shape)\n",
    "        y_0 = conv3\n",
    "        # conv lstm cell\n",
    "        with tf.variable_scope('conv_lstm', initializer=tf.random_uniform_initializer(-.01, 0.1)):\n",
    "\n",
    "            cell = BasicConvLSTMCell(shape = [16, 16], filter_size = [3, 3], num_features=8)\n",
    "            if hidden is None:\n",
    "                hidden = cell.zero_state(y_0, tf.float32)\n",
    "                print (\"hidden zero layer\",hidden.shape)\n",
    "            output, hidden  = cell(y_0, hidden)\n",
    "            print(\"output for cell:\", output)\n",
    "            \n",
    "        output_shape = output.get_shape().as_list()\n",
    "        print (\"output_shape,\",output_shape)\n",
    "        \n",
    "        z3 = tf.reshape(output, [-1, output_shape[1], output_shape[2], output_shape[3]])\n",
    "     \n",
    "        conv5 = ld.transpose_conv_layer(z3, 3, 2, 8, \"decode_5\",activate=\"leaky_relu\") \n",
    "        print(\"conv5 shape\",conv5)\n",
    "       \n",
    "        conv6 = ld.transpose_conv_layer(conv5, 3, 1, 8, \"decode_6\",activate=\"leaky_relu\") \n",
    "        print(\"conv6 shape\",conv6)\n",
    "\n",
    "        x_hat = ld.transpose_conv_layer(conv6, 3, 2, 3, \"decode_7\",activate=\"sigmoid\")  # set activation to linear\n",
    "        print(\"x hat shape\",x_hat)\n",
    "        return x_hat, hidden\n",
    "    \n",
    "    \n",
    "    def convLSTM_network(self):\n",
    "        network_template = tf.make_template('network', convLSTM.convLSTM_cell) #make the template to share the variables\n",
    "        # create network\n",
    "        x_hat_context = []\n",
    "        x_hat_predict = []\n",
    "        seq_start = 1\n",
    "        hidden = None\n",
    "        for i in range(self.context_frames):\n",
    "            if i < seq_start:\n",
    "                x_1, hidden = network_template(self.x[:, i, :, :, :], hidden)\n",
    "            else:\n",
    "                x_1, hidden = network_template(x_1, hidden)\n",
    "            x_hat_context.append(x_1)\n",
    "        \n",
    "        for i in range(self.predict_frames):\n",
    "            x_1, hidden = network_template(x_1, hidden)\n",
    "            x_hat_predict.append(x_1)\n",
    "        \n",
    "        # pack them all together\n",
    "        x_hat_context = tf.stack(x_hat_context)\n",
    "        x_hat_predict = tf.stack(x_hat_predict)\n",
    "        self.x_hat_context = tf.transpose(x_hat_context, [1, 0, 2, 3, 4]) #change first dim with sec dim\n",
    "        self.x_hat_predict = tf.transpose(x_hat_predict, [1, 0, 2, 3, 4]) #change first dim with sec dim\n",
    "        return self.x_hat_context, self.x_hat_predict\n",
    "        \n",
    "        \n",
    "    # Build the netowrk and the loss functions\n",
    "    def build(self):\n",
    "        tf.reset_default_graph()\n",
    "        tf.set_random_seed(12345)\n",
    "        self.train_iterator = make_dataset(type=\"train\")\n",
    "        self.val_iterator = make_dataset(type=\"val\")\n",
    "        self.test_iterator = make_dataset(type=\"test\")\n",
    "        self.x = tf.placeholder(tf.float32, [None,20,64,64,3])\n",
    "        self.global_step = tf.train.get_or_create_global_step()\n",
    "        #ARCHITECTURE\n",
    "        self.x_hat_context_frames,self.x_hat_predict_frames = self.myModel(model_name=self.model_name)\n",
    "        self.x_hat = tf.concat([self.x_hat_context_frames,self.x_hat_predict_frames], 1)\n",
    "        print (\"x_hat,shape\",self.x_hat)\n",
    "        \n",
    "        #Loss calculation\n",
    "        self.context_frames_loss = tf.reduce_mean(tf.square(self.x[:,:self.context_frames,:,:,0]  - self.x_hat_context_frames[:,:,:,:,0]))\n",
    "        self.predict_frames_loss = tf.reduce_mean(tf.square(self.x[:,self.context_frames:,:,:,0]  - self.x_hat_predict_frames[:,:,:,:,0]))\n",
    "        self.total_loss = self.context_frames_loss + self.predict_frames_loss\n",
    "        \n",
    "        self.train_op = tf.train.AdamOptimizer(\n",
    "            lr=self.lr).minimize(self.total_loss,global_step=self.global_step)\n",
    "        \n",
    "        # Build a saver\n",
    "        self.saver = tf.train.Saver(tf.global_variables())\n",
    "        return\n",
    "\n",
    "    # Execute the forward and the backward pass\n",
    "    def run_single_step(self,global_step):\n",
    "        try:\n",
    "            train_batch = self.sess.run(self.train_iterator.get_next())\n",
    "    \n",
    "            x_hat, train_summary, _, train_losses = self.sess.run([self.x_hat, self.summary_op, self.train_op, self.total_loss], feed_dict={self.x: train_batch[\"images\"]})\n",
    "            self.train_writer.add_summary(train_summary, global_step)\n",
    "    \n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print(\"train out of range error\")\n",
    "        \n",
    "        try:\n",
    "            val_batch = self.sess.run(self.val_iterator.get_next())\n",
    "            val_summary, val_losses = self.sess.run([self.summary_op, self.total_loss], feed_dict={self.x: val_batch[\"images\"]})\n",
    "            self.val_writer.add_summary(val_summary, global_step)\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print(\"train out of range error\")\n",
    "        \n",
    "        return train_losses,val_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer_and_checkpoint(model_class, learning_rate=1e-2, \n",
    "            batch_size=64, num_epoch=100, nz=16, log_step=5):\n",
    "    #restore the existing checkpoints  \n",
    "    model = model_class(learning_rate=learning_rate, batch_size=batch_size, nz=nz)\n",
    "    ckpt = tf.train.get_checkpoint_state(model.checkpoint_dir)\n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "        #Extract from checkpoint filename\n",
    "        global_step = int(os.path.basename(ckpt.model_checkpoint_path).split('-')[1])\n",
    "        sess = tf.Session()\n",
    "        print(\"Restore from {}\".format(ckpt.model_checkpoint_path))\n",
    "        #graph = tf.get_default_graph()\n",
    "        saver = tf.train.Saver(tf.global_variables())\n",
    "        #saver = tf.train.import_meta_graph(os.path.join(model.checkpoint_dir,'model.ckpt-{}.meta'.format(global_step)))\n",
    "        saver.restore(sess,tf.train.latest_checkpoint(model.checkpoint_dir))\n",
    "        loaded_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=tf.get_variable_scope().name)\n",
    "    else:\n",
    "        print(\"Initializer from scratch\")\n",
    "        global_step = model.sess.run(model.global_step)\n",
    "        model.sess.run(model.train_iterator.initializer)\n",
    "        model.sess.run(model.val_iterator.initializer)\n",
    "    # Training loop    \n",
    "    for epoch in range(num_epoch):\n",
    "\n",
    "        start_time = time.time()\n",
    "        # Run an epoch\n",
    "        for iter in range(num_sample // batch_size):\n",
    "            print(\"iter\",iter)\n",
    "            global_step = model.sess.run(model.global_step)\n",
    "            train_losses,val_losses = model.run_single_step(global_step)\n",
    "            print (\"Train_loss: {}; Val_loss{} for global step {}\".format(train_losses,val_losses,global_step))\n",
    "            checkpoint_path = os.path.join(model.checkpoint_dir, 'model_arc4.ckpt')\n",
    "            model.saver.save(model.sess,checkpoint_path)\n",
    "            #global_step = global_step  +1\n",
    "        end_time = time.time()\n",
    "        \n",
    "    print('Done!')\n",
    "    return model    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs shape (?, 64, 64, 3)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "hidden zero layer (?, 16, 16, 16)\n",
      "output for cell: Tensor(\"network/conv_lstm/BasicConvLSTMCell/mul_2:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "output_shape, [None, 16, 16, 8]\n",
      "output_shape Tensor(\"network/decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "conv5 shape Tensor(\"network/decode_5_trans_conv/decode_5_transpose_conv:0\", shape=(?, 32, 32, 8), dtype=float32)\n",
      "output_shape Tensor(\"network/decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "conv6 shape Tensor(\"network/decode_6_trans_conv/decode_6_transpose_conv:0\", shape=(?, 32, 32, 8), dtype=float32)\n",
      "output_shape Tensor(\"network/decode_7_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "x hat shape Tensor(\"network/decode_7_trans_conv/sigmoid:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "Inputs shape (?, 64, 64, 3)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "output for cell: Tensor(\"network_1/conv_lstm/BasicConvLSTMCell/mul_2:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "output_shape, [None, 16, 16, 8]\n",
      "output_shape Tensor(\"network_1/decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "conv5 shape Tensor(\"network_1/decode_5_trans_conv/decode_5_transpose_conv:0\", shape=(?, 32, 32, 8), dtype=float32)\n",
      "output_shape Tensor(\"network_1/decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "conv6 shape Tensor(\"network_1/decode_6_trans_conv/decode_6_transpose_conv:0\", shape=(?, 32, 32, 8), dtype=float32)\n",
      "output_shape Tensor(\"network_1/decode_7_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "x hat shape Tensor(\"network_1/decode_7_trans_conv/sigmoid:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "Inputs shape (?, 64, 64, 3)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "output for cell: Tensor(\"network_2/conv_lstm/BasicConvLSTMCell/mul_2:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "output_shape, [None, 16, 16, 8]\n",
      "output_shape Tensor(\"network_2/decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "conv5 shape Tensor(\"network_2/decode_5_trans_conv/decode_5_transpose_conv:0\", shape=(?, 32, 32, 8), dtype=float32)\n",
      "output_shape Tensor(\"network_2/decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "conv6 shape Tensor(\"network_2/decode_6_trans_conv/decode_6_transpose_conv:0\", shape=(?, 32, 32, 8), dtype=float32)\n",
      "output_shape Tensor(\"network_2/decode_7_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "x hat shape Tensor(\"network_2/decode_7_trans_conv/sigmoid:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "Inputs shape (?, 64, 64, 3)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "output for cell: Tensor(\"network_3/conv_lstm/BasicConvLSTMCell/mul_2:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "output_shape, [None, 16, 16, 8]\n",
      "output_shape Tensor(\"network_3/decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "conv5 shape Tensor(\"network_3/decode_5_trans_conv/decode_5_transpose_conv:0\", shape=(?, 32, 32, 8), dtype=float32)\n",
      "output_shape Tensor(\"network_3/decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "conv6 shape Tensor(\"network_3/decode_6_trans_conv/decode_6_transpose_conv:0\", shape=(?, 32, 32, 8), dtype=float32)\n",
      "output_shape Tensor(\"network_3/decode_7_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "x hat shape Tensor(\"network_3/decode_7_trans_conv/sigmoid:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "Inputs shape (?, 64, 64, 3)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "output for cell: Tensor(\"network_4/conv_lstm/BasicConvLSTMCell/mul_2:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "output_shape, [None, 16, 16, 8]\n",
      "output_shape Tensor(\"network_4/decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "conv5 shape Tensor(\"network_4/decode_5_trans_conv/decode_5_transpose_conv:0\", shape=(?, 32, 32, 8), dtype=float32)\n",
      "output_shape Tensor(\"network_4/decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "conv6 shape Tensor(\"network_4/decode_6_trans_conv/decode_6_transpose_conv:0\", shape=(?, 32, 32, 8), dtype=float32)\n",
      "output_shape Tensor(\"network_4/decode_7_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "x hat shape Tensor(\"network_4/decode_7_trans_conv/sigmoid:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "Inputs shape (?, 64, 64, 3)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "output for cell: Tensor(\"network_5/conv_lstm/BasicConvLSTMCell/mul_2:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "output_shape, [None, 16, 16, 8]\n",
      "output_shape Tensor(\"network_5/decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "conv5 shape Tensor(\"network_5/decode_5_trans_conv/decode_5_transpose_conv:0\", shape=(?, 32, 32, 8), dtype=float32)\n",
      "output_shape Tensor(\"network_5/decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "conv6 shape Tensor(\"network_5/decode_6_trans_conv/decode_6_transpose_conv:0\", shape=(?, 32, 32, 8), dtype=float32)\n",
      "output_shape Tensor(\"network_5/decode_7_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "x hat shape Tensor(\"network_5/decode_7_trans_conv/sigmoid:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "Inputs shape (?, 64, 64, 3)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "output for cell: Tensor(\"network_6/conv_lstm/BasicConvLSTMCell/mul_2:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "output_shape, [None, 16, 16, 8]\n",
      "output_shape Tensor(\"network_6/decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "conv5 shape Tensor(\"network_6/decode_5_trans_conv/decode_5_transpose_conv:0\", shape=(?, 32, 32, 8), dtype=float32)\n",
      "output_shape Tensor(\"network_6/decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "conv6 shape Tensor(\"network_6/decode_6_trans_conv/decode_6_transpose_conv:0\", shape=(?, 32, 32, 8), dtype=float32)\n",
      "output_shape Tensor(\"network_6/decode_7_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "x hat shape Tensor(\"network_6/decode_7_trans_conv/sigmoid:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "Inputs shape (?, 64, 64, 3)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "output for cell: Tensor(\"network_7/conv_lstm/BasicConvLSTMCell/mul_2:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "output_shape, [None, 16, 16, 8]\n",
      "output_shape Tensor(\"network_7/decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "conv5 shape Tensor(\"network_7/decode_5_trans_conv/decode_5_transpose_conv:0\", shape=(?, 32, 32, 8), dtype=float32)\n",
      "output_shape Tensor(\"network_7/decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "conv6 shape Tensor(\"network_7/decode_6_trans_conv/decode_6_transpose_conv:0\", shape=(?, 32, 32, 8), dtype=float32)\n",
      "output_shape Tensor(\"network_7/decode_7_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "x hat shape Tensor(\"network_7/decode_7_trans_conv/sigmoid:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "Inputs shape (?, 64, 64, 3)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "output for cell: Tensor(\"network_8/conv_lstm/BasicConvLSTMCell/mul_2:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "output_shape, [None, 16, 16, 8]\n",
      "output_shape Tensor(\"network_8/decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv5 shape Tensor(\"network_8/decode_5_trans_conv/decode_5_transpose_conv:0\", shape=(?, 32, 32, 8), dtype=float32)\n",
      "output_shape Tensor(\"network_8/decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "conv6 shape Tensor(\"network_8/decode_6_trans_conv/decode_6_transpose_conv:0\", shape=(?, 32, 32, 8), dtype=float32)\n",
      "output_shape Tensor(\"network_8/decode_7_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "x hat shape Tensor(\"network_8/decode_7_trans_conv/sigmoid:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "Inputs shape (?, 64, 64, 3)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "output for cell: Tensor(\"network_9/conv_lstm/BasicConvLSTMCell/mul_2:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "output_shape, [None, 16, 16, 8]\n",
      "output_shape Tensor(\"network_9/decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "conv5 shape Tensor(\"network_9/decode_5_trans_conv/decode_5_transpose_conv:0\", shape=(?, 32, 32, 8), dtype=float32)\n",
      "output_shape Tensor(\"network_9/decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "conv6 shape Tensor(\"network_9/decode_6_trans_conv/decode_6_transpose_conv:0\", shape=(?, 32, 32, 8), dtype=float32)\n",
      "output_shape Tensor(\"network_9/decode_7_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "x hat shape Tensor(\"network_9/decode_7_trans_conv/sigmoid:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "Inputs shape (?, 64, 64, 3)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "output for cell: Tensor(\"network_10/conv_lstm/BasicConvLSTMCell/mul_2:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "output_shape, [None, 16, 16, 8]\n",
      "output_shape Tensor(\"network_10/decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "conv5 shape Tensor(\"network_10/decode_5_trans_conv/decode_5_transpose_conv:0\", shape=(?, 32, 32, 8), dtype=float32)\n",
      "output_shape Tensor(\"network_10/decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "conv6 shape Tensor(\"network_10/decode_6_trans_conv/decode_6_transpose_conv:0\", shape=(?, 32, 32, 8), dtype=float32)\n",
      "output_shape Tensor(\"network_10/decode_7_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "x hat shape Tensor(\"network_10/decode_7_trans_conv/sigmoid:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "Inputs shape (?, 64, 64, 3)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "output for cell: Tensor(\"network_11/conv_lstm/BasicConvLSTMCell/mul_2:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "output_shape, [None, 16, 16, 8]\n",
      "output_shape Tensor(\"network_11/decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "conv5 shape Tensor(\"network_11/decode_5_trans_conv/decode_5_transpose_conv:0\", shape=(?, 32, 32, 8), dtype=float32)\n",
      "output_shape Tensor(\"network_11/decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "conv6 shape Tensor(\"network_11/decode_6_trans_conv/decode_6_transpose_conv:0\", shape=(?, 32, 32, 8), dtype=float32)\n",
      "output_shape Tensor(\"network_11/decode_7_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "x hat shape Tensor(\"network_11/decode_7_trans_conv/sigmoid:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "Inputs shape (?, 64, 64, 3)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "output for cell: Tensor(\"network_12/conv_lstm/BasicConvLSTMCell/mul_2:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "output_shape, [None, 16, 16, 8]\n",
      "output_shape Tensor(\"network_12/decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "conv5 shape Tensor(\"network_12/decode_5_trans_conv/decode_5_transpose_conv:0\", shape=(?, 32, 32, 8), dtype=float32)\n",
      "output_shape Tensor(\"network_12/decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "conv6 shape Tensor(\"network_12/decode_6_trans_conv/decode_6_transpose_conv:0\", shape=(?, 32, 32, 8), dtype=float32)\n",
      "output_shape Tensor(\"network_12/decode_7_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "x hat shape Tensor(\"network_12/decode_7_trans_conv/sigmoid:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "Inputs shape (?, 64, 64, 3)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "output for cell: Tensor(\"network_13/conv_lstm/BasicConvLSTMCell/mul_2:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "output_shape, [None, 16, 16, 8]\n",
      "output_shape Tensor(\"network_13/decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "conv5 shape Tensor(\"network_13/decode_5_trans_conv/decode_5_transpose_conv:0\", shape=(?, 32, 32, 8), dtype=float32)\n",
      "output_shape Tensor(\"network_13/decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "conv6 shape Tensor(\"network_13/decode_6_trans_conv/decode_6_transpose_conv:0\", shape=(?, 32, 32, 8), dtype=float32)\n",
      "output_shape Tensor(\"network_13/decode_7_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "x hat shape Tensor(\"network_13/decode_7_trans_conv/sigmoid:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "Inputs shape (?, 64, 64, 3)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "output for cell: Tensor(\"network_14/conv_lstm/BasicConvLSTMCell/mul_2:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "output_shape, [None, 16, 16, 8]\n",
      "output_shape Tensor(\"network_14/decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "conv5 shape Tensor(\"network_14/decode_5_trans_conv/decode_5_transpose_conv:0\", shape=(?, 32, 32, 8), dtype=float32)\n",
      "output_shape Tensor(\"network_14/decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "conv6 shape Tensor(\"network_14/decode_6_trans_conv/decode_6_transpose_conv:0\", shape=(?, 32, 32, 8), dtype=float32)\n",
      "output_shape Tensor(\"network_14/decode_7_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "x hat shape Tensor(\"network_14/decode_7_trans_conv/sigmoid:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "Inputs shape (?, 64, 64, 3)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "output for cell: Tensor(\"network_15/conv_lstm/BasicConvLSTMCell/mul_2:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "output_shape, [None, 16, 16, 8]\n",
      "output_shape Tensor(\"network_15/decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "conv5 shape Tensor(\"network_15/decode_5_trans_conv/decode_5_transpose_conv:0\", shape=(?, 32, 32, 8), dtype=float32)\n",
      "output_shape Tensor(\"network_15/decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "conv6 shape Tensor(\"network_15/decode_6_trans_conv/decode_6_transpose_conv:0\", shape=(?, 32, 32, 8), dtype=float32)\n",
      "output_shape Tensor(\"network_15/decode_7_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "x hat shape Tensor(\"network_15/decode_7_trans_conv/sigmoid:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "Inputs shape (?, 64, 64, 3)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "output for cell: Tensor(\"network_16/conv_lstm/BasicConvLSTMCell/mul_2:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "output_shape, [None, 16, 16, 8]\n",
      "output_shape Tensor(\"network_16/decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "conv5 shape Tensor(\"network_16/decode_5_trans_conv/decode_5_transpose_conv:0\", shape=(?, 32, 32, 8), dtype=float32)\n",
      "output_shape Tensor(\"network_16/decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "conv6 shape Tensor(\"network_16/decode_6_trans_conv/decode_6_transpose_conv:0\", shape=(?, 32, 32, 8), dtype=float32)\n",
      "output_shape Tensor(\"network_16/decode_7_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "x hat shape Tensor(\"network_16/decode_7_trans_conv/sigmoid:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "Inputs shape (?, 64, 64, 3)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "output for cell: Tensor(\"network_17/conv_lstm/BasicConvLSTMCell/mul_2:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "output_shape, [None, 16, 16, 8]\n",
      "output_shape Tensor(\"network_17/decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "conv5 shape Tensor(\"network_17/decode_5_trans_conv/decode_5_transpose_conv:0\", shape=(?, 32, 32, 8), dtype=float32)\n",
      "output_shape Tensor(\"network_17/decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "conv6 shape Tensor(\"network_17/decode_6_trans_conv/decode_6_transpose_conv:0\", shape=(?, 32, 32, 8), dtype=float32)\n",
      "output_shape Tensor(\"network_17/decode_7_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "x hat shape Tensor(\"network_17/decode_7_trans_conv/sigmoid:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "Inputs shape (?, 64, 64, 3)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "output for cell: Tensor(\"network_18/conv_lstm/BasicConvLSTMCell/mul_2:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "output_shape, [None, 16, 16, 8]\n",
      "output_shape Tensor(\"network_18/decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "conv5 shape Tensor(\"network_18/decode_5_trans_conv/decode_5_transpose_conv:0\", shape=(?, 32, 32, 8), dtype=float32)\n",
      "output_shape Tensor(\"network_18/decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "conv6 shape Tensor(\"network_18/decode_6_trans_conv/decode_6_transpose_conv:0\", shape=(?, 32, 32, 8), dtype=float32)\n",
      "output_shape Tensor(\"network_18/decode_7_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "x hat shape Tensor(\"network_18/decode_7_trans_conv/sigmoid:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "Inputs shape (?, 64, 64, 3)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "output for cell: Tensor(\"network_19/conv_lstm/BasicConvLSTMCell/mul_2:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "output_shape, [None, 16, 16, 8]\n",
      "output_shape Tensor(\"network_19/decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "conv5 shape Tensor(\"network_19/decode_5_trans_conv/decode_5_transpose_conv:0\", shape=(?, 32, 32, 8), dtype=float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_shape Tensor(\"network_19/decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "conv6 shape Tensor(\"network_19/decode_6_trans_conv/decode_6_transpose_conv:0\", shape=(?, 32, 32, 8), dtype=float32)\n",
      "output_shape Tensor(\"network_19/decode_7_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "x hat shape Tensor(\"network_19/decode_7_trans_conv/sigmoid:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "x_hat,shape Tensor(\"concat:0\", shape=(?, 20, 64, 64, 3), dtype=float32)\n",
      "Initializer from scratch\n",
      "iter 0\n",
      "Train_loss: 0.21427994966506958; Val_loss0.14263123273849487 for global step 0\n",
      "iter 1\n",
      "Train_loss: 0.1788034737110138; Val_loss0.1106971725821495 for global step 1\n",
      "iter 2\n",
      "Train_loss: 0.12229645252227783; Val_loss0.08845406770706177 for global step 2\n",
      "iter 3\n",
      "Train_loss: 0.07126347720623016; Val_loss0.0749092847108841 for global step 3\n",
      "iter 4\n",
      "Train_loss: 0.07270807027816772; Val_loss0.0580945685505867 for global step 4\n",
      "iter 5\n",
      "Train_loss: 0.05784735083580017; Val_loss0.04535266384482384 for global step 5\n",
      "iter 6\n",
      "Train_loss: 0.041674017906188965; Val_loss0.054474785923957825 for global step 6\n",
      "iter 7\n",
      "Train_loss: 0.02527039498090744; Val_loss0.07856738567352295 for global step 7\n",
      "iter 8\n",
      "Train_loss: 0.017479993402957916; Val_loss0.10648520290851593 for global step 8\n",
      "iter 9\n",
      "Train_loss: 0.03785960003733635; Val_loss0.10316131263971329 for global step 9\n",
      "iter 10\n",
      "Train_loss: 0.08497726917266846; Val_loss0.08334150910377502 for global step 10\n",
      "iter 11\n",
      "Train_loss: 0.0914967954158783; Val_loss0.08611373603343964 for global step 11\n",
      "iter 12\n",
      "Train_loss: 0.07475851476192474; Val_loss0.05559171736240387 for global step 12\n",
      "iter 13\n",
      "Train_loss: 0.013876628130674362; Val_loss0.01858953945338726 for global step 13\n",
      "iter 14\n",
      "Train_loss: 0.013718714937567711; Val_loss0.016991183161735535 for global step 14\n",
      "iter 15\n",
      "Train_loss: 0.015339034609496593; Val_loss0.0150558827444911 for global step 15\n",
      "iter 16\n",
      "Train_loss: 0.018863026052713394; Val_loss0.026821978390216827 for global step 16\n",
      "iter 17\n",
      "Train_loss: 0.014589582569897175; Val_loss0.02560480497777462 for global step 17\n",
      "iter 18\n",
      "Train_loss: 0.013441236689686775; Val_loss0.022931713610887527 for global step 18\n",
      "iter 19\n",
      "Train_loss: 0.04453521966934204; Val_loss0.017599891871213913 for global step 19\n",
      "iter 20\n",
      "Train_loss: 0.04059714823961258; Val_loss0.019274277612566948 for global step 20\n",
      "iter 21\n",
      "Train_loss: 0.027985773980617523; Val_loss0.02708372101187706 for global step 21\n",
      "iter 22\n",
      "Train_loss: 0.012385666370391846; Val_loss0.06985935568809509 for global step 22\n",
      "iter 0\n",
      "Train_loss: 0.05872582644224167; Val_loss0.059021539986133575 for global step 23\n",
      "iter 1\n",
      "Train_loss: 0.08252575993537903; Val_loss0.07055958360433578 for global step 24\n",
      "iter 2\n",
      "Train_loss: 0.0816241055727005; Val_loss0.06156853958964348 for global step 25\n",
      "iter 3\n",
      "Train_loss: 0.024944469332695007; Val_loss0.03960184007883072 for global step 26\n",
      "iter 4\n",
      "Train_loss: 0.011264152824878693; Val_loss0.02789640799164772 for global step 27\n",
      "iter 5\n",
      "Train_loss: 0.009521564468741417; Val_loss0.022367678582668304 for global step 28\n",
      "iter 6\n",
      "Train_loss: 0.010795596987009048; Val_loss0.02729569934308529 for global step 29\n",
      "iter 7\n",
      "Train_loss: 0.013126050122082233; Val_loss0.030589967966079712 for global step 30\n",
      "iter 8\n",
      "Train_loss: 0.017977047711610794; Val_loss0.03453676030039787 for global step 31\n",
      "iter 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gongbing/anaconda3/envs/GAN_practice/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py:408: UserWarning: An unusually high number of `Iterator.get_next()` calls was detected. This often indicates that `Iterator.get_next()` is being called inside a training loop, which will cause gradual slowdown and eventual resource exhaustion. If this is the case, restructure your code to call `next_element = iterator.get_next()` once outside the loop, and use `next_element` as the input to some computation that is invoked inside the loop.\n",
      "  warnings.warn(GET_NEXT_CALL_WARNING_MESSAGE)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: 0.02111382782459259; Val_loss0.028916671872138977 for global step 32\n",
      "iter 10\n",
      "Train_loss: 0.020132645964622498; Val_loss0.020434508100152016 for global step 33\n",
      "iter 11\n",
      "Train_loss: 0.02447749301791191; Val_loss0.023730896413326263 for global step 34\n",
      "iter 12\n",
      "Train_loss: 0.02405542880296707; Val_loss0.016301894560456276 for global step 35\n",
      "iter 13\n",
      "Train_loss: 0.03178892284631729; Val_loss0.011570471338927746 for global step 36\n",
      "iter 14\n",
      "Train_loss: 0.025819160044193268; Val_loss0.010554560460150242 for global step 37\n",
      "iter 15\n",
      "Train_loss: 0.01980629190802574; Val_loss0.009965412318706512 for global step 38\n",
      "iter 16\n",
      "Train_loss: 0.015596813522279263; Val_loss0.029409734532237053 for global step 39\n",
      "iter 17\n",
      "Train_loss: 0.008390480652451515; Val_loss0.03737672418355942 for global step 40\n",
      "iter 18\n",
      "Train_loss: 0.007606159895658493; Val_loss0.038186706602573395 for global step 41\n",
      "iter 19\n",
      "Train_loss: 0.024350382387638092; Val_loss0.031375959515571594 for global step 42\n",
      "iter 20\n",
      "Train_loss: 0.02091033197939396; Val_loss0.031164325773715973 for global step 43\n",
      "iter 21\n",
      "Train_loss: 0.016037777066230774; Val_loss0.03665217384696007 for global step 44\n",
      "iter 22\n",
      "Train_loss: 0.01064828597009182; Val_loss0.076586052775383 for global step 45\n",
      "iter 0\n",
      "Train_loss: 0.06503808498382568; Val_loss0.060470253229141235 for global step 46\n",
      "iter 1\n",
      "Train_loss: 0.08450015634298325; Val_loss0.07079772651195526 for global step 47\n",
      "iter 2\n",
      "Train_loss: 0.0820365846157074; Val_loss0.06272708624601364 for global step 48\n",
      "iter 3\n",
      "Train_loss: 0.025159209966659546; Val_loss0.04121251404285431 for global step 49\n",
      "iter 4\n",
      "Train_loss: 0.011129913851618767; Val_loss0.029559310525655746 for global step 50\n",
      "iter 5\n",
      "Train_loss: 0.008864057250320911; Val_loss0.023633185774087906 for global step 51\n",
      "iter 6\n",
      "Train_loss: 0.008658677339553833; Val_loss0.028434567153453827 for global step 52\n",
      "iter 7\n",
      "Train_loss: 0.010038248263299465; Val_loss0.0314766988158226 for global step 53\n",
      "iter 8\n",
      "Train_loss: 0.014591636136174202; Val_loss0.0346502885222435 for global step 54\n",
      "iter 9\n",
      "Train_loss: 0.019146472215652466; Val_loss0.027761714532971382 for global step 55\n",
      "iter 10\n",
      "Train_loss: 0.018945157527923584; Val_loss0.01861189864575863 for global step 56\n",
      "iter 11\n",
      "Train_loss: 0.022577086463570595; Val_loss0.021259557455778122 for global step 57\n",
      "iter 12\n",
      "Train_loss: 0.022097937762737274; Val_loss0.01439935714006424 for global step 58\n",
      "iter 13\n",
      "Train_loss: 0.03389418125152588; Val_loss0.01162615604698658 for global step 59\n",
      "iter 14\n",
      "Train_loss: 0.02789914794266224; Val_loss0.009926067665219307 for global step 60\n",
      "iter 15\n",
      "Train_loss: 0.021260086447000504; Val_loss0.00870092585682869 for global step 61\n",
      "iter 16\n",
      "Train_loss: 0.016161395236849785; Val_loss0.026324979960918427 for global step 62\n",
      "iter 17\n",
      "Train_loss: 0.007852627895772457; Val_loss0.034389860928058624 for global step 63\n",
      "iter 18\n",
      "Train_loss: 0.006491073872894049; Val_loss0.0357486829161644 for global step 64\n",
      "iter 19\n",
      "Train_loss: 0.02397463098168373; Val_loss0.029784895479679108 for global step 65\n",
      "iter 20\n",
      "Train_loss: 0.0202149897813797; Val_loss0.03062565252184868 for global step 66\n",
      "iter 21\n",
      "Train_loss: 0.015031395480036736; Val_loss0.03731694445014 for global step 67\n",
      "iter 22\n",
      "Train_loss: 0.010060284286737442; Val_loss0.07908298075199127 for global step 68\n",
      "iter 0\n",
      "Train_loss: 0.06740690022706985; Val_loss0.06160610914230347 for global step 69\n",
      "iter 1\n",
      "Train_loss: 0.08615130186080933; Val_loss0.07029876857995987 for global step 70\n",
      "iter 2\n",
      "Train_loss: 0.08169935643672943; Val_loss0.06105658411979675 for global step 71\n",
      "iter 3\n",
      "Train_loss: 0.02431439235806465; Val_loss0.03969225287437439 for global step 72\n",
      "iter 4\n",
      "Train_loss: 0.010528046637773514; Val_loss0.02879270166158676 for global step 73\n",
      "iter 5\n",
      "Train_loss: 0.008494793437421322; Val_loss0.02379264310002327 for global step 74\n",
      "iter 6\n",
      "Train_loss: 0.00817674957215786; Val_loss0.029496464878320694 for global step 75\n",
      "iter 7\n",
      "Train_loss: 0.008766889572143555; Val_loss0.033702246844768524 for global step 76\n",
      "iter 8\n",
      "Train_loss: 0.012087702751159668; Val_loss0.038175519555807114 for global step 77\n",
      "iter 9\n",
      "Train_loss: 0.01748962141573429; Val_loss0.03128021955490112 for global step 78\n",
      "iter 10\n",
      "Train_loss: 0.02159612625837326; Val_loss0.020578905940055847 for global step 79\n",
      "iter 11\n",
      "Train_loss: 0.024859171360731125; Val_loss0.02196340076625347 for global step 80\n",
      "iter 12\n",
      "Train_loss: 0.022159794345498085; Val_loss0.012947529554367065 for global step 81\n",
      "iter 13\n",
      "Train_loss: 0.03345954045653343; Val_loss0.011031471192836761 for global step 82\n",
      "iter 14\n",
      "Train_loss: 0.028360063210129738; Val_loss0.009050773456692696 for global step 83\n",
      "iter 15\n",
      "Train_loss: 0.0213899165391922; Val_loss0.007873601280152798 for global step 84\n",
      "iter 16\n",
      "Train_loss: 0.015266499482095242; Val_loss0.026448842138051987 for global step 85\n",
      "iter 17\n",
      "Train_loss: 0.007065448444336653; Val_loss0.0351189523935318 for global step 86\n",
      "iter 18\n",
      "Train_loss: 0.005913794506341219; Val_loss0.036272235214710236 for global step 87\n",
      "iter 19\n",
      "Train_loss: 0.022790636867284775; Val_loss0.02977307140827179 for global step 88\n",
      "iter 20\n",
      "Train_loss: 0.019212614744901657; Val_loss0.030208658427000046 for global step 89\n",
      "iter 21\n",
      "Train_loss: 0.014409766532480717; Val_loss0.0361909344792366 for global step 90\n",
      "iter 22\n",
      "Train_loss: 0.009347150102257729; Val_loss0.07677232474088669 for global step 91\n",
      "iter 0\n",
      "Train_loss: 0.06505486369132996; Val_loss0.06014861911535263 for global step 92\n",
      "iter 1\n",
      "Train_loss: 0.08450719714164734; Val_loss0.06876499950885773 for global step 93\n",
      "iter 2\n",
      "Train_loss: 0.08022645115852356; Val_loss0.0584598183631897 for global step 94\n",
      "iter 3\n",
      "Train_loss: 0.02289631962776184; Val_loss0.03595472127199173 for global step 95\n",
      "iter 4\n",
      "Train_loss: 0.009132207371294498; Val_loss0.024157311767339706 for global step 96\n",
      "iter 5\n",
      "Train_loss: 0.0071037462912499905; Val_loss0.018637478351593018 for global step 97\n",
      "iter 6\n",
      "Train_loss: 0.008491071872413158; Val_loss0.023162905126810074 for global step 98\n",
      "iter 7\n",
      "Train_loss: 0.011057913303375244; Val_loss0.026152240112423897 for global step 99\n",
      "iter 8\n",
      "Train_loss: 0.0164826400578022; Val_loss0.02942933887243271 for global step 100\n",
      "iter 9\n",
      "Train_loss: 0.019170008599758148; Val_loss0.023723337799310684 for global step 101\n",
      "iter 10\n",
      "Train_loss: 0.015629645437002182; Val_loss0.016076572239398956 for global step 102\n",
      "iter 11\n",
      "Train_loss: 0.01985989697277546; Val_loss0.019680514931678772 for global step 103\n",
      "iter 12\n",
      "Train_loss: 0.020763996988534927; Val_loss0.013688665814697742 for global step 104\n",
      "iter 13\n",
      "Train_loss: 0.03135280683636665; Val_loss0.009846058674156666 for global step 105\n",
      "iter 14\n",
      "Train_loss: 0.024892525747418404; Val_loss0.008743181824684143 for global step 106\n",
      "iter 15\n",
      "Train_loss: 0.019061336293816566; Val_loss0.008036976680159569 for global step 107\n",
      "iter 16\n",
      "Train_loss: 0.014729484915733337; Val_loss0.026313217356801033 for global step 108\n",
      "iter 17\n",
      "Train_loss: 0.007232511416077614; Val_loss0.03409861773252487 for global step 109\n",
      "iter 18\n",
      "Train_loss: 0.006073988974094391; Val_loss0.03486797958612442 for global step 110\n",
      "iter 19\n",
      "Train_loss: 0.023795537650585175; Val_loss0.028607264161109924 for global step 111\n",
      "iter 20\n",
      "Train_loss: 0.020309723913669586; Val_loss0.02993028238415718 for global step 112\n",
      "iter 21\n",
      "Train_loss: 0.014932926744222641; Val_loss0.038440294563770294 for global step 113\n",
      "iter 22\n",
      "Train_loss: 0.010029861703515053; Val_loss0.08273586630821228 for global step 114\n",
      "iter 0\n",
      "Train_loss: 0.07079894095659256; Val_loss0.058666013181209564 for global step 115\n",
      "iter 1\n",
      "Train_loss: 0.08276921510696411; Val_loss0.06109408289194107 for global step 116\n",
      "iter 2\n",
      "Train_loss: 0.07194013893604279; Val_loss0.050297364592552185 for global step 117\n",
      "iter 3\n",
      "Train_loss: 0.018949229270219803; Val_loss0.03204643726348877 for global step 118\n",
      "iter 4\n",
      "Train_loss: 0.007883161306381226; Val_loss0.023896120488643646 for global step 119\n",
      "iter 5\n",
      "Train_loss: 0.006961727514863014; Val_loss0.021107319742441177 for global step 120\n",
      "iter 6\n",
      "Train_loss: 0.007998714223504066; Val_loss0.028503697365522385 for global step 121\n",
      "iter 7\n",
      "Train_loss: 0.008863214403390884; Val_loss0.034539543092250824 for global step 122\n",
      "iter 8\n",
      "Train_loss: 0.011730775237083435; Val_loss0.040381960570812225 for global step 123\n",
      "iter 9\n",
      "Train_loss: 0.01738135889172554; Val_loss0.033707134425640106 for global step 124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 10\n",
      "Train_loss: 0.023583944886922836; Val_loss0.023498009890317917 for global step 125\n",
      "iter 11\n",
      "Train_loss: 0.028142601251602173; Val_loss0.02691151574254036 for global step 126\n",
      "iter 12\n",
      "Train_loss: 0.0256429985165596; Val_loss0.016381576657295227 for global step 127\n",
      "iter 13\n",
      "Train_loss: 0.024853430688381195; Val_loss0.008420977741479874 for global step 128\n",
      "iter 14\n",
      "Train_loss: 0.020954076200723648; Val_loss0.007855052128434181 for global step 129\n",
      "iter 15\n",
      "Train_loss: 0.01712506264448166; Val_loss0.007370474748313427 for global step 130\n",
      "iter 16\n",
      "Train_loss: 0.01389509066939354; Val_loss0.02488633245229721 for global step 131\n",
      "iter 17\n",
      "Train_loss: 0.006827532313764095; Val_loss0.032306693494319916 for global step 132\n",
      "iter 18\n",
      "Train_loss: 0.005533850751817226; Val_loss0.03299407288432121 for global step 133\n",
      "iter 19\n",
      "Train_loss: 0.024247024208307266; Val_loss0.028097206726670265 for global step 134\n",
      "iter 20\n",
      "Train_loss: 0.02031897008419037; Val_loss0.03188082575798035 for global step 135\n",
      "iter 21\n",
      "Train_loss: 0.014675861224532127; Val_loss0.043561339378356934 for global step 136\n",
      "iter 22\n",
      "Train_loss: 0.011530289426445961; Val_loss0.08997131884098053 for global step 137\n",
      "iter 0\n",
      "Train_loss: 0.07776030153036118; Val_loss0.0627511739730835 for global step 138\n",
      "iter 1\n",
      "Train_loss: 0.08793038129806519; Val_loss0.060324959456920624 for global step 139\n",
      "iter 2\n",
      "Train_loss: 0.07145194709300995; Val_loss0.04319559782743454 for global step 140\n",
      "iter 3\n",
      "Train_loss: 0.016064906492829323; Val_loss0.021859917789697647 for global step 141\n",
      "iter 4\n",
      "Train_loss: 0.0060285767540335655; Val_loss0.012418870814144611 for global step 142\n",
      "iter 5\n",
      "Train_loss: 0.006367071531713009; Val_loss0.009433571249246597 for global step 143\n",
      "iter 6\n",
      "Train_loss: 0.012858858332037926; Val_loss0.014014322310686111 for global step 144\n",
      "iter 7\n",
      "Train_loss: 0.018000394105911255; Val_loss0.01847226545214653 for global step 145\n",
      "iter 8\n",
      "Train_loss: 0.023269854485988617; Val_loss0.02521682158112526 for global step 146\n",
      "iter 9\n",
      "Train_loss: 0.020115431398153305; Val_loss0.02425357699394226 for global step 147\n",
      "iter 10\n",
      "Train_loss: 0.01601521298289299; Val_loss0.019245292991399765 for global step 148\n",
      "iter 11\n",
      "Train_loss: 0.02342245727777481; Val_loss0.026031725108623505 for global step 149\n",
      "iter 12\n",
      "Train_loss: 0.024967722594738007; Val_loss0.018343262374401093 for global step 150\n",
      "iter 13\n",
      "Train_loss: 0.02151533216238022; Val_loss0.0074769556522369385 for global step 151\n",
      "iter 14\n",
      "Train_loss: 0.015534676611423492; Val_loss0.007957510650157928 for global step 152\n",
      "iter 15\n",
      "Train_loss: 0.011744658462703228; Val_loss0.009309817105531693 for global step 153\n",
      "iter 16\n",
      "Train_loss: 0.009795285761356354; Val_loss0.03254566341638565 for global step 154\n",
      "iter 17\n",
      "Train_loss: 0.006060208193957806; Val_loss0.039411839097738266 for global step 155\n",
      "iter 18\n",
      "Train_loss: 0.005934222601354122; Val_loss0.03718184307217598 for global step 156\n",
      "iter 19\n",
      "Train_loss: 0.021847514435648918; Val_loss0.028379343450069427 for global step 157\n",
      "iter 20\n",
      "Train_loss: 0.01958819106221199; Val_loss0.028547264635562897 for global step 158\n",
      "iter 21\n",
      "Train_loss: 0.015019092708826065; Val_loss0.036134980618953705 for global step 159\n",
      "iter 22\n",
      "Train_loss: 0.009355667047202587; Val_loss0.07919836789369583 for global step 160\n",
      "iter 0\n",
      "Train_loss: 0.06721824407577515; Val_loss0.055285222828388214 for global step 161\n",
      "iter 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-556a653a966b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_vae2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer_and_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvLSTM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-827b8e116a8f>\u001b[0m in \u001b[0;36mtrainer_and_checkpoint\u001b[0;34m(model_class, learning_rate, batch_size, num_epoch, n_z, log_step)\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"iter\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mglobal_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_single_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m             \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Train_loss: {}; Val_loss{} for global step {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_losses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mcheckpoint_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model_arc4.ckpt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-67e864a61367>\u001b[0m in \u001b[0;36mrun_single_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0mtrain_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m             \u001b[0mx_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_summary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_loss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"images\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_summary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/GAN_practice/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/GAN_practice/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/GAN_practice/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/GAN_practice/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/GAN_practice/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/GAN_practice/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_vae2 = trainer_and_checkpoint(convLSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs shape (?, 64, 64, 3)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "hidden zero layer (?, 16, 16, 16)\n",
      "output for cell: Tensor(\"network/conv_lstm/BasicConvLSTMCell/mul_2:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "output_shape, [None, 16, 16, 8]\n",
      "output_shape Tensor(\"network/decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "conv5 shape Tensor(\"network/decode_5_trans_conv/decode_5_transpose_conv:0\", shape=(?, 32, 32, 8), dtype=float32)\n",
      "output_shape Tensor(\"network/decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "conv6 shape Tensor(\"network/decode_6_trans_conv/decode_6_transpose_conv:0\", shape=(?, 32, 32, 8), dtype=float32)\n",
      "output_shape Tensor(\"network/decode_7_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "x hat shape Tensor(\"network/decode_7_trans_conv/sigmoid:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "Inputs shape (?, 64, 64, 3)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "output for cell: Tensor(\"network_1/conv_lstm/BasicConvLSTMCell/mul_2:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "output_shape, [None, 16, 16, 8]\n",
      "output_shape Tensor(\"network_1/decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "conv5 shape Tensor(\"network_1/decode_5_trans_conv/decode_5_transpose_conv:0\", shape=(?, 32, 32, 8), dtype=float32)\n",
      "output_shape Tensor(\"network_1/decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "conv6 shape Tensor(\"network_1/decode_6_trans_conv/decode_6_transpose_conv:0\", shape=(?, 32, 32, 8), dtype=float32)\n",
      "output_shape Tensor(\"network_1/decode_7_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "x hat shape Tensor(\"network_1/decode_7_trans_conv/sigmoid:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "Inputs shape (?, 64, 64, 3)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "output for cell: Tensor(\"network_2/conv_lstm/BasicConvLSTMCell/mul_2:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "output_shape, [None, 16, 16, 8]\n",
      "output_shape Tensor(\"network_2/decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "conv5 shape Tensor(\"network_2/decode_5_trans_conv/decode_5_transpose_conv:0\", shape=(?, 32, 32, 8), dtype=float32)\n",
      "output_shape Tensor(\"network_2/decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "conv6 shape Tensor(\"network_2/decode_6_trans_conv/decode_6_transpose_conv:0\", shape=(?, 32, 32, 8), dtype=float32)\n",
      "output_shape Tensor(\"network_2/decode_7_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "x hat shape Tensor(\"network_2/decode_7_trans_conv/sigmoid:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "Inputs shape (?, 64, 64, 3)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "output for cell: Tensor(\"network_3/conv_lstm/BasicConvLSTMCell/mul_2:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "output_shape, [None, 16, 16, 8]\n",
      "output_shape Tensor(\"network_3/decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "conv5 shape Tensor(\"network_3/decode_5_trans_conv/decode_5_transpose_conv:0\", shape=(?, 32, 32, 8), dtype=float32)\n",
      "output_shape Tensor(\"network_3/decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "conv6 shape Tensor(\"network_3/decode_6_trans_conv/decode_6_transpose_conv:0\", shape=(?, 32, 32, 8), dtype=float32)\n",
      "output_shape Tensor(\"network_3/decode_7_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "x hat shape Tensor(\"network_3/decode_7_trans_conv/sigmoid:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "Inputs shape (?, 64, 64, 3)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "output for cell: Tensor(\"network_4/conv_lstm/BasicConvLSTMCell/mul_2:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "output_shape, [None, 16, 16, 8]\n",
      "output_shape Tensor(\"network_4/decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "conv5 shape Tensor(\"network_4/decode_5_trans_conv/decode_5_transpose_conv:0\", shape=(?, 32, 32, 8), dtype=float32)\n",
      "output_shape Tensor(\"network_4/decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "conv6 shape Tensor(\"network_4/decode_6_trans_conv/decode_6_transpose_conv:0\", shape=(?, 32, 32, 8), dtype=float32)\n",
      "output_shape Tensor(\"network_4/decode_7_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "x hat shape Tensor(\"network_4/decode_7_trans_conv/sigmoid:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "Inputs shape (?, 64, 64, 3)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "output for cell: Tensor(\"network_5/conv_lstm/BasicConvLSTMCell/mul_2:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "output_shape, [None, 16, 16, 8]\n",
      "output_shape Tensor(\"network_5/decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "conv5 shape Tensor(\"network_5/decode_5_trans_conv/decode_5_transpose_conv:0\", shape=(?, 32, 32, 8), dtype=float32)\n",
      "output_shape Tensor(\"network_5/decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "conv6 shape Tensor(\"network_5/decode_6_trans_conv/decode_6_transpose_conv:0\", shape=(?, 32, 32, 8), dtype=float32)\n",
      "output_shape Tensor(\"network_5/decode_7_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "x hat shape Tensor(\"network_5/decode_7_trans_conv/sigmoid:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "Inputs shape (?, 64, 64, 3)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "output for cell: Tensor(\"network_6/conv_lstm/BasicConvLSTMCell/mul_2:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "output_shape, [None, 16, 16, 8]\n",
      "output_shape Tensor(\"network_6/decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "conv5 shape Tensor(\"network_6/decode_5_trans_conv/decode_5_transpose_conv:0\", shape=(?, 32, 32, 8), dtype=float32)\n",
      "output_shape Tensor(\"network_6/decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "conv6 shape Tensor(\"network_6/decode_6_trans_conv/decode_6_transpose_conv:0\", shape=(?, 32, 32, 8), dtype=float32)\n",
      "output_shape Tensor(\"network_6/decode_7_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "x hat shape Tensor(\"network_6/decode_7_trans_conv/sigmoid:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "Inputs shape (?, 64, 64, 3)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "output for cell: Tensor(\"network_7/conv_lstm/BasicConvLSTMCell/mul_2:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "output_shape, [None, 16, 16, 8]\n",
      "output_shape Tensor(\"network_7/decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "conv5 shape Tensor(\"network_7/decode_5_trans_conv/decode_5_transpose_conv:0\", shape=(?, 32, 32, 8), dtype=float32)\n",
      "output_shape Tensor(\"network_7/decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "conv6 shape Tensor(\"network_7/decode_6_trans_conv/decode_6_transpose_conv:0\", shape=(?, 32, 32, 8), dtype=float32)\n",
      "output_shape Tensor(\"network_7/decode_7_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "x hat shape Tensor(\"network_7/decode_7_trans_conv/sigmoid:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "Inputs shape (?, 64, 64, 3)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "output for cell: Tensor(\"network_8/conv_lstm/BasicConvLSTMCell/mul_2:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "output_shape, [None, 16, 16, 8]\n",
      "output_shape Tensor(\"network_8/decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv5 shape Tensor(\"network_8/decode_5_trans_conv/decode_5_transpose_conv:0\", shape=(?, 32, 32, 8), dtype=float32)\n",
      "output_shape Tensor(\"network_8/decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "conv6 shape Tensor(\"network_8/decode_6_trans_conv/decode_6_transpose_conv:0\", shape=(?, 32, 32, 8), dtype=float32)\n",
      "output_shape Tensor(\"network_8/decode_7_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "x hat shape Tensor(\"network_8/decode_7_trans_conv/sigmoid:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "Inputs shape (?, 64, 64, 3)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "output for cell: Tensor(\"network_9/conv_lstm/BasicConvLSTMCell/mul_2:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "output_shape, [None, 16, 16, 8]\n",
      "output_shape Tensor(\"network_9/decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "conv5 shape Tensor(\"network_9/decode_5_trans_conv/decode_5_transpose_conv:0\", shape=(?, 32, 32, 8), dtype=float32)\n",
      "output_shape Tensor(\"network_9/decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "conv6 shape Tensor(\"network_9/decode_6_trans_conv/decode_6_transpose_conv:0\", shape=(?, 32, 32, 8), dtype=float32)\n",
      "output_shape Tensor(\"network_9/decode_7_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "x hat shape Tensor(\"network_9/decode_7_trans_conv/sigmoid:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "Inputs shape (?, 64, 64, 3)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "output for cell: Tensor(\"network_10/conv_lstm/BasicConvLSTMCell/mul_2:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "output_shape, [None, 16, 16, 8]\n",
      "output_shape Tensor(\"network_10/decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "conv5 shape Tensor(\"network_10/decode_5_trans_conv/decode_5_transpose_conv:0\", shape=(?, 32, 32, 8), dtype=float32)\n",
      "output_shape Tensor(\"network_10/decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "conv6 shape Tensor(\"network_10/decode_6_trans_conv/decode_6_transpose_conv:0\", shape=(?, 32, 32, 8), dtype=float32)\n",
      "output_shape Tensor(\"network_10/decode_7_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "x hat shape Tensor(\"network_10/decode_7_trans_conv/sigmoid:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "Inputs shape (?, 64, 64, 3)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "output for cell: Tensor(\"network_11/conv_lstm/BasicConvLSTMCell/mul_2:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "output_shape, [None, 16, 16, 8]\n",
      "output_shape Tensor(\"network_11/decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "conv5 shape Tensor(\"network_11/decode_5_trans_conv/decode_5_transpose_conv:0\", shape=(?, 32, 32, 8), dtype=float32)\n",
      "output_shape Tensor(\"network_11/decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "conv6 shape Tensor(\"network_11/decode_6_trans_conv/decode_6_transpose_conv:0\", shape=(?, 32, 32, 8), dtype=float32)\n",
      "output_shape Tensor(\"network_11/decode_7_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "x hat shape Tensor(\"network_11/decode_7_trans_conv/sigmoid:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "Inputs shape (?, 64, 64, 3)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "output for cell: Tensor(\"network_12/conv_lstm/BasicConvLSTMCell/mul_2:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "output_shape, [None, 16, 16, 8]\n",
      "output_shape Tensor(\"network_12/decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "conv5 shape Tensor(\"network_12/decode_5_trans_conv/decode_5_transpose_conv:0\", shape=(?, 32, 32, 8), dtype=float32)\n",
      "output_shape Tensor(\"network_12/decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "conv6 shape Tensor(\"network_12/decode_6_trans_conv/decode_6_transpose_conv:0\", shape=(?, 32, 32, 8), dtype=float32)\n",
      "output_shape Tensor(\"network_12/decode_7_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "x hat shape Tensor(\"network_12/decode_7_trans_conv/sigmoid:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "Inputs shape (?, 64, 64, 3)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "output for cell: Tensor(\"network_13/conv_lstm/BasicConvLSTMCell/mul_2:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "output_shape, [None, 16, 16, 8]\n",
      "output_shape Tensor(\"network_13/decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "conv5 shape Tensor(\"network_13/decode_5_trans_conv/decode_5_transpose_conv:0\", shape=(?, 32, 32, 8), dtype=float32)\n",
      "output_shape Tensor(\"network_13/decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "conv6 shape Tensor(\"network_13/decode_6_trans_conv/decode_6_transpose_conv:0\", shape=(?, 32, 32, 8), dtype=float32)\n",
      "output_shape Tensor(\"network_13/decode_7_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "x hat shape Tensor(\"network_13/decode_7_trans_conv/sigmoid:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "Inputs shape (?, 64, 64, 3)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "output for cell: Tensor(\"network_14/conv_lstm/BasicConvLSTMCell/mul_2:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "output_shape, [None, 16, 16, 8]\n",
      "output_shape Tensor(\"network_14/decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "conv5 shape Tensor(\"network_14/decode_5_trans_conv/decode_5_transpose_conv:0\", shape=(?, 32, 32, 8), dtype=float32)\n",
      "output_shape Tensor(\"network_14/decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "conv6 shape Tensor(\"network_14/decode_6_trans_conv/decode_6_transpose_conv:0\", shape=(?, 32, 32, 8), dtype=float32)\n",
      "output_shape Tensor(\"network_14/decode_7_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "x hat shape Tensor(\"network_14/decode_7_trans_conv/sigmoid:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "Inputs shape (?, 64, 64, 3)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "output for cell: Tensor(\"network_15/conv_lstm/BasicConvLSTMCell/mul_2:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "output_shape, [None, 16, 16, 8]\n",
      "output_shape Tensor(\"network_15/decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "conv5 shape Tensor(\"network_15/decode_5_trans_conv/decode_5_transpose_conv:0\", shape=(?, 32, 32, 8), dtype=float32)\n",
      "output_shape Tensor(\"network_15/decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "conv6 shape Tensor(\"network_15/decode_6_trans_conv/decode_6_transpose_conv:0\", shape=(?, 32, 32, 8), dtype=float32)\n",
      "output_shape Tensor(\"network_15/decode_7_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "x hat shape Tensor(\"network_15/decode_7_trans_conv/sigmoid:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "Inputs shape (?, 64, 64, 3)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "output for cell: Tensor(\"network_16/conv_lstm/BasicConvLSTMCell/mul_2:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "output_shape, [None, 16, 16, 8]\n",
      "output_shape Tensor(\"network_16/decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "conv5 shape Tensor(\"network_16/decode_5_trans_conv/decode_5_transpose_conv:0\", shape=(?, 32, 32, 8), dtype=float32)\n",
      "output_shape Tensor(\"network_16/decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "conv6 shape Tensor(\"network_16/decode_6_trans_conv/decode_6_transpose_conv:0\", shape=(?, 32, 32, 8), dtype=float32)\n",
      "output_shape Tensor(\"network_16/decode_7_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "x hat shape Tensor(\"network_16/decode_7_trans_conv/sigmoid:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "Inputs shape (?, 64, 64, 3)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "output for cell: Tensor(\"network_17/conv_lstm/BasicConvLSTMCell/mul_2:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "output_shape, [None, 16, 16, 8]\n",
      "output_shape Tensor(\"network_17/decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "conv5 shape Tensor(\"network_17/decode_5_trans_conv/decode_5_transpose_conv:0\", shape=(?, 32, 32, 8), dtype=float32)\n",
      "output_shape Tensor(\"network_17/decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "conv6 shape Tensor(\"network_17/decode_6_trans_conv/decode_6_transpose_conv:0\", shape=(?, 32, 32, 8), dtype=float32)\n",
      "output_shape Tensor(\"network_17/decode_7_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "x hat shape Tensor(\"network_17/decode_7_trans_conv/sigmoid:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "Inputs shape (?, 64, 64, 3)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "output for cell: Tensor(\"network_18/conv_lstm/BasicConvLSTMCell/mul_2:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "output_shape, [None, 16, 16, 8]\n",
      "output_shape Tensor(\"network_18/decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "conv5 shape Tensor(\"network_18/decode_5_trans_conv/decode_5_transpose_conv:0\", shape=(?, 32, 32, 8), dtype=float32)\n",
      "output_shape Tensor(\"network_18/decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "conv6 shape Tensor(\"network_18/decode_6_trans_conv/decode_6_transpose_conv:0\", shape=(?, 32, 32, 8), dtype=float32)\n",
      "output_shape Tensor(\"network_18/decode_7_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "x hat shape Tensor(\"network_18/decode_7_trans_conv/sigmoid:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "Inputs shape (?, 64, 64, 3)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function leaky_relu\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "output for cell: Tensor(\"network_19/conv_lstm/BasicConvLSTMCell/mul_2:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "output_shape, [None, 16, 16, 8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_shape Tensor(\"network_19/decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "conv5 shape Tensor(\"network_19/decode_5_trans_conv/decode_5_transpose_conv:0\", shape=(?, 32, 32, 8), dtype=float32)\n",
      "output_shape Tensor(\"network_19/decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "conv6 shape Tensor(\"network_19/decode_6_trans_conv/decode_6_transpose_conv:0\", shape=(?, 32, 32, 8), dtype=float32)\n",
      "output_shape Tensor(\"network_19/decode_7_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "x hat shape Tensor(\"network_19/decode_7_trans_conv/sigmoid:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "x_hat,shape Tensor(\"concat:0\", shape=(?, 20, 64, 64, 3), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gongbing/anaconda3/envs/GAN_practice/lib/python3.6/site-packages/tensorflow/python/client/session.py:1702: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_checkpoint_dir convLSTM1/checkpoint\n",
      "INFO:tensorflow:Restoring parameters from convLSTM1/checkpoint/model_arc4.ckpt-98\n",
      "recon_loss 0.026403949\n",
      "real_image (20, 64, 64, 3)\n",
      "predic image (20, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "#def model_prediction():\n",
    "model = convLSTM(lr=1e-4, batch_size=64, nz=16)\n",
    "ckpt = tf.train.get_checkpoint_state(model.checkpoint_dir)\n",
    "print(\"model_checkpoint_dir\",model.checkpoint_dir)\n",
    "global_step = int(os.path.basename(ckpt.model_checkpoint_path).split('-')[1])\n",
    "#First let's load meta graph and restore weights\n",
    "sess = tf.Session()  \n",
    "saver = tf.train.Saver(tf.global_variables())\n",
    "saver.restore(sess,tf.train.latest_checkpoint(model.checkpoint_dir))\n",
    "#latest_checkpoints = saver.restore(sess,tf.train.latest_checkpoint('./'))\n",
    "graph = tf.get_default_graph()\n",
    "#op = sess.graph.get_operations()\n",
    "loaded_vars = tf.trainable_variables() \n",
    "test_iterator = make_dataset(type=\"test\")\n",
    "sess.run(test_iterator.initializer)\n",
    "for i in range(1):\n",
    "    test_batch = sess.run(test_iterator.get_next())\n",
    "    # print(\"test_batch\",test_batch[\"images\"].shape)\n",
    "    #op_to_restore.eval(feed_dict={model.x: test_batch[\"images\"]})\n",
    "    predict_images,  recon_loss = sess.run([model.x_hat, model.total_loss], feed_dict={model.x: test_batch[\"images\"]})\n",
    "    #plot real and predicted images\n",
    "    real_img = test_batch[\"images\"][0]\n",
    "    pred_img = predict_images[0]\n",
    "    #plt.figure(figsize=(8, 8))\n",
    "    #plt.imshow(real_img[0])\n",
    "    print(\"recon_loss\",recon_loss)\n",
    "    print(\"real_image\",real_img.shape)\n",
    "    print(\"predic image\", pred_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.5560357 , 0.5554696 , 0.5550167 , 0.55508465, 0.55508465,\n",
       "        0.55490345, 0.5546091 , 0.55422413, 0.55320513, 0.5519144 ,\n",
       "        0.5500576 , 0.5483366 , 0.54668355, 0.54464555, 0.54299253,\n",
       "        0.54215467, 0.54122627, 0.54025257, 0.5384863 , 0.5368785 ,\n",
       "        0.53554255, 0.5287492 , 0.5191933 , 0.512717  , 0.45368317,\n",
       "        0.4614049 , 0.4616087 , 0.45902723, 0.46871904, 0.47924864,\n",
       "        0.49399012, 0.49879074, 0.5079164 , 0.5121962 , 0.51584196,\n",
       "        0.51824224, 0.51969147, 0.52066517, 0.51609105, 0.51217353,\n",
       "        0.5048821 , 0.48690245, 0.47519532, 0.46878695, 0.46280885,\n",
       "        0.45766857, 0.452166  , 0.44648227, 0.44734275, 0.44849762,\n",
       "        0.46081614, 0.44849762, 0.4451236 , 0.43957573, 0.4354318 ,\n",
       "        0.43414107, 0.4350695 , 0.43713015, 0.44000596, 0.45092055,\n",
       "        0.4548154 , 0.45830262, 0.4615634 , 0.46244654], dtype=float32),\n",
       " array([0.55576396, 0.5558998 , 0.55601305, 0.5557413 , 0.5555602 ,\n",
       "        0.5554922 , 0.5548582 , 0.5539071 , 0.55300134, 0.55182385,\n",
       "        0.5501255 , 0.5484951 , 0.54688734, 0.545257  , 0.5436945 ,\n",
       "        0.54224527, 0.54138476, 0.54079604, 0.5389845 , 0.5371277 ,\n",
       "        0.5351802 , 0.53334606, 0.5315798 , 0.52859074, 0.52634895,\n",
       "        0.52512616, 0.5208916 , 0.5154796 , 0.5175176 , 0.5185819 ,\n",
       "        0.519465  , 0.5208237 , 0.52243143, 0.52320135, 0.5233599 ,\n",
       "        0.52236354, 0.51969147, 0.5162269 , 0.5124453 , 0.50891274,\n",
       "        0.5043386 , 0.48701566, 0.47315732, 0.4644166 , 0.4563099 ,\n",
       "        0.44947132, 0.44362906, 0.438285  , 0.43819442, 0.43880582,\n",
       "        0.44077587, 0.4386926 , 0.43454868, 0.43178606, 0.42972544,\n",
       "        0.4290914 , 0.4321031 , 0.43697163, 0.4487467 , 0.45173576,\n",
       "        0.45606083, 0.45918575, 0.46174455, 0.46113315], dtype=float32),\n",
       " array([0.55596775, 0.5564433 , 0.55703205, 0.5566018 , 0.55626214,\n",
       "        0.55612624, 0.5551752 , 0.55381656, 0.5525258 , 0.55116713,\n",
       "        0.54964995, 0.5479743 , 0.5462533 , 0.54482675, 0.54337746,\n",
       "        0.54186034, 0.5405696 , 0.5393468 , 0.5382372 , 0.53681064,\n",
       "        0.5347953 , 0.53248554, 0.52999467, 0.5290436 , 0.52816045,\n",
       "        0.5274132 , 0.52646214, 0.52539784, 0.5272094 , 0.52845484,\n",
       "        0.52854544, 0.5289077 , 0.52936065, 0.52621305, 0.5227258 ,\n",
       "        0.516476  , 0.49145398, 0.5047009 , 0.5045424 , 0.50390834,\n",
       "        0.5023006 , 0.4955073 , 0.4742669 , 0.46088406, 0.4532303 ,\n",
       "        0.44546327, 0.4401192 , 0.43599793, 0.43432224, 0.43280506,\n",
       "        0.4316502 , 0.43099353, 0.43060857, 0.43063122, 0.43051797,\n",
       "        0.43015566, 0.4340958 , 0.44018713, 0.44958454, 0.45255095,\n",
       "        0.45766857, 0.46027267, 0.46163133, 0.45474744], dtype=float32),\n",
       " array([0.5562848 , 0.5567603 , 0.5573717 , 0.5570547 , 0.5565339 ,\n",
       "        0.5556507 , 0.5545412 , 0.55329573, 0.5518691 , 0.5503293 ,\n",
       "        0.5485857 , 0.5470006 , 0.54550606, 0.54367185, 0.54197353,\n",
       "        0.54054695, 0.5390751 , 0.5376032 , 0.53642565, 0.53520286,\n",
       "        0.5338895 , 0.5327573 , 0.53171563, 0.5305155 , 0.5297909 ,\n",
       "        0.52999467, 0.5305608 , 0.53126276, 0.53287053, 0.53345925,\n",
       "        0.53203267, 0.52947384, 0.52634895, 0.52134454, 0.49072933,\n",
       "        0.48153573, 0.48135456, 0.49727356, 0.49890396, 0.49897188,\n",
       "        0.5011005 , 0.49625456, 0.48898572, 0.4615634 , 0.4551324 ,\n",
       "        0.44686723, 0.44238362, 0.43982482, 0.4369037 , 0.4344581 ,\n",
       "        0.43294093, 0.43214837, 0.4316955 , 0.43323532, 0.43484306,\n",
       "        0.43654138, 0.4387379 , 0.44784093, 0.450128  , 0.45565322,\n",
       "        0.46104258, 0.46287677, 0.46387312, 0.4577818 ], dtype=float32),\n",
       " array([0.557417  , 0.5574623 , 0.55707735, 0.5565112 , 0.555696  ,\n",
       "        0.5544053 , 0.553024  , 0.55162   , 0.5503972 , 0.548948  ,\n",
       "        0.5470006 , 0.5453928 , 0.5439436 , 0.5423585 , 0.54079604,\n",
       "        0.5393015 , 0.537422  , 0.5353614 , 0.5350444 , 0.5347953 ,\n",
       "        0.5346594 , 0.53452355, 0.53436506, 0.5340027 , 0.53379893,\n",
       "        0.5339348 , 0.5346594 , 0.5356331 , 0.5350897 , 0.5336178 ,\n",
       "        0.51133573, 0.51018083, 0.5126717 , 0.49016324, 0.48540792,\n",
       "        0.48019972, 0.48042616, 0.49500912, 0.49727356, 0.49962857,\n",
       "        0.50033057, 0.4977944 , 0.49371842, 0.48640427, 0.45841584,\n",
       "        0.44747862, 0.44258744, 0.4406853 , 0.43853408, 0.4370169 ,\n",
       "        0.4366999 , 0.43602055, 0.43513742, 0.4364055 , 0.43876052,\n",
       "        0.44335735, 0.44582558, 0.45295855, 0.45642313, 0.46219745,\n",
       "        0.4647789 , 0.46697542, 0.46928513, 0.47025883], dtype=float32),\n",
       " array([0.5571679 , 0.55694145, 0.5565339 , 0.55576396, 0.55469966,\n",
       "        0.55309194, 0.5514162 , 0.54969525, 0.5480649 , 0.5463213 ,\n",
       "        0.5443738 , 0.5431963 , 0.54224527, 0.5412489 , 0.5400941 ,\n",
       "        0.538826  , 0.53719556, 0.5355652 , 0.5350444 , 0.53540665,\n",
       "        0.53656155, 0.5374673 , 0.5382372 , 0.53871274, 0.53880334,\n",
       "        0.53866744, 0.53866744, 0.537807  , 0.5342065 , 0.530357  ,\n",
       "        0.506286  , 0.5031611 , 0.4975906 , 0.48846492, 0.48502296,\n",
       "        0.48327935, 0.4846833 , 0.49451095, 0.49897188, 0.5003079 ,\n",
       "        0.4999456 , 0.4958017 , 0.49075198, 0.4840266 , 0.47558028,\n",
       "        0.45080733, 0.443697  , 0.43998334, 0.43835294, 0.43697163,\n",
       "        0.43636024, 0.43692634, 0.438987  , 0.4404815 , 0.44220248,\n",
       "        0.44476128, 0.44876933, 0.45732892, 0.46104258, 0.46545824,\n",
       "        0.4693757 , 0.47277236, 0.47598785, 0.4783429 ], dtype=float32),\n",
       " array([0.55562806, 0.5553564 , 0.555062  , 0.5545412 , 0.55368066,\n",
       "        0.55232203, 0.5504425 , 0.548314  , 0.5457325 , 0.54367185,\n",
       "        0.5419509 , 0.54152066, 0.54127157, 0.54113567, 0.5401393 ,\n",
       "        0.5389392 , 0.53782964, 0.53715026, 0.53681064, 0.5379202 ,\n",
       "        0.53927886, 0.54070544, 0.54122627, 0.54143006, 0.54147536,\n",
       "        0.54075074, 0.53948265, 0.5370597 , 0.5328026 , 0.5263942 ,\n",
       "        0.5070786 , 0.5033196 , 0.49944744, 0.49476004, 0.4909105 ,\n",
       "        0.48903102, 0.48828375, 0.4879441 , 0.4901859 , 0.49883604,\n",
       "        0.49451095, 0.48986885, 0.48540792, 0.47761825, 0.47089288,\n",
       "        0.44827116, 0.44276857, 0.43835294, 0.4371075 , 0.4379227 ,\n",
       "        0.440323  , 0.4455765 , 0.4489958 , 0.44938073, 0.45006007,\n",
       "        0.45082998, 0.45864227, 0.4622201 , 0.4671792 , 0.47168544,\n",
       "        0.47582936, 0.4794751 , 0.4824415 , 0.48486444], dtype=float32),\n",
       " array([0.55368066, 0.55386186, 0.5539071 , 0.55392975, 0.5534995 ,\n",
       "        0.5523447 , 0.54998964, 0.5472497 , 0.5442153 , 0.5423585 ,\n",
       "        0.5413395 , 0.5405696 , 0.5401167 , 0.5400714 , 0.5397997 ,\n",
       "        0.53927886, 0.5379655 , 0.5371729 , 0.5367427 , 0.5380561 ,\n",
       "        0.5397544 , 0.5419962 , 0.5430152 , 0.5435813 , 0.543536  ,\n",
       "        0.5423132 , 0.5403205 , 0.53651625, 0.53155714, 0.5248318 ,\n",
       "        0.5065351 , 0.5024138 , 0.49885866, 0.49625456, 0.49426186,\n",
       "        0.49129546, 0.48975563, 0.49521294, 0.49659422, 0.4959602 ,\n",
       "        0.4872874 , 0.47974682, 0.47297618, 0.45698926, 0.45255095,\n",
       "        0.44729745, 0.4449198 , 0.4426327 , 0.43826234, 0.43817177,\n",
       "        0.45137343, 0.46588847, 0.47397253, 0.47234213, 0.468402  ,\n",
       "        0.46545824, 0.46862844, 0.47200245, 0.47571614, 0.478909  ,\n",
       "        0.48210183, 0.48522675, 0.48767236, 0.4894839 ], dtype=float32),\n",
       " array([0.55241257, 0.5528202 , 0.55329573, 0.5530693 , 0.5525258 ,\n",
       "        0.55148417, 0.5494688 , 0.5470912 , 0.5441247 , 0.5419962 ,\n",
       "        0.5404337 , 0.5400714 , 0.53961855, 0.5389845 , 0.5381014 ,\n",
       "        0.53715026, 0.53631246, 0.5361539 , 0.53647095, 0.53762585,\n",
       "        0.53923357, 0.54143006, 0.54278874, 0.5434454 , 0.5422679 ,\n",
       "        0.54059225, 0.53855425, 0.53447825, 0.529338  , 0.5225447 ,\n",
       "        0.5085731 , 0.5053123 , 0.50166655, 0.4985643 , 0.4958017 ,\n",
       "        0.49505442, 0.49426186, 0.49444303, 0.49292585, 0.4907067 ,\n",
       "        0.4701909 , 0.46862844, 0.46122375, 0.4589593 , 0.45678544,\n",
       "        0.44621053, 0.43885112, 0.43762833, 0.44016448, 0.4443084 ,\n",
       "        0.47048527, 0.47852403, 0.48183012, 0.47795793, 0.4763502 ,\n",
       "        0.47582936, 0.4774371 , 0.47976947, 0.48257738, 0.4850456 ,\n",
       "        0.4874912 , 0.48986885, 0.49197477, 0.49353725], dtype=float32),\n",
       " array([0.5528881 , 0.5526164 , 0.55270696, 0.5520503 , 0.5511445 ,\n",
       "        0.5498538 , 0.54790634, 0.5457325 , 0.54326427, 0.5407734 ,\n",
       "        0.5382372 , 0.5375126 , 0.5369465 , 0.53656155, 0.5359728 ,\n",
       "        0.53540665, 0.5351349 , 0.5349538 , 0.53486323, 0.53617656,\n",
       "        0.53782964, 0.5399808 , 0.54192823, 0.54335487, 0.5427208 ,\n",
       "        0.54075074, 0.53787494, 0.5330743 , 0.5268471 , 0.5185819 ,\n",
       "        0.51434743, 0.50166655, 0.5003532 , 0.4991757 , 0.49808878,\n",
       "        0.497183  , 0.49301642, 0.48925745, 0.48900837, 0.4888725 ,\n",
       "        0.46736038, 0.46194836, 0.45572117, 0.4612011 , 0.47023618,\n",
       "        0.45080733, 0.43760568, 0.4377189 , 0.44999215, 0.45510978,\n",
       "        0.48266795, 0.48486444, 0.48475122, 0.48124135, 0.48262265,\n",
       "        0.48522675, 0.48792145, 0.49045762, 0.4929032 , 0.4934693 ,\n",
       "        0.49383163, 0.49394485, 0.4945336 , 0.49539408], dtype=float32),\n",
       " array([0.5513483 , 0.5507369 , 0.55046517, 0.54974055, 0.54881215,\n",
       "        0.54765725, 0.54546076, 0.54294723, 0.5401393 , 0.537807  ,\n",
       "        0.535769  , 0.5345009 , 0.5339121 , 0.5337763 , 0.5340254 ,\n",
       "        0.5350897 , 0.5369918 , 0.53821456, 0.5390524 , 0.5393468 ,\n",
       "        0.5400488 , 0.54079604, 0.541498  , 0.5420415 , 0.5422226 ,\n",
       "        0.5403205 , 0.5379428 , 0.53520286, 0.5284322 , 0.52039343,\n",
       "        0.51074696, 0.5041122 , 0.50248176, 0.50001353, 0.49761322,\n",
       "        0.49512234, 0.49202007, 0.48980093, 0.48835167, 0.48706096,\n",
       "        0.47911277, 0.4645298 , 0.4602274 , 0.45963863, 0.48583817,\n",
       "        0.4854985 , 0.484638  , 0.4850909 , 0.48812523, 0.49202007,\n",
       "        0.4937637 , 0.4932655 , 0.49102372, 0.49374104, 0.4957564 ,\n",
       "        0.4968886 , 0.49797553, 0.4985643 , 0.4981114 , 0.49702448,\n",
       "        0.49577904, 0.494828  , 0.49408072, 0.49367312], dtype=float32),\n",
       " array([0.55055577, 0.54989904, 0.5481554 , 0.5476799 , 0.547227  ,\n",
       "        0.54677415, 0.5446003 , 0.5419056 , 0.5385769 , 0.53579164,\n",
       "        0.5333687 , 0.53189677, 0.531693  , 0.5323497 , 0.53379893,\n",
       "        0.5361087 , 0.5392562 , 0.54219997, 0.5436492 , 0.5425623 ,\n",
       "        0.542517  , 0.5428567 , 0.5436492 , 0.5436492 , 0.5430605 ,\n",
       "        0.5409772 , 0.5382372 , 0.5349991 , 0.5273453 , 0.5184234 ,\n",
       "        0.5078032 , 0.50399894, 0.5025497 , 0.49922097, 0.49799818,\n",
       "        0.49756795, 0.49797553, 0.49802083, 0.4968207 , 0.49281263,\n",
       "        0.48518148, 0.4782523 , 0.4793845 , 0.48581553, 0.48986885,\n",
       "        0.49215594, 0.4942166 , 0.4968886 , 0.4973415 , 0.49706978,\n",
       "        0.49883604, 0.4997418 , 0.49992296, 0.50209683, 0.5025044 ,\n",
       "        0.5006702 , 0.500172  , 0.49899453, 0.49557525, 0.4845248 ,\n",
       "        0.4727497 , 0.46822086, 0.46989653, 0.47551233], dtype=float32),\n",
       " array([0.54503053, 0.5461175 , 0.5464571 , 0.54595894, 0.54541546,\n",
       "        0.5447588 , 0.5426302 , 0.54020727, 0.53753525, 0.5351123 ,\n",
       "        0.5329611 , 0.531693  , 0.53151184, 0.53207797, 0.5338895 ,\n",
       "        0.5361539 , 0.53884864, 0.5417018 , 0.5434001 , 0.5431284 ,\n",
       "        0.5429699 , 0.54283404, 0.5426755 , 0.5423132 , 0.5417018 ,\n",
       "        0.5401846 , 0.53733146, 0.5334366 , 0.52489966, 0.51536644,\n",
       "        0.50451976, 0.5037725 , 0.505335  , 0.5029573 , 0.49926627,\n",
       "        0.4959149 , 0.49582434, 0.4967754 , 0.49788496, 0.49138603,\n",
       "        0.48332465, 0.4764181 , 0.48056203, 0.4835058 , 0.48321143,\n",
       "        0.47983742, 0.47990534, 0.49204272, 0.4973415 , 0.49849635,\n",
       "        0.5006702 , 0.50139487, 0.50103253, 0.50166655, 0.49971914,\n",
       "        0.49442038, 0.4896424 , 0.4840719 , 0.456876  , 0.43826234,\n",
       "        0.41681814, 0.4080095 , 0.40993425, 0.41799566], dtype=float32),\n",
       " array([0.52451473, 0.5373541 , 0.540479  , 0.5410678 , 0.54161125,\n",
       "        0.542132  , 0.5415886 , 0.54054695, 0.53880334, 0.53715026,\n",
       "        0.53579164, 0.535384  , 0.5351349 , 0.5350217 , 0.53570104,\n",
       "        0.5369238 , 0.53835046, 0.5397091 , 0.5406375 , 0.54095453,\n",
       "        0.54084134, 0.5408187 , 0.54045635, 0.5400941 , 0.5396638 ,\n",
       "        0.5383957 , 0.536086  , 0.53305167, 0.5259413 , 0.5169968 ,\n",
       "        0.5063766 , 0.50506324, 0.5083014 , 0.5051991 , 0.50134957,\n",
       "        0.49793026, 0.49675274, 0.49566582, 0.4955526 , 0.49172568,\n",
       "        0.48210183, 0.4784108 , 0.4740631 , 0.45264152, 0.442678  ,\n",
       "        0.44217983, 0.45320764, 0.4588461 , 0.4854985 , 0.49149925,\n",
       "        0.49645838, 0.49430716, 0.49118224, 0.488714  , 0.4832567 ,\n",
       "        0.4598877 , 0.44535005, 0.43439016, 0.41829002, 0.4062885 ,\n",
       "        0.39813656, 0.39700434, 0.39863473, 0.39985752], dtype=float32),\n",
       " array([0.51910275, 0.5186046 , 0.53375363, 0.53635776, 0.5383731 ,\n",
       "        0.53977704, 0.5400941 , 0.5400941 , 0.5397544 , 0.53943735,\n",
       "        0.53918827, 0.5390298 , 0.5390298 , 0.5388713 , 0.5384863 ,\n",
       "        0.5388939 , 0.53923357, 0.53952795, 0.53943735, 0.5389392 ,\n",
       "        0.5380561 , 0.53787494, 0.5373541 , 0.5364936 , 0.53520286,\n",
       "        0.5333913 , 0.53105897, 0.529338  , 0.5249676 , 0.51794785,\n",
       "        0.51099604, 0.50667095, 0.51018083, 0.5061501 , 0.5028894 ,\n",
       "        0.5003985 , 0.49874544, 0.4977944 , 0.49756795, 0.49274468,\n",
       "        0.47847876, 0.4696248 , 0.46004623, 0.45200747, 0.44548592,\n",
       "        0.4456444 , 0.44888255, 0.455223  , 0.45866492, 0.4654356 ,\n",
       "        0.48067525, 0.46792647, 0.46158606, 0.45805353, 0.454204  ,\n",
       "        0.44845232, 0.44082117, 0.4274157 , 0.4162294 , 0.40721694,\n",
       "        0.40293714, 0.4010124 , 0.40141997, 0.40189552], dtype=float32),\n",
       " array([0.5169515 , 0.51366806, 0.5224541 , 0.52902097, 0.5333913 ,\n",
       "        0.53554255, 0.5365389 , 0.53733146, 0.53787494, 0.5380787 ,\n",
       "        0.5382372 , 0.5383731 , 0.5386448 , 0.5384863 , 0.5379655 ,\n",
       "        0.5379881 , 0.5379655 , 0.53782964, 0.5368785 , 0.5356784 ,\n",
       "        0.53427446, 0.5333913 , 0.5321685 , 0.53062874, 0.5273453 ,\n",
       "        0.52532995, 0.52422035, 0.5224994 , 0.5190348 , 0.51384926,\n",
       "        0.5104752 , 0.50558406, 0.50701064, 0.50413483, 0.50184774,\n",
       "        0.5001494 , 0.5008514 , 0.5009193 , 0.5003985 , 0.49435243,\n",
       "        0.4844795 , 0.47073436, 0.4615634 , 0.45610613, 0.45438513,\n",
       "        0.45248303, 0.4515999 , 0.45175838, 0.45474744, 0.45610613,\n",
       "        0.4638505 , 0.4559929 , 0.45454365, 0.45139608, 0.4473201 ,\n",
       "        0.4429271 , 0.43819442, 0.42961222, 0.42263776, 0.41729367,\n",
       "        0.41432726, 0.41040978, 0.40554124, 0.4059262 ], dtype=float32),\n",
       " array([0.51867247, 0.5140304 , 0.5112225 , 0.52211446, 0.5266207 ,\n",
       "        0.5289077 , 0.53049284, 0.5321006 , 0.53370833, 0.53443295,\n",
       "        0.535067  , 0.5356105 , 0.53570104, 0.5356784 , 0.5355199 ,\n",
       "        0.5358822 , 0.53579164, 0.53524816, 0.5309004 , 0.5267339 ,\n",
       "        0.5227485 , 0.52435625, 0.515457  , 0.5231787 , 0.5142795 ,\n",
       "        0.51790255, 0.51486826, 0.5144606 , 0.51314723, 0.51088285,\n",
       "        0.5073956 , 0.50540286, 0.5048821 , 0.50261766, 0.50048906,\n",
       "        0.49849635, 0.49999088, 0.501191  , 0.50214213, 0.4972509 ,\n",
       "        0.4895745 , 0.47909015, 0.4701456 , 0.4636014 , 0.45943484,\n",
       "        0.45400017, 0.45110172, 0.4507394 , 0.45259625, 0.45341143,\n",
       "        0.45316234, 0.4522792 , 0.4515999 , 0.45116964, 0.44535005,\n",
       "        0.44020978, 0.4357262 , 0.4308803 , 0.42718926, 0.42463046,\n",
       "        0.42152816, 0.41702193, 0.41113442, 0.4093002 ], dtype=float32),\n",
       " array([0.5233599 , 0.51824224, 0.51323783, 0.5154796 , 0.52186537,\n",
       "        0.5247185 , 0.52519405, 0.5264395 , 0.5286586 , 0.53044754,\n",
       "        0.5323497 , 0.53436506, 0.53529346, 0.5359728 , 0.53647095,\n",
       "        0.536086  , 0.53477263, 0.5324629 , 0.5227032 , 0.5165666 ,\n",
       "        0.5032064 , 0.5081881 , 0.50968266, 0.50947887, 0.51045257,\n",
       "        0.5105205 , 0.5097053 , 0.5095921 , 0.5088222 , 0.5073956 ,\n",
       "        0.50612754, 0.50495   , 0.50384045, 0.5009193 , 0.498202  ,\n",
       "        0.49571112, 0.49589226, 0.49686596, 0.49860957, 0.49824727,\n",
       "        0.49521294, 0.48943862, 0.48022237, 0.47123256, 0.4624918 ,\n",
       "        0.45424926, 0.44994685, 0.44958454, 0.453502  , 0.4548607 ,\n",
       "        0.45366052, 0.4522792 , 0.44999215, 0.44679928, 0.4422704 ,\n",
       "        0.4380812 , 0.43418637, 0.43414107, 0.43269184, 0.4298613 ,\n",
       "        0.42530978, 0.42125645, 0.41767862, 0.41502923], dtype=float32),\n",
       " array([0.5258055 , 0.5230202 , 0.51828754, 0.5144606 , 0.5109734 ,\n",
       "        0.5099091 , 0.5082787 , 0.509026  , 0.5223862 , 0.5264848 ,\n",
       "        0.53058344, 0.53463674, 0.53681064, 0.5378523 , 0.537807  ,\n",
       "        0.5370144 , 0.5345915 , 0.5305155 , 0.52014434, 0.51396245,\n",
       "        0.5001268 , 0.50748616, 0.5091166 , 0.5091166 , 0.50916183,\n",
       "        0.50913924, 0.50904864, 0.50793904, 0.50671625, 0.5053576 ,\n",
       "        0.50447446, 0.50350076, 0.50243646, 0.4998324 , 0.49704713,\n",
       "        0.49405807, 0.49260882, 0.49267676, 0.49426186, 0.4963225 ,\n",
       "        0.49607342, 0.4935146 , 0.4850909 , 0.4752859 , 0.4640543 ,\n",
       "        0.45372847, 0.44827116, 0.44765976, 0.4529812 , 0.45526826,\n",
       "        0.45458895, 0.452166  , 0.4487014 , 0.44419518, 0.44045886,\n",
       "        0.43722072, 0.4344581 , 0.43602055, 0.43504685, 0.43155962,\n",
       "        0.4268043 , 0.42401904, 0.4231812 , 0.42105263], dtype=float32),\n",
       " array([0.5246506 , 0.52349573, 0.51964617, 0.5138945 , 0.50866365,\n",
       "        0.5039763 , 0.5027988 , 0.5041122 , 0.51994056, 0.52591866,\n",
       "        0.5308552 , 0.5349991 , 0.5379655 , 0.5388939 , 0.53830516,\n",
       "        0.5370144 , 0.5329611 , 0.5237448 , 0.5165213 , 0.50972795,\n",
       "        0.50696534, 0.51022613, 0.510679  , 0.51070166, 0.5098865 ,\n",
       "        0.50879955, 0.50768995, 0.5065804 , 0.5051764 , 0.503931  ,\n",
       "        0.5034328 , 0.50232327, 0.50073814, 0.49817935, 0.49722826,\n",
       "        0.49577904, 0.49374104, 0.4926994 , 0.49235973, 0.49215594,\n",
       "        0.49288055, 0.49174833, 0.48719683, 0.47689363, 0.46649987,\n",
       "        0.45705718, 0.4539549 , 0.4519169 , 0.4519169 , 0.45445308,\n",
       "        0.4552456 , 0.45386434, 0.44738802, 0.4429724 , 0.4401192 ,\n",
       "        0.43744716, 0.4352733 , 0.43416372, 0.43167284, 0.42743835,\n",
       "        0.42352086, 0.42313594, 0.42329443, 0.42263776], dtype=float32),\n",
       " array([0.52105016, 0.5205746 , 0.5189895 , 0.5146418 , 0.5097053 ,\n",
       "        0.50442916, 0.50395364, 0.5055614 , 0.52145773, 0.5287039 ,\n",
       "        0.5339574 , 0.5375126 , 0.53859955, 0.53859955, 0.53753525,\n",
       "        0.53379893, 0.5304249 , 0.51731384, 0.5103394 , 0.508007  ,\n",
       "        0.5075541 , 0.5092071 , 0.5101356 , 0.5102488 , 0.50850517,\n",
       "        0.5065351 , 0.50472355, 0.50354606, 0.5016892 , 0.4999003 ,\n",
       "        0.49860957, 0.4965263 , 0.4939675 , 0.49079728, 0.4901406 ,\n",
       "        0.4889631 , 0.4865628 , 0.48624575, 0.48735532, 0.49007267,\n",
       "        0.49143133, 0.4907067 , 0.48778558, 0.47757298, 0.46894547,\n",
       "        0.46201628, 0.46092936, 0.45900458, 0.45653635, 0.45556265,\n",
       "        0.4532303 , 0.44999215, 0.44711632, 0.44489715, 0.44283652,\n",
       "        0.43950778, 0.43622437, 0.43319002, 0.4311294 , 0.42845735,\n",
       "        0.4262382 , 0.42650995, 0.42515126, 0.423068  ], dtype=float32),\n",
       " array([0.51575136, 0.51532114, 0.51532114, 0.51287556, 0.5117433 ,\n",
       "        0.5112225 , 0.5160231 , 0.5213672 , 0.52630365, 0.5312854 ,\n",
       "        0.5352255 , 0.53728616, 0.53753525, 0.5364936 , 0.5332781 ,\n",
       "        0.5302664 , 0.52018964, 0.512717  , 0.50787115, 0.5058558 ,\n",
       "        0.50549346, 0.50574255, 0.5060143 , 0.50599164, 0.5045877 ,\n",
       "        0.5025497 , 0.5011684 , 0.5012363 , 0.5005117 , 0.4984737 ,\n",
       "        0.4953035 , 0.49072933, 0.48563436, 0.48117343, 0.47786734,\n",
       "        0.46969274, 0.46391842, 0.46165398, 0.4642128 , 0.47648603,\n",
       "        0.48563436, 0.48973298, 0.48654014, 0.47961095, 0.47295353,\n",
       "        0.46831143, 0.4638505 , 0.4597745 , 0.4567628 , 0.45710248,\n",
       "        0.45510978, 0.45132816, 0.4463464 , 0.44530475, 0.44351584,\n",
       "        0.4408891 , 0.43774155, 0.43529594, 0.43196723, 0.42700812,\n",
       "        0.4218452 , 0.42356616, 0.4264873 , 0.4250154 ], dtype=float32),\n",
       " array([0.5133058 , 0.5123774 , 0.511698  , 0.51298875, 0.5134869 ,\n",
       "        0.51527584, 0.51706475, 0.52243143, 0.5281378 , 0.5329384 ,\n",
       "        0.5352255 , 0.53475   , 0.53198737, 0.5267565 , 0.52410716,\n",
       "        0.52206916, 0.51366806, 0.5094562 , 0.5068748 , 0.5052897 ,\n",
       "        0.50451976, 0.50399894, 0.5037725 , 0.50354606, 0.5022553 ,\n",
       "        0.49969652, 0.49740943, 0.49614134, 0.49444303, 0.49048024,\n",
       "        0.48513618, 0.4799959 , 0.47904485, 0.4793166 , 0.47979212,\n",
       "        0.47614637, 0.46763209, 0.4592084 , 0.45741948, 0.46631873,\n",
       "        0.47562554, 0.48332465, 0.4855438 , 0.48257738, 0.47798055,\n",
       "        0.4740631 , 0.4693757 , 0.46443924, 0.4595254 , 0.45563057,\n",
       "        0.4525736 , 0.4489505 , 0.4440593 , 0.44179487, 0.4399607 ,\n",
       "        0.438285  , 0.43622437, 0.43472984, 0.4320578 , 0.4277554 ,\n",
       "        0.42284155, 0.4250607 , 0.42660052, 0.4172484 ], dtype=float32),\n",
       " array([0.50374985, 0.50069284, 0.49874544, 0.5030479 , 0.5055614 ,\n",
       "        0.5075994 , 0.51206034, 0.52431095, 0.5280699 , 0.5324176 ,\n",
       "        0.5310816 , 0.5281378 , 0.5231787 , 0.52141243, 0.516476  ,\n",
       "        0.5119471 , 0.50859576, 0.5062634 , 0.50476885, 0.50379515,\n",
       "        0.5032064 , 0.50293463, 0.5023912 , 0.50146276, 0.4995833 ,\n",
       "        0.49414864, 0.48665336, 0.47755033, 0.46894547, 0.4621295 ,\n",
       "        0.45769122, 0.45784974, 0.46403164, 0.4692172 , 0.47148165,\n",
       "        0.4716175 , 0.4711646 , 0.47093818, 0.47211567, 0.47404045,\n",
       "        0.4763049 , 0.478909  , 0.481966  , 0.4796789 , 0.474833  ,\n",
       "        0.4690134 , 0.46770003, 0.46425807, 0.45866492, 0.45189425,\n",
       "        0.44849762, 0.44657284, 0.44546327, 0.44265535, 0.44095704,\n",
       "        0.43987012, 0.43842086, 0.43753773, 0.4360432 , 0.43330324,\n",
       "        0.42528713, 0.42127907, 0.4191505 , 0.41672757], dtype=float32),\n",
       " array([0.5027535 , 0.5013269 , 0.49867752, 0.5029573 , 0.50782585,\n",
       "        0.52023494, 0.5256017 , 0.5298588 , 0.53198737, 0.52990407,\n",
       "        0.5258734 , 0.5213898 , 0.51930654, 0.5144833 , 0.5118792 ,\n",
       "        0.50986385, 0.5082787 , 0.5074182 , 0.5067842 , 0.50594634,\n",
       "        0.50447446, 0.5032743 , 0.5022327 , 0.50175714, 0.50359136,\n",
       "        0.4987681 , 0.48751384, 0.4691266 , 0.46194836, 0.4569213 ,\n",
       "        0.45440778, 0.45592496, 0.46138224, 0.46468833, 0.46428072,\n",
       "        0.4627409 , 0.46276355, 0.4641675 , 0.46715656, 0.47173074,\n",
       "        0.473814  , 0.47317997, 0.47252327, 0.47159487, 0.46824348,\n",
       "        0.4602274 , 0.45105642, 0.4450783 , 0.4419081 , 0.43987012,\n",
       "        0.4388964 , 0.43790004, 0.4363376 , 0.4284347 , 0.426442  ,\n",
       "        0.42902344, 0.4344581 , 0.43597528, 0.43597528, 0.43488833,\n",
       "        0.43155962, 0.4287291 , 0.4255815 , 0.42107528], dtype=float32),\n",
       " array([0.5434001 , 0.5460269 , 0.5453023 , 0.5450985 , 0.54507583,\n",
       "        0.545189  , 0.5453702 , 0.5373541 , 0.53379893, 0.5285228 ,\n",
       "        0.5285228 , 0.52630365, 0.52256733, 0.517812  , 0.51371336,\n",
       "        0.5101582 , 0.50710124, 0.503931  , 0.502278  , 0.50125897,\n",
       "        0.50033057, 0.4955073 , 0.49072933, 0.48780823, 0.49288055,\n",
       "        0.49548465, 0.4938769 , 0.48674393, 0.4701909 , 0.46251446,\n",
       "        0.46228802, 0.46824348, 0.46606964, 0.46183515, 0.45714775,\n",
       "        0.4525283 , 0.44976568, 0.44781828, 0.4456897 , 0.45049033,\n",
       "        0.4565137 , 0.46190307, 0.45954806, 0.4535926 , 0.44591615,\n",
       "        0.43753773, 0.43208045, 0.4283894 , 0.42662317, 0.4281177 ,\n",
       "        0.43092558, 0.4297481 , 0.42175463, 0.40218988, 0.3928604 ,\n",
       "        0.3936756 , 0.40721694, 0.4165917 , 0.42528713, 0.43371084,\n",
       "        0.43371084, 0.43085766, 0.42641935, 0.42161876], dtype=float32),\n",
       " array([0.56402916, 0.5643688 , 0.56350833, 0.5623761 , 0.5610401 ,\n",
       "        0.5591606 , 0.55601305, 0.5447588 , 0.5403884 , 0.5340254 ,\n",
       "        0.5322138 , 0.5297682 , 0.5262357 , 0.52071047, 0.5136907 ,\n",
       "        0.5070786 , 0.5012816 , 0.4973415 , 0.49521294, 0.49340138,\n",
       "        0.49077463, 0.48078847, 0.47057587, 0.4624692 , 0.46434867,\n",
       "        0.47164014, 0.47816172, 0.48103756, 0.46824348, 0.46527708,\n",
       "        0.46908134, 0.47481036, 0.46428072, 0.45300382, 0.44523683,\n",
       "        0.4432894 , 0.44596145, 0.44840702, 0.44417253, 0.44041356,\n",
       "        0.44000596, 0.442678  , 0.44392344, 0.4364055 , 0.42662317,\n",
       "        0.418992  , 0.428797  , 0.43420902, 0.43484306, 0.43330324,\n",
       "        0.43319002, 0.43217102, 0.4290461 , 0.4228642 , 0.41570857,\n",
       "        0.40846238, 0.403073  , 0.40083122, 0.402756  , 0.40945873,\n",
       "        0.4222528 , 0.42850265, 0.4287291 , 0.4218905 ], dtype=float32),\n",
       " array([0.5711621 , 0.56996197, 0.5681504 , 0.56536514, 0.5606551 ,\n",
       "        0.5555828 , 0.5531146 , 0.54084134, 0.53923357, 0.5339348 ,\n",
       "        0.52927005, 0.52442414, 0.5188989 , 0.5118792 , 0.5037725 ,\n",
       "        0.49643573, 0.49043497, 0.4882611 , 0.4860193 , 0.48323405,\n",
       "        0.47936186, 0.4710061 , 0.46627343, 0.46527708, 0.4674736 ,\n",
       "        0.46890017, 0.47030413, 0.4720251 , 0.467066  , 0.46794912,\n",
       "        0.4728403 , 0.47863725, 0.47358757, 0.46541294, 0.45637783,\n",
       "        0.45332086, 0.45372847, 0.4546116 , 0.45212072, 0.44700307,\n",
       "        0.44102496, 0.4353186 , 0.43574885, 0.43350706, 0.43076706,\n",
       "        0.4290461 , 0.43314472, 0.4345034 , 0.43355232, 0.43314472,\n",
       "        0.43468454, 0.43577147, 0.4352733 , 0.4338014 , 0.43063122,\n",
       "        0.4234756 , 0.4061753 , 0.39077714, 0.3818326 , 0.38137972,\n",
       "        0.39686847, 0.4118817 , 0.4221622 , 0.42080355], dtype=float32),\n",
       " array([0.5602249 , 0.55714524, 0.5528202 , 0.5492877 , 0.51987267,\n",
       "        0.5167477 , 0.5203482 , 0.520869  , 0.5216163 , 0.5227485 ,\n",
       "        0.5199179 , 0.514121  , 0.506988  , 0.5002173 , 0.49371842,\n",
       "        0.48817053, 0.48380017, 0.481264  , 0.47981477, 0.47788998,\n",
       "        0.47415367, 0.47241005, 0.4749915 , 0.4796336 , 0.47788998,\n",
       "        0.47114196, 0.46577525, 0.4648242 , 0.47168544, 0.47816172,\n",
       "        0.48169425, 0.47573876, 0.46792647, 0.46215215, 0.45938954,\n",
       "        0.45637783, 0.4535926 , 0.45107907, 0.44897315, 0.44535005,\n",
       "        0.44086647, 0.43595263, 0.43269184, 0.4292046 , 0.42877436,\n",
       "        0.4346619 , 0.4343449 , 0.43051797, 0.42544565, 0.42666844,\n",
       "        0.42723456, 0.42673638, 0.42490217, 0.42333972, 0.41971663,\n",
       "        0.41369322, 0.4039788 , 0.39569095, 0.39256603, 0.39578155,\n",
       "        0.403073  , 0.41047773, 0.41566327, 0.414916  ], dtype=float32),\n",
       " array([0.5397544 , 0.5345915 , 0.52816045, 0.5025497 , 0.50205153,\n",
       "        0.50166655, 0.50214213, 0.5021874 , 0.50261766, 0.5035234 ,\n",
       "        0.50205153, 0.49890396, 0.4949412 , 0.4911596 , 0.48814788,\n",
       "        0.48622313, 0.48522675, 0.48341522, 0.48275852, 0.4818754 ,\n",
       "        0.47958833, 0.4794751 , 0.48121873, 0.48291704, 0.4773918 ,\n",
       "        0.47114196, 0.4654809 , 0.46111053, 0.46758682, 0.474833  ,\n",
       "        0.47854668, 0.4681982 , 0.45827997, 0.45243773, 0.4515546 ,\n",
       "        0.44978833, 0.44883728, 0.44879198, 0.44990155, 0.44550854,\n",
       "        0.44172695, 0.4393493 , 0.43765095, 0.43253332, 0.42895553,\n",
       "        0.43110675, 0.42995188, 0.42825356, 0.42696282, 0.42943105,\n",
       "        0.42601177, 0.4208715 , 0.41568592, 0.41403288, 0.41156465,\n",
       "        0.40671876, 0.39537394, 0.39451346, 0.40012926, 0.41063625,\n",
       "        0.41136086, 0.409187  , 0.40524688, 0.40042362], dtype=float32),\n",
       " array([0.4879441 , 0.4870383 , 0.48454744, 0.4839134 , 0.4870383 ,\n",
       "        0.49158984, 0.49265411, 0.4915219 , 0.49048024, 0.49000472,\n",
       "        0.48807997, 0.48511353, 0.4818754 , 0.47920337, 0.4798827 ,\n",
       "        0.4820339 , 0.4849324 , 0.48490974, 0.48404926, 0.4822377 ,\n",
       "        0.47920337, 0.48133194, 0.48380017, 0.48552114, 0.48368695,\n",
       "        0.4816716 , 0.47752768, 0.47016826, 0.47032678, 0.47367814,\n",
       "        0.47639546, 0.469738  , 0.4614049 , 0.45370582, 0.44729745,\n",
       "        0.4425648 , 0.4426327 , 0.44498774, 0.44720688, 0.44383287,\n",
       "        0.44082117, 0.43916813, 0.43989274, 0.43717542, 0.43178606,\n",
       "        0.42365673, 0.4133762 , 0.41034186, 0.414599  , 0.4256268 ,\n",
       "        0.42662317, 0.42238867, 0.41448578, 0.41233456, 0.41369322,\n",
       "        0.41573122, 0.41249308, 0.4099116 , 0.40728486, 0.40461284,\n",
       "        0.40504307, 0.40178227, 0.3964835 , 0.39057332], dtype=float32),\n",
       " array([0.46280885, 0.46638665, 0.46430337, 0.46951157, 0.4764181 ,\n",
       "        0.48282647, 0.48552114, 0.48416248, 0.48257738, 0.481264  ,\n",
       "        0.47940716, 0.47530854, 0.47193453, 0.47066644, 0.47295353,\n",
       "        0.4783655 , 0.484321  , 0.48780823, 0.48774028, 0.48443422,\n",
       "        0.48151308, 0.48248678, 0.48400396, 0.4854985 , 0.4839813 ,\n",
       "        0.48087904, 0.47696158, 0.4786599 , 0.47709745, 0.47057587,\n",
       "        0.4591631 , 0.45628726, 0.45454365, 0.4505356 , 0.44145522,\n",
       "        0.437266  , 0.43912286, 0.44317618, 0.44539532, 0.44442162,\n",
       "        0.44337997, 0.4425195 , 0.4420213 , 0.4399607 , 0.43697163,\n",
       "        0.42999718, 0.4165917 , 0.4045449 , 0.40257484, 0.410523  ,\n",
       "        0.41620675, 0.41670492, 0.41602558, 0.41772392, 0.42207164,\n",
       "        0.4251739 , 0.4206224 , 0.41450843, 0.4060168 , 0.40110296,\n",
       "        0.39838564, 0.3940379 , 0.38964492, 0.38366678], dtype=float32),\n",
       " array([0.44473866, 0.4476824 , 0.4492675 , 0.45565322, 0.46299   ,\n",
       "        0.46953422, 0.47354227, 0.47254592, 0.47091553, 0.469421  ,\n",
       "        0.4688096 , 0.46708864, 0.46683955, 0.468402  , 0.4720251 ,\n",
       "        0.47974682, 0.48635897, 0.49027646, 0.49002737, 0.48620048,\n",
       "        0.48280382, 0.4806073 , 0.48042616, 0.48316613, 0.4790222 ,\n",
       "        0.47087023, 0.46169928, 0.47290823, 0.47048527, 0.45769122,\n",
       "        0.43780947, 0.44143257, 0.442678  , 0.44000596, 0.43192193,\n",
       "        0.4351148 , 0.44061738, 0.44548592, 0.44682193, 0.44641432,\n",
       "        0.44555384, 0.4445575 , 0.44371966, 0.44050413, 0.4401192 ,\n",
       "        0.43973425, 0.43654138, 0.42712134, 0.42019215, 0.41514248,\n",
       "        0.4112929 , 0.40468076, 0.40696785, 0.41588974, 0.4292046 ,\n",
       "        0.43377876, 0.4300651 , 0.4206224 , 0.4079642 , 0.40085387,\n",
       "        0.39630234, 0.39299628, 0.38964492, 0.38964492], dtype=float32),\n",
       " array([0.4403909 , 0.44181752, 0.44439897, 0.4486561 , 0.45356995,\n",
       "        0.45791766, 0.46040854, 0.4594575 , 0.4569666 , 0.4552456 ,\n",
       "        0.45658165, 0.45984244, 0.4634882 , 0.46797177, 0.47383666,\n",
       "        0.48112813, 0.4859061 , 0.48792145, 0.48694775, 0.48296234,\n",
       "        0.47958833, 0.47745976, 0.47721067, 0.47492358, 0.4650733 ,\n",
       "        0.45463422, 0.45060354, 0.46618286, 0.4618578 , 0.44720688,\n",
       "        0.431854  , 0.43366554, 0.43192193, 0.42988396, 0.4307897 ,\n",
       "        0.44014183, 0.44478393, 0.4459841 , 0.4450783 , 0.4456897 ,\n",
       "        0.44546327, 0.44514623, 0.4455312 , 0.44485188, 0.44448957,\n",
       "        0.44331205, 0.44014183, 0.43880582, 0.43842086, 0.43760568,\n",
       "        0.4350695 , 0.42503804, 0.4227736 , 0.42773274, 0.43953043,\n",
       "        0.4410476 , 0.4383982 , 0.4314917 , 0.42035067, 0.40896055,\n",
       "        0.40554124, 0.4049072 , 0.40189552, 0.401035  ], dtype=float32),\n",
       " array([0.44385552, 0.4449198 , 0.44347057, 0.44539532, 0.44849762,\n",
       "        0.45116964, 0.45180368, 0.4496298 , 0.4462558 , 0.445735  ,\n",
       "        0.45212072, 0.45705718, 0.4631485 , 0.4699871 , 0.47714272,\n",
       "        0.48248678, 0.48518148, 0.4852494 , 0.48282647, 0.47940716,\n",
       "        0.4783655 , 0.4776409 , 0.47517267, 0.46206158, 0.4479315 ,\n",
       "        0.4417043 , 0.45234716, 0.4615181 , 0.44842967, 0.43099353,\n",
       "        0.42703074, 0.42834413, 0.42825356, 0.43099353, 0.4407306 ,\n",
       "        0.4436517 , 0.44403666, 0.44376493, 0.44473866, 0.4460973 ,\n",
       "        0.4456218 , 0.44514623, 0.4465955 , 0.44999215, 0.44679928,\n",
       "        0.44018713, 0.4332806 , 0.42968014, 0.4297707 , 0.431854  ,\n",
       "        0.43411845, 0.42524186, 0.416954  , 0.41358   , 0.41942224,\n",
       "        0.43223897, 0.43968895, 0.43973425, 0.43031418, 0.41942224,\n",
       "        0.41416875, 0.41136086, 0.4077604 , 0.40119353], dtype=float32),\n",
       " array([0.44784093, 0.4476371 , 0.44091174, 0.44041356, 0.44294974,\n",
       "        0.44582558, 0.44627845, 0.4425195 , 0.44324413, 0.44673136,\n",
       "        0.45128286, 0.4593669 , 0.46663573, 0.47338375, 0.47990534,\n",
       "        0.48253208, 0.48212448, 0.47981477, 0.47668985, 0.4804035 ,\n",
       "        0.4816263 , 0.47956568, 0.47351962, 0.46346554, 0.45302647,\n",
       "        0.4492449 , 0.45923105, 0.4604991 , 0.4487014 , 0.43769625,\n",
       "        0.44138727, 0.44331205, 0.4476824 , 0.4512602 , 0.44994685,\n",
       "        0.43740186, 0.42761952, 0.41869763, 0.41638792, 0.41727102,\n",
       "        0.41964868, 0.4218452 , 0.4222528 , 0.42173198, 0.4155727 ,\n",
       "        0.4082586 , 0.40418258, 0.39134324, 0.3795455 , 0.37091804,\n",
       "        0.36765724, 0.36450967, 0.36598155, 0.37046513, 0.3764206 ,\n",
       "        0.40098974, 0.42195842, 0.43300885, 0.42791387, 0.41969398,\n",
       "        0.41208547, 0.4056092 , 0.40085387, 0.39548716], dtype=float32),\n",
       " array([0.4499695 , 0.4482938 , 0.4429724 , 0.43993804, 0.43957573,\n",
       "        0.44061738, 0.44177222, 0.44516888, 0.4479768 , 0.4525736 ,\n",
       "        0.46138224, 0.46760947, 0.4734517 , 0.47752768, 0.47838816,\n",
       "        0.47451597, 0.4732932 , 0.47399515, 0.47587463, 0.4830529 ,\n",
       "        0.48341522, 0.4776862 , 0.46663573, 0.45621935, 0.4472748 ,\n",
       "        0.44247422, 0.4445122 , 0.43984747, 0.4407306 , 0.4483391 ,\n",
       "        0.46391842, 0.44944867, 0.44000596, 0.43285036, 0.424087  ,\n",
       "        0.4043411 , 0.3882636 , 0.37950024, 0.38432348, 0.38767484,\n",
       "        0.39175084, 0.39458138, 0.39419642, 0.39002988, 0.3907545 ,\n",
       "        0.39127532, 0.3864747 , 0.36752138, 0.3493153 , 0.33473232,\n",
       "        0.32658035, 0.3389442 , 0.36084127, 0.38470843, 0.40298244,\n",
       "        0.41595766, 0.42361146, 0.42596647, 0.4231133 , 0.41545948,\n",
       "        0.4056092 , 0.3979101 , 0.39666465, 0.395306  ], dtype=float32),\n",
       " array([0.44901842, 0.44412723, 0.441659  , 0.44417253, 0.4462558 ,\n",
       "        0.44775033, 0.44845232, 0.45121494, 0.45465687, 0.46009153,\n",
       "        0.4687643 , 0.4744254 , 0.4798827 , 0.48307556, 0.48194334,\n",
       "        0.47164014, 0.47127783, 0.4763049 , 0.4820792 , 0.48336992,\n",
       "        0.4810149 , 0.47204775, 0.45352465, 0.43468454, 0.42895553,\n",
       "        0.43375614, 0.44643697, 0.44587088, 0.44566706, 0.44770506,\n",
       "        0.4539549 , 0.42780066, 0.41462165, 0.40726224, 0.39863473,\n",
       "        0.36992168, 0.34913415, 0.33692884, 0.3338945 , 0.33020344,\n",
       "        0.33717793, 0.34424296, 0.34082365, 0.31865484, 0.31405804,\n",
       "        0.32128158, 0.33459646, 0.33984995, 0.33996317, 0.3338492 ,\n",
       "        0.32044375, 0.33271697, 0.37540162, 0.41795036, 0.4298613 ,\n",
       "        0.4316955 , 0.42816296, 0.42263776, 0.4184259 , 0.40891525,\n",
       "        0.40468076, 0.40207666, 0.397344  , 0.39965373], dtype=float32),\n",
       " array([0.4370622 , 0.4381265 , 0.44188544, 0.44684458, 0.4519169 ,\n",
       "        0.45547208, 0.4559023 , 0.4547701 , 0.45474744, 0.4585517 ,\n",
       "        0.46896812, 0.47770885, 0.48343787, 0.48633635, 0.4865628 ,\n",
       "        0.48194334, 0.48151308, 0.48357373, 0.48642692, 0.48633635,\n",
       "        0.47582936, 0.4563552 , 0.42931783, 0.4344581 , 0.44806737,\n",
       "        0.4496298 , 0.41860706, 0.4161841 , 0.40126148, 0.3806551 ,\n",
       "        0.36127153, 0.3550217 , 0.35456878, 0.35989022, 0.37094066,\n",
       "        0.35359508, 0.33235466, 0.3105255 , 0.29141366, 0.33319253,\n",
       "        0.36188293, 0.36822334, 0.3428843 , 0.32141745, 0.31702444,\n",
       "        0.33437002, 0.37809628, 0.3828969 , 0.3699443 , 0.3617244 ,\n",
       "        0.38072303, 0.36767986, 0.38572744, 0.4133762 , 0.42906874,\n",
       "        0.42773274, 0.42816296, 0.427461  , 0.42272833, 0.42191312,\n",
       "        0.42671373, 0.42367938, 0.39942726, 0.3984309 ], dtype=float32),\n",
       " array([0.44408196, 0.44324413, 0.44718423, 0.45105642, 0.4549739 ,\n",
       "        0.4593669 , 0.46219745, 0.4591178 , 0.45572117, 0.4585517 ,\n",
       "        0.46496007, 0.47211567, 0.4770748 , 0.48303026, 0.485974  ,\n",
       "        0.4868798 , 0.48547584, 0.48017707, 0.4872874 , 0.48617783,\n",
       "        0.46996447, 0.44580293, 0.43491098, 0.45857435, 0.45943484,\n",
       "        0.4199657 , 0.35767108, 0.32494998, 0.317115  , 0.31453356,\n",
       "        0.32420272, 0.34041607, 0.34458262, 0.34619036, 0.331698  ,\n",
       "        0.31457886, 0.2959199 , 0.26439893, 0.311386  , 0.38233078,\n",
       "        0.39695904, 0.3497229 , 0.3098688 , 0.32637656, 0.36555132,\n",
       "        0.40207666, 0.4182221 , 0.40366176, 0.357739  , 0.3594147 ,\n",
       "        0.36618534, 0.36163384, 0.35536134, 0.38946375, 0.41068152,\n",
       "        0.41987514, 0.42223015, 0.42739305, 0.4205771 , 0.41068152,\n",
       "        0.40461284, 0.40305036, 0.40042362, 0.400718  ], dtype=float32),\n",
       " array([0.45640048, 0.45837054, 0.4589593 , 0.45483804, 0.45472482,\n",
       "        0.45336616, 0.45035446, 0.45006007, 0.45105642, 0.45551735,\n",
       "        0.45943484, 0.46271828, 0.46923983, 0.47822964, 0.47619167,\n",
       "        0.4744707 , 0.47530854, 0.47179866, 0.4865175 , 0.48382282,\n",
       "        0.46708864, 0.44392344, 0.42610234, 0.39931405, 0.35819188,\n",
       "        0.32544816, 0.31376365, 0.32569724, 0.31641304, 0.34003112,\n",
       "        0.37648854, 0.40232575, 0.39079976, 0.36471346, 0.32576516,\n",
       "        0.29512733, 0.27762324, 0.26186278, 0.3117483 , 0.37424675,\n",
       "        0.38002107, 0.33941972, 0.3425899 , 0.40689993, 0.4350242 ,\n",
       "        0.44349322, 0.43916813, 0.41917315, 0.36532485, 0.3730013 ,\n",
       "        0.3915244 , 0.39868   , 0.4006727 , 0.40945873, 0.41151938,\n",
       "        0.4128554 , 0.41478014, 0.41391966, 0.41308182, 0.41645584,\n",
       "        0.4143952 , 0.4072396 , 0.40529215, 0.40284657], dtype=float32),\n",
       " array([0.457895  , 0.46133697, 0.46052176, 0.45538148, 0.45010537,\n",
       "        0.44616523, 0.4450783 , 0.44845232, 0.44433105, 0.44439897,\n",
       "        0.44428575, 0.44611996, 0.4584385 , 0.46690747, 0.4595707 ,\n",
       "        0.46029532, 0.4716628 , 0.47519532, 0.48751384, 0.48486444,\n",
       "        0.4711646 , 0.4543172 , 0.4463011 , 0.37150678, 0.30823842,\n",
       "        0.28851518, 0.29999587, 0.28593373, 0.2724377 , 0.328958  ,\n",
       "        0.3924528 , 0.424087  , 0.40909642, 0.3933133 , 0.36047897,\n",
       "        0.34331456, 0.34689236, 0.34868127, 0.41068152, 0.42141494,\n",
       "        0.41896936, 0.42487955, 0.44419518, 0.45809883, 0.46124637,\n",
       "        0.46233332, 0.46158606, 0.44913164, 0.42168668, 0.41022864,\n",
       "        0.4043411 , 0.40207666, 0.40615264, 0.40762454, 0.4083265 ,\n",
       "        0.40984368, 0.41244778, 0.4151651 , 0.41568592, 0.41534626,\n",
       "        0.41575387, 0.41661435, 0.41575387, 0.4099569 ], dtype=float32),\n",
       " array([0.46203893, 0.46034062, 0.45569852, 0.4523698 , 0.4476824 ,\n",
       "        0.44555384, 0.4463011 , 0.44668606, 0.4417043 , 0.442678  ,\n",
       "        0.4401192 , 0.43599793, 0.44381022, 0.45388696, 0.45105642,\n",
       "        0.45304912, 0.46260506, 0.4674736 , 0.48275852, 0.4842304 ,\n",
       "        0.47422162, 0.4579856 , 0.44371966, 0.3565162 , 0.31177095,\n",
       "        0.29256853, 0.28486943, 0.27755532, 0.33215088, 0.397344  ,\n",
       "        0.43362027, 0.4353639 , 0.43090293, 0.43069914, 0.43031418,\n",
       "        0.43056327, 0.43559033, 0.4529359 , 0.45751005, 0.44396874,\n",
       "        0.43620172, 0.44193074, 0.4526189 , 0.4654809 , 0.47363284,\n",
       "        0.5092071 , 0.51434743, 0.50562936, 0.4381265 , 0.4139876 ,\n",
       "        0.3935171 , 0.383146  , 0.39578155, 0.40585828, 0.41278744,\n",
       "        0.41267422, 0.40997955, 0.41742954, 0.4314917 , 0.42515126,\n",
       "        0.41783714, 0.41731632, 0.41969398, 0.41706723], dtype=float32),\n",
       " array([0.4655488 , 0.45674017, 0.45166782, 0.45198485, 0.4502186 ,\n",
       "        0.45044503, 0.45230186, 0.45105642, 0.44861084, 0.44867876,\n",
       "        0.44147786, 0.42968014, 0.42841205, 0.444716  , 0.45026386,\n",
       "        0.44881463, 0.44707102, 0.4546116 , 0.4769842 , 0.4772333 ,\n",
       "        0.4608388 , 0.4320578 , 0.39392468, 0.3328755 , 0.31125012,\n",
       "        0.28849253, 0.2790725 , 0.35259873, 0.41774657, 0.44313088,\n",
       "        0.43722072, 0.42010158, 0.42345294, 0.438285  , 0.44086647,\n",
       "        0.44249687, 0.44906372, 0.46126902, 0.45026386, 0.44156843,\n",
       "        0.43597528, 0.43479776, 0.4399154 , 0.5097053 , 0.51892155,\n",
       "        0.5241298 , 0.52494496, 0.5117886 , 0.4499695 , 0.42804974,\n",
       "        0.4508979 , 0.4069452 , 0.40155584, 0.40624323, 0.41145143,\n",
       "        0.41410083, 0.41473487, 0.41767862, 0.43085766, 0.42544565,\n",
       "        0.41951284, 0.4185165 , 0.41534626, 0.416637  ], dtype=float32),\n",
       " array([0.4572157 , 0.456242  , 0.45723835, 0.45447573, 0.45424926,\n",
       "        0.4551324 , 0.45506448, 0.45144138, 0.44439897, 0.4410929 ,\n",
       "        0.43529594, 0.42700812, 0.42254716, 0.4334844 , 0.43851143,\n",
       "        0.4374698 , 0.43823972, 0.4568534 , 0.47949773, 0.46996447,\n",
       "        0.43851143, 0.39358503, 0.34193325, 0.29940712, 0.2691316 ,\n",
       "        0.26666337, 0.30801198, 0.40968516, 0.43151432, 0.42352086,\n",
       "        0.415618  , 0.41838062, 0.42295477, 0.43805856, 0.4371075 ,\n",
       "        0.43309945, 0.43217102, 0.43352968, 0.4327145 , 0.4333259 ,\n",
       "        0.43183136, 0.4291593 , 0.43074444, 0.4674736 , 0.5214351 ,\n",
       "        0.5272094 , 0.52630365, 0.52012175, 0.50307053, 0.4994248 ,\n",
       "        0.46389577, 0.47811642, 0.40701315, 0.39043745, 0.4023031 ,\n",
       "        0.41478014, 0.4179277 , 0.41962606, 0.42723456, 0.42689487,\n",
       "        0.4211885 , 0.41502923, 0.41564065, 0.41543683], dtype=float32),\n",
       " array([0.45157725, 0.45112434, 0.4573742 , 0.45270947, 0.45200747,\n",
       "        0.45284534, 0.45284534, 0.44953924, 0.44254214, 0.43599793,\n",
       "        0.43497893, 0.43660933, 0.42992923, 0.42755157, 0.4298613 ,\n",
       "        0.43855673, 0.4548154 , 0.4793166 , 0.48438892, 0.457895  ,\n",
       "        0.42732513, 0.4023031 , 0.3745864 , 0.3051135 , 0.26879194,\n",
       "        0.26904103, 0.30699298, 0.3814703 , 0.38991663, 0.4030051 ,\n",
       "        0.4241323 , 0.44249687, 0.4331221 , 0.42832148, 0.42356616,\n",
       "        0.42795917, 0.43823972, 0.43862468, 0.4344581 , 0.43325797,\n",
       "        0.42963487, 0.42585325, 0.43187666, 0.5004664 , 0.5185819 ,\n",
       "        0.5282284 , 0.5285228 , 0.53065133, 0.5186046 , 0.52039343,\n",
       "        0.51600045, 0.50057966, 0.42019215, 0.37051043, 0.3732051 ,\n",
       "        0.39199993, 0.39695904, 0.36450967, 0.3772358 , 0.402054  ,\n",
       "        0.41446313, 0.41237986, 0.41611618, 0.4178145 ], dtype=float32),\n",
       " array([0.45438513, 0.45193955, 0.45411342, 0.45255095, 0.45039973,\n",
       "        0.44908637, 0.44759184, 0.4423157 , 0.43620172, 0.42956692,\n",
       "        0.42929518, 0.43300885, 0.42918196, 0.43160492, 0.4408891 ,\n",
       "        0.457578  , 0.47920337, 0.50028527, 0.49113694, 0.45707983,\n",
       "        0.43167284, 0.42478895, 0.42254716, 0.36149797, 0.30740058,\n",
       "        0.28391838, 0.29671246, 0.33344162, 0.34322396, 0.40121618,\n",
       "        0.45162252, 0.53201   , 0.467383  , 0.4554947 , 0.4515546 ,\n",
       "        0.44116083, 0.42492482, 0.41982985, 0.4283894 , 0.43167284,\n",
       "        0.42870644, 0.42410964, 0.42809504, 0.445033  , 0.5014401 ,\n",
       "        0.52757174, 0.53096837, 0.5286134 , 0.52757174, 0.5248544 ,\n",
       "        0.52091426, 0.51405305, 0.4477277 , 0.39804596, 0.38772014,\n",
       "        0.388173  , 0.37195966, 0.2927044 , 0.32397625, 0.3623811 ,\n",
       "        0.38074568, 0.38400647, 0.40925494, 0.41385174], dtype=float32),\n",
       " array([0.45520034, 0.45433986, 0.4557438 , 0.45501918, 0.45540413,\n",
       "        0.45547208, 0.45341143, 0.44693515, 0.4340958 , 0.43561298,\n",
       "        0.43656403, 0.43314472, 0.4327145 , 0.4387379 , 0.4451236 ,\n",
       "        0.45662692, 0.47607845, 0.5043386 , 0.49342403, 0.4584385 ,\n",
       "        0.43194458, 0.4255815 , 0.43015566, 0.3991329 , 0.3633548 ,\n",
       "        0.34927002, 0.3590524 , 0.37069157, 0.39560038, 0.43651873,\n",
       "        0.5462986 , 0.55796045, 0.56024754, 0.5552205 , 0.5502387 ,\n",
       "        0.4787052 , 0.44276857, 0.42530978, 0.42784595, 0.42999718,\n",
       "        0.42723456, 0.42150554, 0.42125645, 0.4277554 , 0.48543057,\n",
       "        0.52942854, 0.537105  , 0.53069663, 0.52990407, 0.52723205,\n",
       "        0.525262  , 0.5205067 , 0.5033876 , 0.4467087 , 0.43298623,\n",
       "        0.42069033, 0.3918414 , 0.3068345 , 0.31555256, 0.31849632,\n",
       "        0.3246103 , 0.3452393 , 0.39421907, 0.39537394], dtype=float32),\n",
       " array([0.46337494, 0.4601368 , 0.4584385 , 0.4591178 , 0.46081614,\n",
       "        0.46346554, 0.4654356 , 0.4636014 , 0.45479274, 0.44661814,\n",
       "        0.43948516, 0.43586206, 0.4402777 , 0.4495166 , 0.4508979 ,\n",
       "        0.45710248, 0.474833  , 0.5047915 , 0.4939222 , 0.4585517 ,\n",
       "        0.430835  , 0.4228189 , 0.4266458 , 0.41810888, 0.41976193,\n",
       "        0.43269184, 0.4478862 , 0.53309697, 0.54663825, 0.5600664 ,\n",
       "        0.56330454, 0.5598852 , 0.5555375 , 0.5555149 , 0.5539977 ,\n",
       "        0.54401153, 0.5262357 , 0.4403683 , 0.42727983, 0.42598912,\n",
       "        0.4245625 , 0.41982985, 0.41742954, 0.4242455 , 0.44439897,\n",
       "        0.46362403, 0.52397126, 0.5279793 , 0.5322138 , 0.52999467,\n",
       "        0.52748114, 0.5238128 , 0.5109734 , 0.5029573 , 0.49138603,\n",
       "        0.4555853 , 0.42254716, 0.37936437, 0.36090922, 0.33249053,\n",
       "        0.310367  , 0.3143524 , 0.36783838, 0.36086392], dtype=float32),\n",
       " array([0.4752859 , 0.47392723, 0.46772268, 0.46699804, 0.46788117,\n",
       "        0.47059852, 0.47422162, 0.47659928, 0.47211567, 0.45664957,\n",
       "        0.44523683, 0.44464806, 0.4535473 , 0.46987388, 0.4747198 ,\n",
       "        0.52236354, 0.5322138 , 0.5277529 , 0.49659422, 0.46199363,\n",
       "        0.44686723, 0.43534124, 0.4277101 , 0.4364961 , 0.47265914,\n",
       "        0.5363351 , 0.555062  , 0.56350833, 0.5651387 , 0.5644594 ,\n",
       "        0.56097215, 0.55694145, 0.55728114, 0.55479026, 0.5491291 ,\n",
       "        0.54176974, 0.5332328 , 0.48314348, 0.43432224, 0.4194449 ,\n",
       "        0.41665962, 0.41550478, 0.41675022, 0.41566327, 0.41901466,\n",
       "        0.42528713, 0.43488833, 0.4548833 , 0.49215594, 0.53212327,\n",
       "        0.5339121 , 0.5300173 , 0.52028024, 0.51595515, 0.5173818 ,\n",
       "        0.51172066, 0.4972962 , 0.48654014, 0.4342996 , 0.40146527,\n",
       "        0.37811893, 0.37479022, 0.37173322, 0.32112306], dtype=float32),\n",
       " array([0.4644166 , 0.4643713 , 0.45470217, 0.466047  , 0.47012296,\n",
       "        0.47394988, 0.4790222 , 0.48117343, 0.48001856, 0.47383666,\n",
       "        0.47021356, 0.47073436, 0.4712099 , 0.4924956 , 0.5316477 ,\n",
       "        0.5418377 , 0.5449626 , 0.5369238 , 0.52222764, 0.5240392 ,\n",
       "        0.4878988 , 0.49075198, 0.49969652, 0.47555763, 0.50472355,\n",
       "        0.56224024, 0.5687392 , 0.5614024 , 0.5626478 , 0.5599758 ,\n",
       "        0.5581869 , 0.5575982 , 0.5539524 , 0.5511898 , 0.54702324,\n",
       "        0.5441474 , 0.54181504, 0.5124906 , 0.45504183, 0.43167284,\n",
       "        0.42694017, 0.4324654 , 0.44700307, 0.4205318 , 0.411225  ,\n",
       "        0.40504307, 0.40551862, 0.43375614, 0.47358757, 0.53262144,\n",
       "        0.53850895, 0.5365842 , 0.5303117 , 0.52295226, 0.5238354 ,\n",
       "        0.52537525, 0.5230655 , 0.51532114, 0.4945336 , 0.43681312,\n",
       "        0.40780568, 0.40280128, 0.39981222, 0.374994  ], dtype=float32),\n",
       " array([0.41428196, 0.39870265, 0.38298747, 0.39804596, 0.40508837,\n",
       "        0.416637  , 0.4304274 , 0.42934048, 0.43269184, 0.44442162,\n",
       "        0.45979714, 0.47295353, 0.49278998, 0.5243336 , 0.5428793 ,\n",
       "        0.5501934 , 0.5496273 , 0.5460722 , 0.53964114, 0.5431963 ,\n",
       "        0.5544506 , 0.5667918 , 0.5697129 , 0.55162   , 0.55834544,\n",
       "        0.5666559 , 0.5677428 , 0.56491226, 0.5647538 , 0.55995315,\n",
       "        0.56033814, 0.563146  , 0.5528881 , 0.547929  , 0.5405243 ,\n",
       "        0.5389165 , 0.535067  , 0.52324665, 0.47909015, 0.45608348,\n",
       "        0.43622437, 0.42617026, 0.4262382 , 0.42580795, 0.41142878,\n",
       "        0.4033221 , 0.40563184, 0.4063791 , 0.4539096 , 0.5250582 ,\n",
       "        0.5370371 , 0.54206413, 0.53737676, 0.53287053, 0.53316486,\n",
       "        0.535769  , 0.5361539 , 0.5277982 , 0.520869  , 0.4998324 ,\n",
       "        0.48096964, 0.43060857, 0.40952665, 0.39845356], dtype=float32),\n",
       " array([0.4409344 , 0.42100736, 0.402054  , 0.37587714, 0.36516637,\n",
       "        0.35975435, 0.35148916, 0.33536637, 0.32877687, 0.35035694,\n",
       "        0.39360768, 0.44136465, 0.47607845, 0.53545195, 0.549967  ,\n",
       "        0.5549261 , 0.5537033 , 0.55148417, 0.550352  , 0.55465436,\n",
       "        0.5615383 , 0.5686486 , 0.573653  , 0.5759174 , 0.57394737,\n",
       "        0.5718867 , 0.5695544 , 0.56642944, 0.56228554, 0.5635763 ,\n",
       "        0.5650708 , 0.55372596, 0.47628224, 0.4714137 , 0.5368333 ,\n",
       "        0.54224527, 0.53660685, 0.5297682 , 0.52634895, 0.5103847 ,\n",
       "        0.46224272, 0.44673136, 0.43457133, 0.42857057, 0.4208715 ,\n",
       "        0.40794155, 0.39396998, 0.39951786, 0.44070795, 0.51045257,\n",
       "        0.5277302 , 0.5383731 , 0.5412036 , 0.53855425, 0.53638035,\n",
       "        0.5389165 , 0.54489464, 0.5393015 , 0.5308778 , 0.52406186,\n",
       "        0.5192839 , 0.5171327 , 0.5045877 , 0.43092558], dtype=float32),\n",
       " array([0.46525443, 0.46955687, 0.47881842, 0.46106523, 0.42958957,\n",
       "        0.40984368, 0.40486193, 0.40135205, 0.3953966 , 0.40078592,\n",
       "        0.41838062, 0.44555384, 0.47542176, 0.54335487, 0.55356747,\n",
       "        0.5575076 , 0.5563301 , 0.55363536, 0.55626214, 0.56199116,\n",
       "        0.5676975 , 0.57224905, 0.5745135 , 0.5732907 , 0.571932  ,\n",
       "        0.57093567, 0.5713659 , 0.5712074 , 0.5680825 , 0.57550985,\n",
       "        0.5578925 , 0.42598912, 0.40420523, 0.41625205, 0.5389618 ,\n",
       "        0.544555  , 0.54034317, 0.53570104, 0.53558785, 0.5349538 ,\n",
       "        0.52197856, 0.4681529 , 0.44806737, 0.42958957, 0.43484306,\n",
       "        0.42431343, 0.4010803 , 0.39967635, 0.41482544, 0.42569473,\n",
       "        0.47193453, 0.5190348 , 0.53167033, 0.54269814, 0.5471817 ,\n",
       "        0.54863095, 0.5472044 , 0.54290193, 0.5369691 , 0.5314892 ,\n",
       "        0.5297003 , 0.5322591 , 0.53748995, 0.52714145], dtype=float32),\n",
       " array([0.44897315, 0.45008272, 0.45304912, 0.47286293, 0.47317997,\n",
       "        0.4645298 , 0.45112434, 0.43713015, 0.43255597, 0.45832527,\n",
       "        0.44827116, 0.45728362, 0.48099226, 0.5532731 , 0.5609495 ,\n",
       "        0.5593644 , 0.5591606 , 0.5595003 , 0.56169677, 0.5657728 ,\n",
       "        0.5668371 , 0.5749437 , 0.5779328 , 0.5784536 , 0.577729  ,\n",
       "        0.57614386, 0.57408327, 0.57618916, 0.5724302 , 0.5775705 ,\n",
       "        0.5681957 , 0.47961095, 0.42422286, 0.45112434, 0.543536  ,\n",
       "        0.5471591 , 0.54210943, 0.54396623, 0.5397091 , 0.54079604,\n",
       "        0.5424717 , 0.5388713 , 0.50028527, 0.46697542, 0.43787742,\n",
       "        0.42848   , 0.42012423, 0.4086888 , 0.39809126, 0.39664203,\n",
       "        0.41342148, 0.46926248, 0.5251714 , 0.52304286, 0.5251714 ,\n",
       "        0.52349573, 0.5462986 , 0.5492197 , 0.5428567 , 0.53744465,\n",
       "        0.5349991 , 0.5340933 , 0.53486323, 0.5420868 ], dtype=float32),\n",
       " array([0.4634882 , 0.4621748 , 0.46484685, 0.47415367, 0.4691719 ,\n",
       "        0.454521  , 0.44448957, 0.4487014 , 0.4579403 , 0.45703453,\n",
       "        0.45741948, 0.4793845 , 0.54790634, 0.56169677, 0.5637121 ,\n",
       "        0.5623761 , 0.56233084, 0.5629422 , 0.56554633, 0.56996197,\n",
       "        0.5712527 , 0.578748  , 0.5809218 , 0.57969904, 0.5780687 ,\n",
       "        0.57759315, 0.57623446, 0.57827246, 0.57347184, 0.57288307,\n",
       "        0.5674258 , 0.5197594 , 0.48368695, 0.48282647, 0.52553374,\n",
       "        0.54779315, 0.54706854, 0.54473615, 0.545257  , 0.550986  ,\n",
       "        0.55055577, 0.54770255, 0.5441474 , 0.51579666, 0.4747424 ,\n",
       "        0.44152313, 0.4182221 , 0.39779687, 0.38493487, 0.38624826,\n",
       "        0.40352592, 0.42098472, 0.45418134, 0.47603315, 0.479928  ,\n",
       "        0.4756935 , 0.52646214, 0.5442153 , 0.543151  , 0.54025257,\n",
       "        0.5405696 , 0.5418377 , 0.53914297, 0.5391656 ], dtype=float32),\n",
       " array([0.46996447, 0.47050792, 0.47560292, 0.4648242 , 0.46255976,\n",
       "        0.46101993, 0.46618286, 0.4832567 , 0.50209683, 0.49933422,\n",
       "        0.5560357 , 0.56244403, 0.5663389 , 0.56787866, 0.5680825 ,\n",
       "        0.5667465 , 0.567222  , 0.5687618 , 0.5701431 , 0.57089037,\n",
       "        0.5722717 , 0.5801066 , 0.58305043, 0.5820541 , 0.58042365,\n",
       "        0.5799481 , 0.57750255, 0.57677794, 0.57258874, 0.56708616,\n",
       "        0.5626478 , 0.5583907 , 0.54693264, 0.53964114, 0.54758936,\n",
       "        0.5507822 , 0.548948  , 0.5485857 , 0.54998964, 0.5555602 ,\n",
       "        0.55388445, 0.54867625, 0.54677415, 0.550352  , 0.5491291 ,\n",
       "        0.48250943, 0.45259625, 0.43214837, 0.4222528 , 0.413263  ,\n",
       "        0.40708107, 0.42238867, 0.44138727, 0.46172193, 0.47607845,\n",
       "        0.4806526 , 0.5121509 , 0.5202123 , 0.53515756, 0.5425623 ,\n",
       "        0.54249436, 0.5415886 , 0.5437398 , 0.54274344], dtype=float32),\n",
       " array([0.46081614, 0.46697542, 0.46781325, 0.4670207 , 0.47490093,\n",
       "        0.4874912 , 0.5483593 , 0.56559163, 0.577027  , 0.5752381 ,\n",
       "        0.575691  , 0.57580423, 0.57541925, 0.5749437 , 0.57460403,\n",
       "        0.57215846, 0.5717509 , 0.57224905, 0.57258874, 0.5732001 ,\n",
       "        0.57754785, 0.5843185 , 0.5843864 , 0.5824843 , 0.5810577 ,\n",
       "        0.58012927, 0.5772308 , 0.5750796 , 0.5705281 , 0.56647474,\n",
       "        0.56228554, 0.55626214, 0.49901718, 0.47954303, 0.53948265,\n",
       "        0.5530693 , 0.55211824, 0.5524352 , 0.5548808 , 0.5591153 ,\n",
       "        0.55825484, 0.5515068 , 0.548246  , 0.5545412 , 0.5597267 ,\n",
       "        0.5539071 , 0.5434001 , 0.53719556, 0.52105016, 0.46423545,\n",
       "        0.42857057, 0.43321267, 0.437266  , 0.4439461 , 0.4518716 ,\n",
       "        0.45744213, 0.45710248, 0.4605444 , 0.4790222 , 0.53176093,\n",
       "        0.543536  , 0.5470006 , 0.54591364, 0.5431737 ], dtype=float32),\n",
       " array([0.42080355, 0.4276648 , 0.4291593 , 0.45239243, 0.4857023 ,\n",
       "        0.5658407 , 0.5773214 , 0.5845676 , 0.58327687, 0.5798123 ,\n",
       "        0.5799028 , 0.5812615 , 0.58221257, 0.58160114, 0.57868004,\n",
       "        0.5768459 , 0.57627976, 0.575691  , 0.5756457 , 0.5776384 ,\n",
       "        0.58332217, 0.5867188 , 0.5852243 , 0.5841373 , 0.5832542 ,\n",
       "        0.5811709 , 0.5796764 , 0.57584953, 0.5708225 , 0.5621044 ,\n",
       "        0.5155249 , 0.47261384, 0.45470217, 0.45103377, 0.48121873,\n",
       "        0.55162   , 0.5571679 , 0.555379  , 0.5584586 , 0.5619232 ,\n",
       "        0.5613345 , 0.55356747, 0.54978585, 0.5566018 , 0.5571226 ,\n",
       "        0.5544279 , 0.54953676, 0.5448041 , 0.540864  , 0.53074193,\n",
       "        0.46208423, 0.44519153, 0.43289563, 0.42694017, 0.42467573,\n",
       "        0.42596647, 0.42857057, 0.44487453, 0.45809883, 0.4752859 ,\n",
       "        0.48719683, 0.48925745, 0.52727735, 0.5436492 ], dtype=float32),\n",
       " array([0.3961212 , 0.40932286, 0.43355232, 0.46337494, 0.5605646 ,\n",
       "        0.5801972 , 0.58393353, 0.58440906, 0.5862433 , 0.584477  ,\n",
       "        0.5859942 , 0.5866735 , 0.5859036 , 0.58436376, 0.5816691 ,\n",
       "        0.5797217 , 0.57847625, 0.5780234 , 0.5799028 , 0.5846355 ,\n",
       "        0.5893003 , 0.58848506, 0.5862659 , 0.5856092 , 0.58474874,\n",
       "        0.5823937 , 0.58259755, 0.5768459 , 0.5751475 , 0.5579831 ,\n",
       "        0.4754444 , 0.44548592, 0.4270987 , 0.4463464 , 0.48303026,\n",
       "        0.55329573, 0.5605193 , 0.55805105, 0.56337243, 0.56382537,\n",
       "        0.5632819 , 0.55678296, 0.55250317, 0.55714524, 0.56122124,\n",
       "        0.5566244 , 0.5502161 , 0.5467515 , 0.54489464, 0.5417924 ,\n",
       "        0.53753525, 0.52243143, 0.4523698 , 0.422049  , 0.4019408 ,\n",
       "        0.40977573, 0.41416875, 0.44412723, 0.4598198 , 0.510679  ,\n",
       "        0.4728403 , 0.47012296, 0.47777677, 0.49691126], dtype=float32),\n",
       " array([0.41987514, 0.4433347 , 0.47795793, 0.50961477, 0.57220376,\n",
       "        0.5866735 , 0.58660555, 0.58853036, 0.5889606 , 0.588553  ,\n",
       "        0.58941346, 0.5889153 , 0.587534  , 0.586198  , 0.5833448 ,\n",
       "        0.58051425, 0.58071804, 0.5826881 , 0.58606213, 0.58954936,\n",
       "        0.5893003 , 0.58737546, 0.5864697 , 0.5864244 , 0.5856545 ,\n",
       "        0.583843  , 0.58459026, 0.57969904, 0.5800387 , 0.5678108 ,\n",
       "        0.5455287 , 0.44806737, 0.43069914, 0.44852024, 0.47788998,\n",
       "        0.55682826, 0.56740314, 0.56097215, 0.5674711 , 0.5666559 ,\n",
       "        0.56291956, 0.5585266 , 0.55703205, 0.55979466, 0.5623535 ,\n",
       "        0.5590927 , 0.5544959 , 0.55189174, 0.5498538 , 0.54691   ,\n",
       "        0.5463666 , 0.54090923, 0.47123256, 0.43316737, 0.40948138,\n",
       "        0.39711756, 0.3984762 , 0.4542719 , 0.48246416, 0.53033435,\n",
       "        0.5339348 , 0.5293833 , 0.5019836 , 0.4931523 ], dtype=float32),\n",
       " array([0.46926248, 0.49247295, 0.57376623, 0.5883266 , 0.58839446,\n",
       "        0.58766985, 0.5881907 , 0.5893455 , 0.5884171 , 0.59194964,\n",
       "        0.58640176, 0.58055955, 0.5776837 , 0.58284664, 0.5849752 ,\n",
       "        0.58271074, 0.5844317 , 0.588236  , 0.58889264, 0.5882813 ,\n",
       "        0.5860848 , 0.58461285, 0.58420527, 0.58255225, 0.5838656 ,\n",
       "        0.58305043, 0.58454496, 0.58357126, 0.58110297, 0.577095  ,\n",
       "        0.5498085 , 0.46317115, 0.43817177, 0.43724337, 0.4668169 ,\n",
       "        0.5622176 , 0.57127535, 0.5663389 , 0.57025635, 0.568241  ,\n",
       "        0.56355363, 0.5606551 , 0.5607457 , 0.56334984, 0.56407446,\n",
       "        0.562829  , 0.55931914, 0.5564433 , 0.55524313, 0.55490345,\n",
       "        0.55198234, 0.5481781 , 0.54050165, 0.5283643 , 0.4859514 ,\n",
       "        0.4110212 , 0.40948138, 0.46740565, 0.5327573 , 0.5399808 ,\n",
       "        0.54464555, 0.54847246, 0.5361087 , 0.5088222 ], dtype=float32),\n",
       " array([0.5055161 , 0.55689615, 0.5893455 , 0.59407824, 0.59102124,\n",
       "        0.5893455 , 0.58970785, 0.5903193 , 0.5905004 , 0.5917685 ,\n",
       "        0.5852243 , 0.5473176 , 0.5473403 , 0.55422413, 0.5851563 ,\n",
       "        0.5866282 , 0.5886662 , 0.5907495 , 0.58889264, 0.58791894,\n",
       "        0.58674145, 0.5841373 , 0.5838656 , 0.5808765 , 0.5822805 ,\n",
       "        0.58142   , 0.58291453, 0.5846808 , 0.58230317, 0.57729876,\n",
       "        0.5373088 , 0.4645298 , 0.45576644, 0.46169928, 0.4794751 ,\n",
       "        0.57005256, 0.5762571 , 0.57233965, 0.573336  , 0.5696223 ,\n",
       "        0.5649349 , 0.56287426, 0.56305546, 0.5658633 , 0.56631625,\n",
       "        0.56534255, 0.5635763 , 0.5620591 , 0.56110805, 0.56015694,\n",
       "        0.5598852 , 0.55499405, 0.549967  , 0.54448706, 0.5229296 ,\n",
       "        0.45327556, 0.42694017, 0.4306765 , 0.4769842 , 0.54233587,\n",
       "        0.54779315, 0.54940087, 0.54808754, 0.5463439 ], dtype=float32),\n",
       " array([0.5118792 , 0.56393856, 0.59568596, 0.59441787, 0.5923572 ,\n",
       "        0.5921761 , 0.591293  , 0.59063625, 0.5937159 , 0.59149677,\n",
       "        0.5899343 , 0.58429587, 0.58042365, 0.58250695, 0.58660555,\n",
       "        0.5906589 , 0.5918817 , 0.590591  , 0.588236  , 0.5881227 ,\n",
       "        0.5881454 , 0.5863339 , 0.5853375 , 0.58076334, 0.57983494,\n",
       "        0.58026516, 0.58241636, 0.58445436, 0.5830957 , 0.57535136,\n",
       "        0.48875928, 0.47487828, 0.5027535 , 0.5151626 , 0.5099091 ,\n",
       "        0.57288307, 0.58212197, 0.5763024 , 0.57469463, 0.5701884 ,\n",
       "        0.5667691 , 0.5662936 , 0.5661577 , 0.56753904, 0.5690562 ,\n",
       "        0.5688071 , 0.5671767 , 0.5658181 , 0.56504816, 0.56350833,\n",
       "        0.56181   , 0.5604287 , 0.55796045, 0.55580926, 0.55227673,\n",
       "        0.5426302 , 0.44698045, 0.40982103, 0.4502865 , 0.48538527,\n",
       "        0.55085015, 0.5507369 , 0.5508275 , 0.5510766 ], dtype=float32)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(real_img[0][:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.49320534, 0.44745713, 0.5766689 , 0.4641738 , 0.60705465,\n",
       "        0.46950525, 0.5948406 , 0.4638009 , 0.6054449 , 0.46955097,\n",
       "        0.59434456, 0.4638989 , 0.6055772 , 0.46947005, 0.594272  ,\n",
       "        0.46380433, 0.6054064 , 0.4694348 , 0.5942071 , 0.46378076,\n",
       "        0.60534954, 0.46940926, 0.5941551 , 0.4637759 , 0.6052942 ,\n",
       "        0.46937263, 0.59406495, 0.46375534, 0.6051829 , 0.46929306,\n",
       "        0.5938719 , 0.46367675, 0.6050081 , 0.46919897, 0.5936955 ,\n",
       "        0.46361703, 0.6048424 , 0.4691077 , 0.5935205 , 0.46357316,\n",
       "        0.60464597, 0.46896937, 0.5932163 , 0.46344322, 0.60436386,\n",
       "        0.46883845, 0.592953  , 0.46333903, 0.60425395, 0.4687915 ,\n",
       "        0.59288883, 0.46333337, 0.60419893, 0.46876112, 0.5926205 ,\n",
       "        0.46312538, 0.6049836 , 0.4690384 , 0.59445316, 0.46433222,\n",
       "        0.60377157, 0.468295  , 0.5906709 , 0.45809314], dtype=float32),\n",
       " array([0.42938492, 0.50645626, 0.5498936 , 0.54659444, 0.5514135 ,\n",
       "        0.55093247, 0.5663991 , 0.54805183, 0.55173033, 0.5513632 ,\n",
       "        0.5667517 , 0.54835945, 0.5509995 , 0.5512009 , 0.5664859 ,\n",
       "        0.5481269 , 0.5510423 , 0.5511178 , 0.5663898 , 0.5480817 ,\n",
       "        0.5509965 , 0.55106866, 0.56634194, 0.5480777 , 0.55094904,\n",
       "        0.5509928 , 0.5662462 , 0.5480483 , 0.5508658 , 0.5508081 ,\n",
       "        0.56599903, 0.54791534, 0.55071616, 0.5505933 , 0.56574273,\n",
       "        0.547812  , 0.55057746, 0.5503959 , 0.5654867 , 0.54773283,\n",
       "        0.5504542 , 0.55006975, 0.5650409 , 0.5474837 , 0.55025834,\n",
       "        0.54977334, 0.56471014, 0.54728895, 0.55010426, 0.5496495 ,\n",
       "        0.56464106, 0.5472857 , 0.5500779 , 0.549605  , 0.56440526,\n",
       "        0.54686326, 0.54999834, 0.5497071 , 0.56677306, 0.5489945 ,\n",
       "        0.5509399 , 0.54940593, 0.5667736 , 0.5283468 ], dtype=float32),\n",
       " array([0.52093035, 0.5457507 , 0.6727706 , 0.5714109 , 0.68250847,\n",
       "        0.5830112 , 0.68990177, 0.57195544, 0.68302304, 0.58454514,\n",
       "        0.6919594 , 0.57247055, 0.6830312 , 0.5840087 , 0.69104004,\n",
       "        0.57217133, 0.68272525, 0.58394706, 0.6909961 , 0.57219005,\n",
       "        0.68267536, 0.58392465, 0.6909395 , 0.5722036 , 0.68254405,\n",
       "        0.5838409 , 0.69072306, 0.57215714, 0.68223053, 0.58362633,\n",
       "        0.69040895, 0.5720955 , 0.68189967, 0.5834205 , 0.6901856 ,\n",
       "        0.5721165 , 0.6816131 , 0.58322906, 0.6898489 , 0.5721087 ,\n",
       "        0.68112737, 0.582873  , 0.68937135, 0.5720234 , 0.6808002 ,\n",
       "        0.5826813 , 0.689301  , 0.5720622 , 0.6807962 , 0.58268523,\n",
       "        0.6894711 , 0.57221746, 0.6807726 , 0.5826619 , 0.68917596,\n",
       "        0.57182014, 0.682364  , 0.5838928 , 0.6933782 , 0.5741938 ,\n",
       "        0.67965627, 0.58093023, 0.6477823 , 0.5327225 ], dtype=float32),\n",
       " array([0.44242987, 0.56113   , 0.5821272 , 0.5897552 , 0.61120015,\n",
       "        0.6067279 , 0.60611784, 0.59037954, 0.61120296, 0.6091102 ,\n",
       "        0.6075953 , 0.5920129 , 0.61220115, 0.60821724, 0.6067888 ,\n",
       "        0.59146   , 0.61168206, 0.6081655 , 0.6067345 , 0.59149444,\n",
       "        0.611644  , 0.6081551 , 0.6066736 , 0.59152853, 0.6115391 ,\n",
       "        0.60806257, 0.6065066 , 0.5914644 , 0.61123854, 0.60782564,\n",
       "        0.6062388 , 0.5913944 , 0.6109099 , 0.6076138 , 0.60600394,\n",
       "        0.59143186, 0.610641  , 0.6074035 , 0.6057339 , 0.59139854,\n",
       "        0.61019087, 0.6070105 , 0.6053296 , 0.59126604, 0.60978353,\n",
       "        0.6068356 , 0.6051646 , 0.5913376 , 0.60975575, 0.60688317,\n",
       "        0.6052397 , 0.5915556 , 0.60985404, 0.6069487 , 0.60507464,\n",
       "        0.59102553, 0.61044776, 0.60815066, 0.607468  , 0.59397334,\n",
       "        0.6108231 , 0.6063329 , 0.5890101 , 0.55090874], dtype=float32),\n",
       " array([0.51928204, 0.5679579 , 0.63211155, 0.59036255, 0.66883874,\n",
       "        0.6095871 , 0.6460508 , 0.5871505 , 0.6653073 , 0.6108586 ,\n",
       "        0.646935  , 0.58883363, 0.6664986 , 0.6101449 , 0.6464826 ,\n",
       "        0.58839357, 0.66606414, 0.6101274 , 0.6464823 , 0.58846575,\n",
       "        0.6661087 , 0.61012226, 0.6464666 , 0.5885362 , 0.66597605,\n",
       "        0.60999906, 0.6462971 , 0.5885098 , 0.6656242 , 0.60974705,\n",
       "        0.64599067, 0.58847564, 0.6653735 , 0.6095495 , 0.6457791 ,\n",
       "        0.58856744, 0.66520774, 0.60935414, 0.6455676 , 0.5886064 ,\n",
       "        0.6648536 , 0.6090134 , 0.6451919 , 0.58854896, 0.6647053 ,\n",
       "        0.6088663 , 0.6450073 , 0.5886651 , 0.6649816 , 0.6089822 ,\n",
       "        0.6451017 , 0.5889445 , 0.6651832 , 0.6090491 , 0.64479905,\n",
       "        0.5882711 , 0.66661406, 0.6102145 , 0.64711154, 0.59194887,\n",
       "        0.6646069 , 0.6078951 , 0.6325632 , 0.55261064], dtype=float32),\n",
       " array([0.43632907, 0.5490177 , 0.5815793 , 0.5779205 , 0.5801391 ,\n",
       "        0.59176725, 0.59525764, 0.5741004 , 0.57762986, 0.5934199 ,\n",
       "        0.5965517 , 0.5762877 , 0.5778135 , 0.59286773, 0.5960251 ,\n",
       "        0.5757172 , 0.5777605 , 0.59281856, 0.59604234, 0.5757837 ,\n",
       "        0.5776931 , 0.59277403, 0.59603477, 0.5758204 , 0.57754683,\n",
       "        0.59258723, 0.5957992 , 0.5756961 , 0.577267  , 0.59225106,\n",
       "        0.5954413 , 0.57553804, 0.57691807, 0.5919242 , 0.59523153,\n",
       "        0.5755156 , 0.5765822 , 0.5915689 , 0.59493273, 0.5754125 ,\n",
       "        0.57618076, 0.5910946 , 0.59448814, 0.57524765, 0.5757768 ,\n",
       "        0.5907893 , 0.59440446, 0.5753435 , 0.57561034, 0.5907787 ,\n",
       "        0.59465146, 0.575638  , 0.5755654 , 0.59079796, 0.5944015 ,\n",
       "        0.57525665, 0.5757755 , 0.5914087 , 0.59798896, 0.5784487 ,\n",
       "        0.57586586, 0.59053653, 0.5830763 , 0.5437326 ], dtype=float32),\n",
       " array([0.5366397 , 0.5800649 , 0.6903914 , 0.59314466, 0.6944128 ,\n",
       "        0.61427295, 0.70199424, 0.5914355 , 0.6937696 , 0.61751807,\n",
       "        0.7038866 , 0.5929842 , 0.6941245 , 0.61656684, 0.7030854 ,\n",
       "        0.5925814 , 0.69392145, 0.6165772 , 0.70314467, 0.59263825,\n",
       "        0.6938706 , 0.6165483 , 0.70306754, 0.592653  , 0.6935831 ,\n",
       "        0.6163002 , 0.702736  , 0.59256417, 0.69316995, 0.61598164,\n",
       "        0.70250887, 0.5925216 , 0.6928858 , 0.61580753, 0.7025218 ,\n",
       "        0.5925943 , 0.69257146, 0.61553675, 0.7023643 , 0.5925976 ,\n",
       "        0.6921809 , 0.61516947, 0.7022656 , 0.5925968 , 0.6920755 ,\n",
       "        0.6151842 , 0.7026068 , 0.5927741 , 0.69227934, 0.6154083 ,\n",
       "        0.7029159 , 0.592994  , 0.6920815 , 0.61528206, 0.7022073 ,\n",
       "        0.59224945, 0.6941769 , 0.61757934, 0.7071002 , 0.5958988 ,\n",
       "        0.6883758 , 0.61143106, 0.66071385, 0.55214405], dtype=float32),\n",
       " array([0.45035756, 0.5723452 , 0.59147966, 0.58903223, 0.6244441 ,\n",
       "        0.6133418 , 0.6176813 , 0.5915022 , 0.6268707 , 0.61817944,\n",
       "        0.6201308 , 0.5939544 , 0.62836313, 0.6168402 , 0.6192173 ,\n",
       "        0.5933267 , 0.62789005, 0.6169044 , 0.6192296 , 0.5933849 ,\n",
       "        0.62783855, 0.6169082 , 0.61916447, 0.5934024 , 0.6275691 ,\n",
       "        0.6166484 , 0.61882925, 0.5932392 , 0.62710536, 0.6163574 ,\n",
       "        0.61841804, 0.593096  , 0.6267535 , 0.61629367, 0.6181781 ,\n",
       "        0.59308136, 0.6264397 , 0.6161356 , 0.6178461 , 0.59296644,\n",
       "        0.62597114, 0.61588854, 0.6174544 , 0.5928314 , 0.6257322 ,\n",
       "        0.61611986, 0.6174334 , 0.59297454, 0.62588876, 0.61652577,\n",
       "        0.61765313, 0.59323406, 0.62578976, 0.616434  , 0.6170514 ,\n",
       "        0.592318  , 0.6266537 , 0.61860096, 0.6208972 , 0.5971353 ,\n",
       "        0.6249979 , 0.6134198 , 0.59938616, 0.554004  ], dtype=float32),\n",
       " array([0.5227548 , 0.57204735, 0.6332186 , 0.58704185, 0.66592526,\n",
       "        0.60764825, 0.64496046, 0.5822798 , 0.662335  , 0.6102969 ,\n",
       "        0.6472304 , 0.58420205, 0.66385776, 0.6093774 , 0.6465881 ,\n",
       "        0.5837032 , 0.6635061 , 0.60945946, 0.6466171 , 0.5838006 ,\n",
       "        0.6634948 , 0.609465  , 0.6465858 , 0.5838493 , 0.66321075,\n",
       "        0.6092312 , 0.6462886 , 0.5837703 , 0.6628722 , 0.6089573 ,\n",
       "        0.6458937 , 0.5837605 , 0.6628076 , 0.6088832 , 0.64564013,\n",
       "        0.583882  , 0.66278213, 0.60878384, 0.64538026, 0.58394784,\n",
       "        0.6626972 , 0.60865766, 0.6450757 , 0.5840372 , 0.6630386 ,\n",
       "        0.6089102 , 0.64511335, 0.5843667 , 0.66354334, 0.60928655,\n",
       "        0.645291  , 0.5846524 , 0.6632724 , 0.60915273, 0.6446598 ,\n",
       "        0.58397096, 0.66434735, 0.6107055 , 0.64739287, 0.58783835,\n",
       "        0.66074514, 0.6065092 , 0.6350444 , 0.55201155], dtype=float32),\n",
       " array([0.43716168, 0.54969835, 0.5825253 , 0.5758126 , 0.5824233 ,\n",
       "        0.59355044, 0.5926696 , 0.5702129 , 0.5794414 , 0.59557647,\n",
       "        0.5939532 , 0.5725436 , 0.58037996, 0.59516823, 0.5935723 ,\n",
       "        0.57203156, 0.5802893 , 0.595169  , 0.5936332 , 0.57210654,\n",
       "        0.58023983, 0.5951069 , 0.5935632 , 0.5720555 , 0.5800275 ,\n",
       "        0.5947964 , 0.5932099 , 0.57182467, 0.5796013 , 0.5943357 ,\n",
       "        0.5928854 , 0.57167935, 0.57915235, 0.5939522 , 0.59276617,\n",
       "        0.5716479 , 0.5787591 , 0.59358394, 0.5925489 , 0.57156515,\n",
       "        0.57833785, 0.5931993 , 0.59239364, 0.5715862 , 0.5780045 ,\n",
       "        0.5930845 , 0.5926993 , 0.57195085, 0.57799053, 0.59318966,\n",
       "        0.59292907, 0.5721275 , 0.57785535, 0.5929528 , 0.59227324,\n",
       "        0.57173413, 0.5780939 , 0.59347945, 0.59548086, 0.5738283 ,\n",
       "        0.57726145, 0.5916066 , 0.58285064, 0.54019505], dtype=float32),\n",
       " array([0.5363582 , 0.5815921 , 0.68982345, 0.5917473 , 0.69432694,\n",
       "        0.61564916, 0.70176876, 0.5898092 , 0.69477904, 0.61895627,\n",
       "        0.7034114 , 0.59143054, 0.6952214 , 0.61811006, 0.7026417 ,\n",
       "        0.5910056 , 0.6950442 , 0.618139  , 0.70262086, 0.5910354 ,\n",
       "        0.69491714, 0.6180387 , 0.70246726, 0.59102666, 0.69457626,\n",
       "        0.61768484, 0.7021433 , 0.5909378 , 0.6941905 , 0.61737514,\n",
       "        0.7020375 , 0.59093964, 0.69395137, 0.6172337 , 0.70205766,\n",
       "        0.5909949 , 0.6936939 , 0.6169876 , 0.70189357, 0.59099466,\n",
       "        0.69342446, 0.61681014, 0.70189023, 0.5910536 , 0.69345474,\n",
       "        0.61704665, 0.7022184 , 0.5912763 , 0.6935423 , 0.61718917,\n",
       "        0.702174  , 0.59137917, 0.6929922 , 0.61668545, 0.7010862 ,\n",
       "        0.5905223 , 0.69484806, 0.6190106 , 0.70597494, 0.59413314,\n",
       "        0.68889755, 0.6118349 , 0.66095513, 0.5517225 ], dtype=float32),\n",
       " array([0.45134324, 0.5729989 , 0.59043586, 0.58692175, 0.6270447 ,\n",
       "        0.61226034, 0.6186141 , 0.5903453 , 0.63001496, 0.6172495 ,\n",
       "        0.62113297, 0.5928097 , 0.6316947 , 0.6159162 , 0.62027955,\n",
       "        0.5921918 , 0.63120466, 0.6159836 , 0.62030065, 0.59222716,\n",
       "        0.63107026, 0.615886  , 0.62020457, 0.5922413 , 0.6307456 ,\n",
       "        0.6155766 , 0.6198625 , 0.59214175, 0.63029546, 0.61542183,\n",
       "        0.61954415, 0.5921264 , 0.62996995, 0.6154851 , 0.61938405,\n",
       "        0.5921862 , 0.6296233 , 0.6154355 , 0.619152  , 0.59216213,\n",
       "        0.62921745, 0.61549425, 0.6189637 , 0.592201  , 0.6290839 ,\n",
       "        0.61596894, 0.61915785, 0.592414  , 0.6291135 , 0.61614203,\n",
       "        0.61929   , 0.59255445, 0.62867755, 0.6156004 , 0.6182447 ,\n",
       "        0.5912955 , 0.6293542 , 0.61769885, 0.6222469 , 0.59670544,\n",
       "        0.6274911 , 0.6120483 , 0.6018078 , 0.5552936 ], dtype=float32),\n",
       " array([0.522936  , 0.5716405 , 0.63202244, 0.58622956, 0.66542447,\n",
       "        0.6051008 , 0.6460665 , 0.5804752 , 0.6629645 , 0.60787606,\n",
       "        0.64843   , 0.5824315 , 0.66444314, 0.6069786 , 0.64776635,\n",
       "        0.5818824 , 0.66395426, 0.60701454, 0.64771193, 0.581888  ,\n",
       "        0.66374177, 0.60690665, 0.64760077, 0.58188933, 0.6634632 ,\n",
       "        0.60665995, 0.6473464 , 0.58187383, 0.6633482 , 0.60656005,\n",
       "        0.6471234 , 0.5820069 , 0.66342354, 0.606636  , 0.64696234,\n",
       "        0.58218867, 0.6633134 , 0.6066141 , 0.6466733 , 0.5822656 ,\n",
       "        0.66315365, 0.6066433 , 0.6463899 , 0.582406  , 0.6633407 ,\n",
       "        0.6070091 , 0.6463581 , 0.5826276 , 0.6632875 , 0.60711896,\n",
       "        0.64631915, 0.582701  , 0.66255885, 0.6065879 , 0.6453314 ,\n",
       "        0.5818692 , 0.6636386 , 0.6080911 , 0.6484853 , 0.58612376,\n",
       "        0.6607048 , 0.6039979 , 0.636961  , 0.5509253 ], dtype=float32),\n",
       " array([0.43712655, 0.5494    , 0.5819942 , 0.57527643, 0.58226573,\n",
       "        0.5934611 , 0.59230465, 0.56972873, 0.57948434, 0.5956454 ,\n",
       "        0.5937971 , 0.5721513 , 0.580503  , 0.5953194 , 0.5934053 ,\n",
       "        0.5716112 , 0.5803984 , 0.59526706, 0.59331906, 0.5715218 ,\n",
       "        0.58026224, 0.5950969 , 0.59313685, 0.5713774 , 0.5799981 ,\n",
       "        0.59476066, 0.5928386 , 0.57122934, 0.5796343 , 0.5944065 ,\n",
       "        0.5927047 , 0.57124084, 0.5792898 , 0.59411293, 0.5926384 ,\n",
       "        0.5712477 , 0.578926  , 0.5937396 , 0.59236217, 0.5711141 ,\n",
       "        0.5784835 , 0.59335613, 0.59216404, 0.57111454, 0.5782189 ,\n",
       "        0.5932364 , 0.59227777, 0.5711929 , 0.57810616, 0.59312576,\n",
       "        0.59211993, 0.5710108 , 0.5777235 , 0.59258246, 0.5911398 ,\n",
       "        0.57043123, 0.5777521 , 0.59300363, 0.59459937, 0.5729109 ,\n",
       "        0.5771117 , 0.5914113 , 0.58263147, 0.54003865], dtype=float32),\n",
       " array([0.5360488 , 0.5812504 , 0.6893939 , 0.5914285 , 0.69388795,\n",
       "        0.61541164, 0.70175534, 0.58954257, 0.69451255, 0.6188322 ,\n",
       "        0.70356023, 0.5911751 , 0.694944  , 0.6179763 , 0.70264494,\n",
       "        0.5906975 , 0.6946016 , 0.61788625, 0.70250547, 0.59065115,\n",
       "        0.6944152 , 0.61771506, 0.7024325 , 0.59065044, 0.69419235,\n",
       "        0.6174205 , 0.7022846 , 0.5906336 , 0.69397134, 0.6172548 ,\n",
       "        0.70226634, 0.59068906, 0.69376856, 0.6171415 , 0.70219713,\n",
       "        0.59073037, 0.69347054, 0.6168699 , 0.70198524, 0.59069693,\n",
       "        0.6931727 , 0.61670333, 0.70191365, 0.5906929 , 0.6930793 ,\n",
       "        0.6168318 , 0.7020221 , 0.5907498 , 0.69295466, 0.6166987 ,\n",
       "        0.70185655, 0.59074503, 0.692286  , 0.6159617 , 0.70082104,\n",
       "        0.58990324, 0.69431627, 0.6184381 , 0.7061361 , 0.59383327,\n",
       "        0.6888035 , 0.61166006, 0.6615696 , 0.55168283], dtype=float32),\n",
       " array([0.4512741 , 0.5725993 , 0.5900068 , 0.5865182 , 0.62675786,\n",
       "        0.6118299 , 0.6180584 , 0.5898621 , 0.63008803, 0.6168786 ,\n",
       "        0.6206648 , 0.59231603, 0.63183916, 0.61544245, 0.6197396 ,\n",
       "        0.5916174 , 0.6312337 , 0.6153259 , 0.61960477, 0.59156823,\n",
       "        0.631051  , 0.6151835 , 0.61947244, 0.59160167, 0.63082325,\n",
       "        0.61500746, 0.6192364 , 0.5915916 , 0.63050646, 0.61502707,\n",
       "        0.61906874, 0.5916439 , 0.6302136 , 0.6150785 , 0.61894125,\n",
       "        0.59167594, 0.62983537, 0.61496294, 0.61869144, 0.5916413 ,\n",
       "        0.6294533 , 0.61499375, 0.61845267, 0.5915774 , 0.6292733 ,\n",
       "        0.6152344 , 0.6184569 , 0.59164155, 0.629164  , 0.6151092 ,\n",
       "        0.6183998 , 0.59170973, 0.6285976 , 0.6144423 , 0.6172247 ,\n",
       "        0.5904844 , 0.6293239 , 0.61690974, 0.62146455, 0.5962021 ,\n",
       "        0.6276692 , 0.61177284, 0.6015616 , 0.5551337 ], dtype=float32),\n",
       " array([0.52282476, 0.57133406, 0.63187754, 0.5860641 , 0.6654234 ,\n",
       "        0.60470563, 0.6456887 , 0.58032703, 0.6630481 , 0.60752326,\n",
       "        0.64801604, 0.5822201 , 0.6643557 , 0.6065047 , 0.64725345,\n",
       "        0.58156604, 0.66366696, 0.6063572 , 0.6470549 , 0.5815177 ,\n",
       "        0.6634946 , 0.6062238 , 0.6469178 , 0.5815616 , 0.6634361 ,\n",
       "        0.6061137 , 0.6467565 , 0.581613  , 0.66344035, 0.60615647,\n",
       "        0.6466358 , 0.5817594 , 0.6634202 , 0.6062165 , 0.6464852 ,\n",
       "        0.5818862 , 0.6632548 , 0.60615075, 0.6462771 , 0.5819911 ,\n",
       "        0.6631909 , 0.6061705 , 0.6460328 , 0.582078  , 0.6632029 ,\n",
       "        0.60631585, 0.6459031 , 0.5822193 , 0.6630066 , 0.60617524,\n",
       "        0.645784  , 0.582248  , 0.66247535, 0.6056176 , 0.64487904,\n",
       "        0.5815177 , 0.66408765, 0.60746974, 0.6483397 , 0.58605355,\n",
       "        0.66137564, 0.6037994 , 0.6369666 , 0.55090624], dtype=float32),\n",
       " array([0.43706143, 0.5493251 , 0.58186716, 0.5752364 , 0.5821086 ,\n",
       "        0.5932566 , 0.59224105, 0.5697569 , 0.5793156 , 0.59550154,\n",
       "        0.5937473 , 0.57211953, 0.5803098 , 0.5951187 , 0.5931847 ,\n",
       "        0.57144225, 0.5801028 , 0.59493625, 0.5929674 , 0.5712953 ,\n",
       "        0.5798865 , 0.5947324 , 0.59285134, 0.57123363, 0.57964075,\n",
       "        0.5944747 , 0.5926894 , 0.571179  , 0.57935065, 0.59421444,\n",
       "        0.5926062 , 0.571183  , 0.5790688 , 0.5939416 , 0.5924825 ,\n",
       "        0.571124  , 0.5787524 , 0.59360445, 0.59227395, 0.5710642 ,\n",
       "        0.57838714, 0.59327847, 0.5920857 , 0.5710392 , 0.5780993 ,\n",
       "        0.59308326, 0.5920486 , 0.5710439 , 0.57786524, 0.59282064,\n",
       "        0.591797  , 0.5708119 , 0.5773501 , 0.5921961 , 0.59096545,\n",
       "        0.570414  , 0.57738346, 0.5927172 , 0.59476674, 0.5731591 ,\n",
       "        0.57692   , 0.5913216 , 0.58285886, 0.54020953], dtype=float32),\n",
       " array([0.5358727 , 0.58111954, 0.6892033 , 0.5914426 , 0.6937821 ,\n",
       "        0.61534655, 0.70175517, 0.5895671 , 0.69436634, 0.6187702 ,\n",
       "        0.703467  , 0.5911407 , 0.694677  , 0.6177863 , 0.7024433 ,\n",
       "        0.5906205 , 0.69424474, 0.6175907 , 0.70230484, 0.5905887 ,\n",
       "        0.69409555, 0.6174749 , 0.7023012 , 0.59061944, 0.6939271 ,\n",
       "        0.61728066, 0.7021838 , 0.5906104 , 0.69370735, 0.6171518 ,\n",
       "        0.702155  , 0.5906476 , 0.69351435, 0.61701024, 0.7021196 ,\n",
       "        0.59068507, 0.6933404 , 0.6168134 , 0.70206374, 0.590721  ,\n",
       "        0.6930926 , 0.6166438 , 0.7018732 , 0.5906923 , 0.69285107,\n",
       "        0.61662436, 0.7018533 , 0.5907282 , 0.69256437, 0.6163635 ,\n",
       "        0.70172346, 0.5907419 , 0.6919525 , 0.61569417, 0.7009164 ,\n",
       "        0.58999246, 0.69414735, 0.6183849 , 0.70632875, 0.5939501 ,\n",
       "        0.68880093, 0.6117512 , 0.6615699 , 0.55170834], dtype=float32),\n",
       " array([0.4511379 , 0.5724653 , 0.5899389 , 0.58656794, 0.62659675,\n",
       "        0.6118988 , 0.6179618 , 0.5898587 , 0.629938  , 0.6168877 ,\n",
       "        0.62052226, 0.5922653 , 0.6315945 , 0.61528856, 0.61949354,\n",
       "        0.59153086, 0.63087815, 0.61508715, 0.61925864, 0.59148765,\n",
       "        0.63069504, 0.61505413, 0.6191428 , 0.5915275 , 0.6304793 ,\n",
       "        0.61497456, 0.61896193, 0.5915018 , 0.63017726, 0.61497295,\n",
       "        0.6188227 , 0.5915165 , 0.6299166 , 0.61495966, 0.6187146 ,\n",
       "        0.59156287, 0.62967366, 0.61494976, 0.61859286, 0.59164786,\n",
       "        0.6294006 , 0.61495626, 0.6183419 , 0.59157157, 0.62907326,\n",
       "        0.61503136, 0.61820537, 0.5915592 , 0.62879   , 0.6148291 ,\n",
       "        0.6180004 , 0.59163195, 0.6282494 , 0.6143784 , 0.61692125,\n",
       "        0.5904954 , 0.6291168 , 0.61710745, 0.6213511 , 0.59624493,\n",
       "        0.62752956, 0.61203843, 0.60159814, 0.5550959 ], dtype=float32),\n",
       " array([0.52273744, 0.5713197 , 0.6319328 , 0.5861769 , 0.66556597,\n",
       "        0.6048022 , 0.6456405 , 0.5804463 , 0.6630346 , 0.6075336 ,\n",
       "        0.64786595, 0.5822702 , 0.66413087, 0.60634524, 0.6470157 ,\n",
       "        0.5815511 , 0.66343427, 0.60613537, 0.6467569 , 0.581543  ,\n",
       "        0.6633892 , 0.6060807 , 0.6465934 , 0.58159655, 0.6632854 ,\n",
       "        0.6060131 , 0.6463895 , 0.58161604, 0.66315264, 0.6060036 ,\n",
       "        0.6461937 , 0.58169186, 0.66310376, 0.60602385, 0.6460526 ,\n",
       "        0.58181417, 0.6631346 , 0.60608125, 0.6460302 , 0.5820204 ,\n",
       "        0.66315883, 0.60611624, 0.6458787 , 0.5821015 , 0.6630764 ,\n",
       "        0.60613114, 0.6456721 , 0.5821699 , 0.66285247, 0.6059377 ,\n",
       "        0.6454339 , 0.5822816 , 0.66253626, 0.60560304, 0.64457154,\n",
       "        0.58169127, 0.66430146, 0.6077063 , 0.6481793 , 0.5862678 ,\n",
       "        0.6614769 , 0.6040628 , 0.6369448 , 0.5510125 ], dtype=float32),\n",
       " array([0.43703276, 0.5493238 , 0.5819086 , 0.5753434 , 0.5820675 ,\n",
       "        0.59317505, 0.59227836, 0.5698316 , 0.57917655, 0.59535074,\n",
       "        0.5936295 , 0.572061  , 0.5800477 , 0.5948359 , 0.5929141 ,\n",
       "        0.57128185, 0.57970953, 0.59454733, 0.59270823, 0.57118195,\n",
       "        0.57942766, 0.59429276, 0.5925892 , 0.5711111 , 0.5791567 ,\n",
       "        0.59400177, 0.59235036, 0.5709718 , 0.57884496, 0.59371156,\n",
       "        0.59219164, 0.5708993 , 0.57857794, 0.5934902 , 0.5921243 ,\n",
       "        0.57090837, 0.57836413, 0.59332937, 0.5921373 , 0.57100105,\n",
       "        0.5781203 , 0.59307873, 0.59197927, 0.5709626 , 0.5778094 ,\n",
       "        0.5927805 , 0.591812  , 0.57086194, 0.57745564, 0.592422  ,\n",
       "        0.5915805 , 0.5707323 , 0.5769382 , 0.59186673, 0.59093326,\n",
       "        0.5704801 , 0.5770892 , 0.59251547, 0.5948333 , 0.5732624 ,\n",
       "        0.57677   , 0.59123343, 0.5828757 , 0.54019964], dtype=float32),\n",
       " array([0.5357487 , 0.58108264, 0.68921113, 0.59151447, 0.6936976 ,\n",
       "        0.6153614 , 0.7017366 , 0.58962786, 0.69417167, 0.61866415,\n",
       "        0.7032716 , 0.59111685, 0.694327  , 0.61751604, 0.7022198 ,\n",
       "        0.59059334, 0.69390196, 0.6173161 , 0.70214105, 0.59057605,\n",
       "        0.69370615, 0.6171732 , 0.7020941 , 0.59056467, 0.6934502 ,\n",
       "        0.6169375 , 0.7019657 , 0.59052753, 0.69323057, 0.6168086 ,\n",
       "        0.7019522 , 0.5905488 , 0.6931437 , 0.61675525, 0.70200765,\n",
       "        0.59062827, 0.69311106, 0.61672693, 0.7020614 , 0.5907259 ,\n",
       "        0.6928969 , 0.61652714, 0.7018407 , 0.59070164, 0.6925932 ,\n",
       "        0.61636406, 0.70173705, 0.59070385, 0.6923351 , 0.6161286 ,\n",
       "        0.70172054, 0.59078604, 0.6918433 , 0.6156119 , 0.7009738 ,\n",
       "        0.5900512 , 0.6941136 , 0.6183886 , 0.7063491 , 0.59398013,\n",
       "        0.68878376, 0.6117765 , 0.6614342 , 0.55170053], dtype=float32),\n",
       " array([0.45107383, 0.57245886, 0.58984697, 0.5866445 , 0.6266272 ,\n",
       "        0.61202264, 0.61789227, 0.5899507 , 0.6297778 , 0.61686075,\n",
       "        0.62031347, 0.59223926, 0.63120997, 0.6150735 , 0.6191803 ,\n",
       "        0.5914958 , 0.6304698 , 0.6149397 , 0.61895394, 0.5914449 ,\n",
       "        0.63021374, 0.6148901 , 0.6187804 , 0.5913988 , 0.6299311 ,\n",
       "        0.6147585 , 0.6185462 , 0.5913416 , 0.62967956, 0.6147686 ,\n",
       "        0.61839515, 0.59136724, 0.62950736, 0.61485547, 0.61836195,\n",
       "        0.59146786, 0.6293746 , 0.61498076, 0.61838514, 0.591598  ,\n",
       "        0.6291362 , 0.61490005, 0.6181861 , 0.59155077, 0.6287648 ,\n",
       "        0.6148463 , 0.6179898 , 0.59153783, 0.62844396, 0.61475664,\n",
       "        0.6178399 , 0.591692  , 0.6279753 , 0.61450726, 0.6168646 ,\n",
       "        0.59056455, 0.6289261 , 0.6172904 , 0.62137437, 0.5962981 ,\n",
       "        0.6274158 , 0.61216944, 0.6016632 , 0.55509955], dtype=float32),\n",
       " array([0.5227813 , 0.57136506, 0.6318511 , 0.5863185 , 0.66567236,\n",
       "        0.60494024, 0.64564383, 0.5806097 , 0.6629013 , 0.6074694 ,\n",
       "        0.6476015 , 0.5822655 , 0.66374177, 0.60610914, 0.6466347 ,\n",
       "        0.58154935, 0.66318226, 0.6059673 , 0.646424  , 0.58156705,\n",
       "        0.66315305, 0.60592157, 0.6462135 , 0.5816123 , 0.6630299 ,\n",
       "        0.60583305, 0.6459955 , 0.5816738 , 0.66301554, 0.6058453 ,\n",
       "        0.6458384 , 0.58177197, 0.6630498 , 0.60591435, 0.64575195,\n",
       "        0.5818886 , 0.6630592 , 0.6060109 , 0.64570284, 0.58202595,\n",
       "        0.66291416, 0.6059691 , 0.6455122 , 0.5820708 , 0.6627806 ,\n",
       "        0.60594183, 0.6453314 , 0.5821657 , 0.66271794, 0.6058868 ,\n",
       "        0.64520687, 0.5823801 , 0.6625133 , 0.60571325, 0.64436007,\n",
       "        0.5818136 , 0.6642009 , 0.6078459 , 0.6480484 , 0.58638674,\n",
       "        0.66138184, 0.6041612 , 0.63697875, 0.55104566], dtype=float32),\n",
       " array([0.4370432 , 0.54939145, 0.5820304 , 0.5754907 , 0.5819803 ,\n",
       "        0.5931918 , 0.59232944, 0.5699175 , 0.57896894, 0.5951207 ,\n",
       "        0.5933385 , 0.57185686, 0.57961166, 0.5943681 , 0.5925383 ,\n",
       "        0.57105434, 0.5792057 , 0.59403497, 0.59236294, 0.57097214,\n",
       "        0.5789236 , 0.59374774, 0.59220743, 0.5708814 , 0.57862437,\n",
       "        0.59346503, 0.5920343 , 0.5708329 , 0.57831746, 0.5932233 ,\n",
       "        0.59193194, 0.5708238 , 0.5780703 , 0.5930252 , 0.5918728 ,\n",
       "        0.5708249 , 0.57786787, 0.59287053, 0.5918209 , 0.57079494,\n",
       "        0.57764447, 0.59262   , 0.5916152 , 0.57070726, 0.5773545 ,\n",
       "        0.5923479 , 0.5914808 , 0.57067406, 0.577054  , 0.59207416,\n",
       "        0.5913954 , 0.570687  , 0.5766105 , 0.5916045 , 0.59079164,\n",
       "        0.5704528 , 0.5768497 , 0.5923041 , 0.59471846, 0.57322174,\n",
       "        0.57661504, 0.5911075 , 0.5828353 , 0.540166  ], dtype=float32),\n",
       " array([0.5357087 , 0.581106  , 0.6889132 , 0.59141195, 0.69341147,\n",
       "        0.61522377, 0.70134246, 0.58957976, 0.69368356, 0.6182823 ,\n",
       "        0.7028479 , 0.59103346, 0.69388515, 0.6171503 , 0.70210946,\n",
       "        0.59057254, 0.69353235, 0.6169874 , 0.7020856 , 0.59056586,\n",
       "        0.6933389 , 0.61683565, 0.7020038 , 0.59055036, 0.69314086,\n",
       "        0.61667377, 0.70192885, 0.5905595 , 0.69291353, 0.61655873,\n",
       "        0.7018477 , 0.590562  , 0.6927255 , 0.6164901 , 0.7018796 ,\n",
       "        0.59061265, 0.6926106 , 0.616435  , 0.70188147, 0.59064496,\n",
       "        0.69246304, 0.61625266, 0.7017845 , 0.5906642 , 0.6922778 ,\n",
       "        0.61612004, 0.70170766, 0.59069264, 0.6921461 , 0.6160063 ,\n",
       "        0.7017566 , 0.5908416 , 0.6916925 , 0.6155407 , 0.7009361 ,\n",
       "        0.5900931 , 0.6939876 , 0.61833316, 0.70637834, 0.59401715,\n",
       "        0.6887538 , 0.61176753, 0.66141826, 0.5517015 ], dtype=float32),\n",
       " array([0.4510206 , 0.57247037, 0.5897137 , 0.58651567, 0.626032  ,\n",
       "        0.6117625 , 0.6176326 , 0.5897875 , 0.6290684 , 0.6163569 ,\n",
       "        0.61988133, 0.59204906, 0.630638  , 0.6148045 , 0.6188384 ,\n",
       "        0.59142435, 0.6300681 , 0.61479926, 0.6186498 , 0.5914113 ,\n",
       "        0.62984246, 0.6147814 , 0.6184713 , 0.5913911 , 0.6295592 ,\n",
       "        0.6147678 , 0.6183033 , 0.5913967 , 0.62927806, 0.61478484,\n",
       "        0.6181072 , 0.5913473 , 0.62901807, 0.61481535, 0.6179954 ,\n",
       "        0.5913808 , 0.6288862 , 0.61484617, 0.61794096, 0.5914279 ,\n",
       "        0.62870604, 0.614783  , 0.61781687, 0.59149265, 0.6284754 ,\n",
       "        0.6147933 , 0.6176827 , 0.59151614, 0.62819254, 0.6148216 ,\n",
       "        0.6176906 , 0.5917481 , 0.6277569 , 0.6145709 , 0.6167599 ,\n",
       "        0.5905747 , 0.6287351 , 0.6173458 , 0.62131244, 0.5963274 ,\n",
       "        0.6273683 , 0.6122651 , 0.6016657 , 0.5551251 ], dtype=float32),\n",
       " array([0.522427  , 0.5712026 , 0.6314874 , 0.586023  , 0.6646313 ,\n",
       "        0.6044344 , 0.6447382 , 0.5801769 , 0.66183203, 0.60687846,\n",
       "        0.6467705 , 0.58201694, 0.663329  , 0.6058307 , 0.646194  ,\n",
       "        0.5815825 , 0.663202  , 0.60590637, 0.6461992 , 0.581739  ,\n",
       "        0.66327333, 0.6059386 , 0.64608294, 0.58184284, 0.6631894 ,\n",
       "        0.60592145, 0.6458984 , 0.5819278 , 0.66309357, 0.6058924 ,\n",
       "        0.6456107 , 0.5819401 , 0.6629713 , 0.605891  , 0.64540315,\n",
       "        0.58204436, 0.6629367 , 0.60590506, 0.6452377 , 0.5821074 ,\n",
       "        0.6628288 , 0.6058632 , 0.6451485 , 0.58221513, 0.66279685,\n",
       "        0.60587215, 0.64500976, 0.5822732 , 0.6627358 , 0.6059124 ,\n",
       "        0.6449933 , 0.5824889 , 0.66251636, 0.60574716, 0.64420676,\n",
       "        0.5818744 , 0.6642326 , 0.6078843 , 0.64801466, 0.5865141 ,\n",
       "        0.66155475, 0.60426456, 0.6370695 , 0.5511227 ], dtype=float32),\n",
       " array([0.43687162, 0.5490221 , 0.581359  , 0.5749355 , 0.5814678 ,\n",
       "        0.59233165, 0.59125966, 0.5689839 , 0.5780918 , 0.5941718 ,\n",
       "        0.5925056 , 0.5712743 , 0.57889116, 0.59371907, 0.59217983,\n",
       "        0.5708804 , 0.5787113 , 0.59362686, 0.5922583 , 0.57100236,\n",
       "        0.57854646, 0.5934556 , 0.5921891 , 0.571006  , 0.5782678 ,\n",
       "        0.5931883 , 0.5920323 , 0.5709431 , 0.57791805, 0.5928469 ,\n",
       "        0.5917688 , 0.57079685, 0.57758904, 0.5925736 , 0.59164834,\n",
       "        0.57076955, 0.5773233 , 0.59237134, 0.59153366, 0.57070065,\n",
       "        0.5770759 , 0.59216166, 0.59140956, 0.57068205, 0.5768149 ,\n",
       "        0.5919118 , 0.5912601 , 0.5706027 , 0.5765724 , 0.5916817 ,\n",
       "        0.5912184 , 0.5705962 , 0.57620597, 0.5912775 , 0.5906323 ,\n",
       "        0.57036346, 0.5765627 , 0.5921035 , 0.5947006 , 0.57327753,\n",
       "        0.5765037 , 0.59107715, 0.58294064, 0.540239  ], dtype=float32),\n",
       " array([0.53477854, 0.5804663 , 0.6877957 , 0.591048  , 0.6924901 ,\n",
       "        0.6144761 , 0.7008783 , 0.58921635, 0.69316363, 0.61773694,\n",
       "        0.7029462 , 0.5909624 , 0.69370365, 0.6169239 , 0.7023513 ,\n",
       "        0.5906579 , 0.6934361 , 0.61688757, 0.70222634, 0.5906929 ,\n",
       "        0.6931365 , 0.61674887, 0.7020139 , 0.5906748 , 0.69283175,\n",
       "        0.6165902 , 0.70190907, 0.59067786, 0.6925262 , 0.6163629 ,\n",
       "        0.70177174, 0.59067476, 0.6923715 , 0.6162746 , 0.70175755,\n",
       "        0.5906776 , 0.6922128 , 0.6161721 , 0.7017227 , 0.59070486,\n",
       "        0.6920831 , 0.616031  , 0.7016352 , 0.5906943 , 0.69183934,\n",
       "        0.61584735, 0.7015431 , 0.5906817 , 0.6917708 , 0.6157909 ,\n",
       "        0.7017236 , 0.59082127, 0.69144154, 0.61537427, 0.7009702 ,\n",
       "        0.5900924 , 0.6939027 , 0.6183025 , 0.70649374, 0.5940677 ,\n",
       "        0.6887343 , 0.6118252 , 0.66144544, 0.5517223 ], dtype=float32),\n",
       " array([0.4505616 , 0.57168734, 0.58886707, 0.5860905 , 0.62517625,\n",
       "        0.61104786, 0.6167519 , 0.5893875 , 0.62854177, 0.6161101 ,\n",
       "        0.6194461 , 0.591991  , 0.6303622 , 0.6149287 , 0.6186907 ,\n",
       "        0.59153986, 0.6298841 , 0.61501503, 0.61856616, 0.59158003,\n",
       "        0.6296066 , 0.6149726 , 0.6182983 , 0.59151566, 0.6292482 ,\n",
       "        0.6149239 , 0.61808217, 0.59150434, 0.6289171 , 0.6148095 ,\n",
       "        0.6178235 , 0.59150237, 0.6286534 , 0.61485875, 0.61770034,\n",
       "        0.5914554 , 0.6283958 , 0.6148238 , 0.6176037 , 0.5914942 ,\n",
       "        0.62816805, 0.6147959 , 0.61750335, 0.5914426 , 0.6278504 ,\n",
       "        0.6146752 , 0.6173199 , 0.59138924, 0.627683  , 0.61476773,\n",
       "        0.6174232 , 0.5916319 , 0.6274239 , 0.614551  , 0.6166128 ,\n",
       "        0.59052604, 0.62858266, 0.6174644 , 0.6213038 , 0.5963329 ,\n",
       "        0.6273035 , 0.6124065 , 0.6016852 , 0.5551441 ], dtype=float32),\n",
       " array([0.5219556 , 0.57073975, 0.6310909 , 0.5859366 , 0.66431874,\n",
       "        0.6038462 , 0.6442307 , 0.58018994, 0.6621622 , 0.606729  ,\n",
       "        0.6466633 , 0.58223885, 0.6638764 , 0.606024  , 0.6462137 ,\n",
       "        0.5819113 , 0.66356844, 0.6061498 , 0.64614165, 0.5820623 ,\n",
       "        0.663324  , 0.6060854 , 0.64575464, 0.5820724 , 0.6629977 ,\n",
       "        0.60598356, 0.6453616 , 0.5820917 , 0.66281265, 0.6058839 ,\n",
       "        0.64513326, 0.5821923 , 0.662761  , 0.6058927 , 0.64492106,\n",
       "        0.5822036 , 0.6626327 , 0.6058336 , 0.6447964 , 0.58227086,\n",
       "        0.6625439 , 0.6057832 , 0.64462143, 0.58223784, 0.6623727 ,\n",
       "        0.6057045 , 0.64445245, 0.58228827, 0.66247886, 0.605825  ,\n",
       "        0.6445422 , 0.58252573, 0.66244876, 0.6057503 , 0.6440011 ,\n",
       "        0.5819656 , 0.6643586 , 0.60799843, 0.6479671 , 0.58660036,\n",
       "        0.6616459 , 0.6043903 , 0.6370962 , 0.55120337], dtype=float32),\n",
       " array([0.4366786 , 0.5487616 , 0.5808831 , 0.5747405 , 0.5808682 ,\n",
       "        0.5915524 , 0.59088093, 0.5689423 , 0.57742965, 0.5936163 ,\n",
       "        0.59249055, 0.5714238 , 0.5784379 , 0.59344244, 0.59233767,\n",
       "        0.5711259 , 0.57840717, 0.5934496 , 0.59232104, 0.57116526,\n",
       "        0.57818156, 0.5931892 , 0.59202206, 0.57100177, 0.57776344,\n",
       "        0.59279555, 0.59169745, 0.57080823, 0.5772953 , 0.59240305,\n",
       "        0.59148884, 0.57075363, 0.5769409 , 0.59207135, 0.5912868 ,\n",
       "        0.57061386, 0.5766112 , 0.5917596 , 0.5911611 , 0.5705466 ,\n",
       "        0.57634187, 0.5914717 , 0.5909185 , 0.57036674, 0.57608545,\n",
       "        0.5912022 , 0.59080195, 0.5703459 , 0.5759439 , 0.5911185 ,\n",
       "        0.590911  , 0.5704576 , 0.57579094, 0.5909421 , 0.59053546,\n",
       "        0.57037735, 0.5763463 , 0.5919562 , 0.5947072 , 0.573334  ,\n",
       "        0.57643276, 0.5910682 , 0.5829893 , 0.5402742 ], dtype=float32),\n",
       " array([0.5341144 , 0.57995594, 0.68709564, 0.5910585 , 0.6919396 ,\n",
       "        0.6140574 , 0.70089734, 0.58932203, 0.692852  , 0.61760706,\n",
       "        0.7031855 , 0.59112084, 0.6935499 , 0.6169909 , 0.70253813,\n",
       "        0.5908452 , 0.6932188 , 0.6168764 , 0.7020805 , 0.59078676,\n",
       "        0.69270706, 0.6165265 , 0.701424  , 0.5905702 , 0.6922171 ,\n",
       "        0.61621386, 0.70124555, 0.59055763, 0.69195926, 0.61597353,\n",
       "        0.7011611 , 0.5905658 , 0.6916657 , 0.61576647, 0.7011219 ,\n",
       "        0.59055233, 0.69156945, 0.61568815, 0.70139575, 0.59064275,\n",
       "        0.69153726, 0.6155499 , 0.70145833, 0.59066707, 0.69153893,\n",
       "        0.6155285 , 0.70160675, 0.5907067 , 0.6916064 , 0.6156342 ,\n",
       "        0.70184577, 0.59087634, 0.69144434, 0.61538994, 0.7011736 ,\n",
       "        0.590162  , 0.6939419 , 0.6183671 , 0.706573  , 0.5941065 ,\n",
       "        0.6887678 , 0.6118988 , 0.66145325, 0.55173975], dtype=float32),\n",
       " array([0.4501048 , 0.5711665 , 0.588483  , 0.5861867 , 0.6245481 ,\n",
       "        0.6110853 , 0.6163034 , 0.5893933 , 0.6281295 , 0.6164179 ,\n",
       "        0.6192426 , 0.5920747 , 0.6301681 , 0.61534184, 0.6186782 ,\n",
       "        0.59174407, 0.6296782 , 0.6152191 , 0.61841744, 0.59173566,\n",
       "        0.6290815 , 0.6148233 , 0.61783695, 0.5913629 , 0.62827677,\n",
       "        0.614531  , 0.6175093 , 0.59131825, 0.6278313 , 0.6144279 ,\n",
       "        0.61731267, 0.59121054, 0.62742734, 0.6143145 , 0.6171347 ,\n",
       "        0.59112346, 0.6272365 , 0.61440283, 0.6172016 , 0.5912528 ,\n",
       "        0.627328  , 0.6144569 , 0.617199  , 0.5913786 , 0.627415  ,\n",
       "        0.6147059 , 0.61723626, 0.5914792 , 0.627517  , 0.61499166,\n",
       "        0.6173878 , 0.59175676, 0.6274365 , 0.614913  , 0.6167002 ,\n",
       "        0.59064126, 0.62862635, 0.6177325 , 0.62140334, 0.596403  ,\n",
       "        0.62727207, 0.6125529 , 0.6017697 , 0.55518234], dtype=float32),\n",
       " array([0.52164924, 0.57060486, 0.63107204, 0.58622944, 0.6647056 ,\n",
       "        0.60405064, 0.64405686, 0.5805903 , 0.66260487, 0.60713136,\n",
       "        0.6464856 , 0.5826637 , 0.66413534, 0.6064237 , 0.6461351 ,\n",
       "        0.5822927 , 0.66347635, 0.60628766, 0.6459177 , 0.58229405,\n",
       "        0.66263473, 0.60579026, 0.6449978 , 0.58185464, 0.6617369 ,\n",
       "        0.6053407 , 0.6443696 , 0.5817304 , 0.6614715 , 0.605165  ,\n",
       "        0.6440175 , 0.58167416, 0.66135764, 0.6050986 , 0.6438051 ,\n",
       "        0.5817348 , 0.6616014 , 0.6053251 , 0.6439445 , 0.5820291 ,\n",
       "        0.6620941 , 0.60556006, 0.6443176 , 0.58241653, 0.66270536,\n",
       "        0.60593456, 0.64470786, 0.58273333, 0.6631486 , 0.60623515,\n",
       "        0.64494234, 0.5830231 , 0.66312057, 0.60619414, 0.6443957 ,\n",
       "        0.58232343, 0.66477054, 0.6082905 , 0.6481845 , 0.5867443 ,\n",
       "        0.66171205, 0.6045097 , 0.63718134, 0.5512499 ], dtype=float32),\n",
       " array([0.43657124, 0.5487546 , 0.58095497, 0.5749987 , 0.5806008 ,\n",
       "        0.59123415, 0.59101284, 0.5692465 , 0.57707006, 0.5933824 ,\n",
       "        0.5926668 , 0.5716969 , 0.57813334, 0.593305  , 0.5924187 ,\n",
       "        0.571304  , 0.5780745 , 0.59318876, 0.5920894 , 0.5710959 ,\n",
       "        0.5775628 , 0.5924204 , 0.59107006, 0.57028115, 0.5766578 ,\n",
       "        0.5914622 , 0.5903833 , 0.56979895, 0.575955  , 0.5907821 ,\n",
       "        0.5899537 , 0.56947154, 0.5755668 , 0.5903954 , 0.58982676,\n",
       "        0.56949735, 0.5754869 , 0.5905204 , 0.5901923 , 0.5698154 ,\n",
       "        0.57555294, 0.5907435 , 0.5906754 , 0.57036424, 0.5757984 ,\n",
       "        0.5911007 , 0.59111726, 0.5708143 , 0.5759633 , 0.59129494,\n",
       "        0.5914113 , 0.5710443 , 0.57594097, 0.5911751 , 0.59096605,\n",
       "        0.5707965 , 0.5764743 , 0.59208393, 0.5948535 , 0.57347804,\n",
       "        0.5764805 , 0.5911115 , 0.583017  , 0.5403044 ], dtype=float32),\n",
       " array([0.5340357 , 0.5799135 , 0.687046  , 0.5912633 , 0.6919302 ,\n",
       "        0.6140162 , 0.7008205 , 0.589465  , 0.6927066 , 0.6176291 ,\n",
       "        0.70307463, 0.5912114 , 0.69334364, 0.6169771 , 0.7023468 ,\n",
       "        0.5909376 , 0.69281983, 0.6165841 , 0.70147836, 0.59066653,\n",
       "        0.691713  , 0.6156511 , 0.7005025 , 0.5901706 , 0.691013  ,\n",
       "        0.6151518 , 0.7009723 , 0.5902637 , 0.6909834 , 0.6149116 ,\n",
       "        0.70126295, 0.59027565, 0.6911167 , 0.61494374, 0.70166576,\n",
       "        0.59043133, 0.6914637 , 0.61532205, 0.70200944, 0.5905848 ,\n",
       "        0.69186735, 0.61564845, 0.7023531 , 0.5909392 , 0.69210696,\n",
       "        0.6158925 , 0.7021088 , 0.5910074 , 0.69193435, 0.6159738 ,\n",
       "        0.7019656 , 0.5911097 , 0.69152236, 0.61562157, 0.7010833 ,\n",
       "        0.5902454 , 0.69387   , 0.6184063 , 0.70639426, 0.5940993 ,\n",
       "        0.68869054, 0.61193913, 0.6613938 , 0.55174303], dtype=float32),\n",
       " array([0.44992062, 0.57117814, 0.58864594, 0.5865097 , 0.62428594,\n",
       "        0.61138487, 0.6163287 , 0.5895628 , 0.62772954, 0.61670476,\n",
       "        0.6192548 , 0.59217113, 0.62976664, 0.61547714, 0.61866444,\n",
       "        0.59189427, 0.62914896, 0.61495984, 0.6180712 , 0.5915302 ,\n",
       "        0.62799156, 0.61391795, 0.6169069 , 0.59076524, 0.62707084,\n",
       "        0.61369073, 0.6166088 , 0.59087044, 0.6271978 , 0.6138505 ,\n",
       "        0.61659116, 0.59091735, 0.627316  , 0.61427003, 0.6167557 ,\n",
       "        0.5911877 , 0.6275757 , 0.61487544, 0.6171164 , 0.59141904,\n",
       "        0.62783635, 0.6153456 , 0.61767966, 0.59190476, 0.62799835,\n",
       "        0.6156151 , 0.61785144, 0.5919508 , 0.6277865 , 0.61559415,\n",
       "        0.6177831 , 0.59205467, 0.62747645, 0.6152374 , 0.61683667,\n",
       "        0.59070307, 0.62855524, 0.6177693 , 0.6213682 , 0.5963513 ,\n",
       "        0.6272192 , 0.61259896, 0.601778  , 0.555178  ], dtype=float32),\n",
       " array([0.5215266 , 0.5707604 , 0.63124   , 0.5864885 , 0.664732  ,\n",
       "        0.6043763 , 0.6439681 , 0.5808284 , 0.6623428 , 0.6073551 ,\n",
       "        0.6462642 , 0.58280736, 0.66370964, 0.60648155, 0.64597577,\n",
       "        0.5824338 , 0.66281235, 0.6059763 , 0.6454632 , 0.582101  ,\n",
       "        0.6615815 , 0.60498774, 0.6442709 , 0.5815956 , 0.6615153 ,\n",
       "        0.6048624 , 0.6441572 , 0.5820614 , 0.66268927, 0.6053134 ,\n",
       "        0.64468163, 0.582548  , 0.6637329 , 0.6059303 , 0.64529973,\n",
       "        0.5830565 , 0.66429293, 0.6064491 , 0.6455386 , 0.58319646,\n",
       "        0.6645234 , 0.60682744, 0.64595836, 0.5834318 , 0.6643686 ,\n",
       "        0.607015  , 0.6459408 , 0.5833627 , 0.6638275 , 0.6069125 ,\n",
       "        0.64566815, 0.58340144, 0.6631641 , 0.60652924, 0.6445482 ,\n",
       "        0.5824812 , 0.66456807, 0.6083507 , 0.6481499 , 0.58675313,\n",
       "        0.66162777, 0.60452366, 0.63723063, 0.5512417 ], dtype=float32),\n",
       " array([0.43655455, 0.54882944, 0.58109015, 0.5751859 , 0.5805585 ,\n",
       "        0.59111726, 0.5909476 , 0.5692823 , 0.57685816, 0.5931316 ,\n",
       "        0.59241307, 0.5715713 , 0.57783866, 0.5929865 , 0.5921417 ,\n",
       "        0.5711237 , 0.5776232 , 0.5925394 , 0.59136236, 0.5704661 ,\n",
       "        0.5767462 , 0.59133184, 0.5901405 , 0.5697174 , 0.5758352 ,\n",
       "        0.59071463, 0.59046495, 0.5701468 , 0.57570624, 0.5908635 ,\n",
       "        0.5911912 , 0.57087076, 0.5760199 , 0.59135693, 0.5918746 ,\n",
       "        0.5715651 , 0.5762875 , 0.591728  , 0.59217924, 0.5717416 ,\n",
       "        0.5765134 , 0.59194815, 0.592449  , 0.5718459 , 0.5767379 ,\n",
       "        0.5920682 , 0.59225523, 0.5716654 , 0.5767393 , 0.5919699 ,\n",
       "        0.5920125 , 0.5714834 , 0.5764304 , 0.59155184, 0.5912015 ,\n",
       "        0.5709523 , 0.5766586 , 0.5921722 , 0.5948369 , 0.5734385 ,\n",
       "        0.57647383, 0.59108806, 0.5829838 , 0.5403061 ], dtype=float32),\n",
       " array([0.5340132 , 0.5799551 , 0.6870075 , 0.59134257, 0.69186187,\n",
       "        0.61392766, 0.7005356 , 0.589434  , 0.69247884, 0.61744493,\n",
       "        0.70280534, 0.59116876, 0.69316405, 0.6167666 , 0.70222706,\n",
       "        0.5909169 , 0.692459  , 0.61596715, 0.7011627 , 0.5904845 ,\n",
       "        0.6913401 , 0.61490107, 0.700721  , 0.59026086, 0.69141126,\n",
       "        0.6152282 , 0.70197815, 0.59079504, 0.6921546 , 0.6157559 ,\n",
       "        0.7025403 , 0.59119695, 0.6924969 , 0.616228  , 0.70250654,\n",
       "        0.5913787 , 0.69229853, 0.6164329 , 0.70227605, 0.59128386,\n",
       "        0.69253194, 0.6166429 , 0.70262784, 0.5913859 , 0.69264525,\n",
       "        0.6165146 , 0.70220566, 0.59122986, 0.6924012 , 0.61632615,\n",
       "        0.7018492 , 0.5911975 , 0.69174135, 0.61573935, 0.70068485,\n",
       "        0.5901696 , 0.69381094, 0.61829627, 0.70602995, 0.5939775 ,\n",
       "        0.6885762 , 0.6118413 , 0.66124403, 0.5516962 ], dtype=float32),\n",
       " array([0.4498661 , 0.57123166, 0.58868116, 0.58660895, 0.6241356 ,\n",
       "        0.61133265, 0.6162682 , 0.58952117, 0.6273444 , 0.61655056,\n",
       "        0.61913764, 0.5921292 , 0.62941337, 0.6153269 , 0.61864746,\n",
       "        0.5918772 , 0.6287186 , 0.6144318 , 0.6178591 , 0.591386  ,\n",
       "        0.627473  , 0.6136284 , 0.6168592 , 0.59105223, 0.6272484 ,\n",
       "        0.61462986, 0.6173295 , 0.59167415, 0.627975  , 0.6156354 ,\n",
       "        0.61807805, 0.59216577, 0.62819487, 0.6162185 , 0.61839205,\n",
       "        0.59230757, 0.6280794 , 0.6162485 , 0.61825323, 0.59209716,\n",
       "        0.6282138 , 0.6163374 , 0.61866313, 0.5922647 , 0.6284714 ,\n",
       "        0.6160574 , 0.6186493 , 0.59220773, 0.62819254, 0.6157305 ,\n",
       "        0.6184134 , 0.5923072 , 0.62763447, 0.6151456 , 0.6170798 ,\n",
       "        0.5907726 , 0.62846005, 0.61754745, 0.6213259 , 0.59633905,\n",
       "        0.62712455, 0.6124983 , 0.6017077 , 0.5551034 ], dtype=float32),\n",
       " array([0.52146614, 0.57080716, 0.6312262 , 0.58651364, 0.66450036,\n",
       "        0.6043186 , 0.64392567, 0.5807368 , 0.66204894, 0.6072054 ,\n",
       "        0.6462398 , 0.58276814, 0.6636306 , 0.60641074, 0.6461334 ,\n",
       "        0.5824632 , 0.6628177 , 0.60577416, 0.64577377, 0.5821664 ,\n",
       "        0.6623095 , 0.6052568 , 0.64522374, 0.5823181 , 0.66355544,\n",
       "        0.6062407 , 0.6456565 , 0.5831962 , 0.6648331 , 0.60729486,\n",
       "        0.6463633 , 0.58367234, 0.66480297, 0.6077646 , 0.6464402 ,\n",
       "        0.5836916 , 0.664155  , 0.60760474, 0.64597535, 0.5834403 ,\n",
       "        0.6639961 , 0.6076465 , 0.64607865, 0.58340925, 0.66389054,\n",
       "        0.60743237, 0.6463055 , 0.58324695, 0.6634929 , 0.6071087 ,\n",
       "        0.6462646 , 0.5832793 , 0.6627616 , 0.60647213, 0.64489716,\n",
       "        0.58233416, 0.66407794, 0.6081956 , 0.648236  , 0.5867114 ,\n",
       "        0.66138977, 0.6044751 , 0.6370455 , 0.5511991 ], dtype=float32),\n",
       " array([0.43653715, 0.54878885, 0.58101   , 0.5751024 , 0.5804441 ,\n",
       "        0.59088373, 0.59065485, 0.5690068 , 0.5766436 , 0.59281313,\n",
       "        0.59218377, 0.5714008 , 0.577711  , 0.5928025 , 0.59214365,\n",
       "        0.5710444 , 0.5776336 , 0.5923947 , 0.59144455, 0.57055974,\n",
       "        0.57696354, 0.591648  , 0.59115523, 0.57078916, 0.5766444 ,\n",
       "        0.5918182 , 0.59230417, 0.5717646 , 0.57712257, 0.5924445 ,\n",
       "        0.5930077 , 0.57225186, 0.5774908 , 0.59280443, 0.59285206,\n",
       "        0.5720655 , 0.57740223, 0.5926799 , 0.5924918 , 0.57185096,\n",
       "        0.5775008 , 0.5927812 , 0.5926864 , 0.57177126, 0.57763433,\n",
       "        0.59283465, 0.5925147 , 0.5716427 , 0.5776321 , 0.5927076 ,\n",
       "        0.5922199 , 0.5714843 , 0.577154  , 0.5920096 , 0.59114796,\n",
       "        0.570902  , 0.5772113 , 0.5924576 , 0.5948071 , 0.5734407 ,\n",
       "        0.5766673 , 0.59119004, 0.5830043 , 0.54028726], dtype=float32),\n",
       " array([0.5339364 , 0.5798759 , 0.68686974, 0.5912691 , 0.6916976 ,\n",
       "        0.61366445, 0.7005626 , 0.5893773 , 0.6925207 , 0.6173294 ,\n",
       "        0.7032434 , 0.59129035, 0.69354224, 0.6168876 , 0.7028626 ,\n",
       "        0.59105754, 0.6930666 , 0.6161139 , 0.7021592 , 0.5908448 ,\n",
       "        0.6926676 , 0.61578155, 0.70230436, 0.5910274 , 0.6931193 ,\n",
       "        0.6167285 , 0.70314497, 0.5914661 , 0.6937357 , 0.61724186,\n",
       "        0.70301837, 0.59148693, 0.69340795, 0.61704934, 0.70207477,\n",
       "        0.5911749 , 0.69286025, 0.61682725, 0.7017456 , 0.59106016,\n",
       "        0.69302845, 0.6170672 , 0.70224035, 0.5911267 , 0.6932921 ,\n",
       "        0.6169455 , 0.7023314 , 0.5911778 , 0.693185  , 0.6166827 ,\n",
       "        0.7021138 , 0.5912476 , 0.6923134 , 0.6158447 , 0.70078903,\n",
       "        0.5902534 , 0.6941712 , 0.618393  , 0.706064  , 0.5940204 ,\n",
       "        0.68873423, 0.61191857, 0.661149  , 0.5516942 ], dtype=float32),\n",
       " array([0.44980735, 0.57112646, 0.5886354 , 0.5864941 , 0.62392783,\n",
       "        0.6110723 , 0.6161942 , 0.5894238 , 0.6274077 , 0.61662096,\n",
       "        0.61934507, 0.59231126, 0.62990963, 0.6157614 , 0.61916196,\n",
       "        0.5921191 , 0.62942076, 0.6150508 , 0.6187088 , 0.59202427,\n",
       "        0.6288281 , 0.61520505, 0.61841595, 0.59216094, 0.6290997 ,\n",
       "        0.61655897, 0.6190917 , 0.592571  , 0.62952006, 0.6170434 ,\n",
       "        0.619645  , 0.59266156, 0.6292101 , 0.61647266, 0.61928034,\n",
       "        0.59236485, 0.6286529 , 0.61604375, 0.61879313, 0.59207237,\n",
       "        0.6287246 , 0.61621463, 0.61900795, 0.5921688 , 0.62910324,\n",
       "        0.6160717 , 0.6192312 , 0.59232014, 0.62903345, 0.61575586,\n",
       "        0.61911625, 0.59252214, 0.6283789 , 0.6149865 , 0.6175382 ,\n",
       "        0.590969  , 0.6289665 , 0.61751705, 0.62156254, 0.5965738 ,\n",
       "        0.6275213 , 0.61256135, 0.60174775, 0.55526096], dtype=float32),\n",
       " array([0.5213441 , 0.57073873, 0.63117206, 0.586398  , 0.6644213 ,\n",
       "        0.6042221 , 0.6439892 , 0.5807798 , 0.6627693 , 0.6075862 ,\n",
       "        0.6469067 , 0.5832087 , 0.6649965 , 0.6071795 , 0.6472012 ,\n",
       "        0.5829582 , 0.6645032 , 0.6068579 , 0.6473395 , 0.5830156 ,\n",
       "        0.6648029 , 0.607207  , 0.6474528 , 0.58351743, 0.66595805,\n",
       "        0.6083396 , 0.64788675, 0.5839679 , 0.6657419 , 0.6086444 ,\n",
       "        0.64785177, 0.5837615 , 0.6642091 , 0.6078908 , 0.64720464,\n",
       "        0.58321714, 0.6632947 , 0.60726905, 0.64650214, 0.58289903,\n",
       "        0.66336846, 0.6072909 , 0.64629316, 0.5828997 , 0.66354454,\n",
       "        0.6072493 , 0.6465622 , 0.5828528 , 0.66358167, 0.60709816,\n",
       "        0.6469586 , 0.58304936, 0.66340584, 0.6065284 , 0.64594626,\n",
       "        0.582312  , 0.6649168 , 0.6084386 , 0.6489906 , 0.5868622 ,\n",
       "        0.661841  , 0.60464346, 0.6371435 , 0.55128187], dtype=float32),\n",
       " array([0.43650842, 0.5487467 , 0.5808856 , 0.5749762 , 0.5804646 ,\n",
       "        0.59089446, 0.59085083, 0.5692023 , 0.57692707, 0.593346  ,\n",
       "        0.59313965, 0.57223547, 0.578476  , 0.59380716, 0.59342706,\n",
       "        0.57208884, 0.5788778 , 0.59392685, 0.593318  , 0.5721913 ,\n",
       "        0.5788313 , 0.5939705 , 0.5938113 , 0.57283187, 0.57900226,\n",
       "        0.5943676 , 0.59453696, 0.5732949 , 0.5794483 , 0.59460664,\n",
       "        0.5941193 , 0.57274985, 0.57916296, 0.5940794 , 0.59299076,\n",
       "        0.5719034 , 0.5785484 , 0.5934193 , 0.5923752 , 0.5715611 ,\n",
       "        0.5782816 , 0.5933023 , 0.5925118 , 0.571566  , 0.5783273 ,\n",
       "        0.5934093 , 0.5925733 , 0.5714663 , 0.5783007 , 0.5933984 ,\n",
       "        0.59269905, 0.5715735 , 0.57798386, 0.5928291 , 0.59190726,\n",
       "        0.57133675, 0.57812357, 0.5934597 , 0.5956574 , 0.57406306,\n",
       "        0.5772821 , 0.59178746, 0.58327   , 0.5405046 ], dtype=float32),\n",
       " array([0.5340192 , 0.57986   , 0.6870149 , 0.5913631 , 0.6921601 ,\n",
       "        0.6139405 , 0.7012454 , 0.5896899 , 0.6935698 , 0.6181807 ,\n",
       "        0.70416445, 0.59178585, 0.6947397 , 0.6179102 , 0.7035748 ,\n",
       "        0.5915171 , 0.6947099 , 0.6176233 , 0.70329994, 0.5915508 ,\n",
       "        0.69474715, 0.6178801 , 0.70331335, 0.59168494, 0.69486755,\n",
       "        0.6184102 , 0.7031629 , 0.59172964, 0.69465184, 0.6181543 ,\n",
       "        0.70242053, 0.59134614, 0.6938474 , 0.61732477, 0.70178455,\n",
       "        0.59103334, 0.6933352 , 0.6168999 , 0.7016268 , 0.5909151 ,\n",
       "        0.6933013 , 0.61710656, 0.7019588 , 0.5909293 , 0.6934229 ,\n",
       "        0.61713564, 0.7022641 , 0.5909747 , 0.69356537, 0.6171272 ,\n",
       "        0.7025925 , 0.5912277 , 0.6931375 , 0.61637986, 0.70151436,\n",
       "        0.5905461 , 0.6952025 , 0.6191044 , 0.7064445 , 0.5942716 ,\n",
       "        0.6891281 , 0.6121106 , 0.6611904 , 0.55178154], dtype=float32),\n",
       " array([0.44980437, 0.5711066 , 0.5888715 , 0.58663535, 0.6243125 ,\n",
       "        0.61158466, 0.6168245 , 0.5899631 , 0.628404  , 0.6177842 ,\n",
       "        0.62049615, 0.5930196 , 0.6310533 , 0.6168956 , 0.62043756,\n",
       "        0.59270364, 0.6307799 , 0.6165719 , 0.62047005, 0.59289074,\n",
       "        0.63076067, 0.61702114, 0.6205184 , 0.5930526 , 0.6308247 ,\n",
       "        0.61744523, 0.62072015, 0.59296644, 0.630578  , 0.61683583,\n",
       "        0.6203931 , 0.5925641 , 0.6300252 , 0.61583483, 0.61964303,\n",
       "        0.59233433, 0.62951154, 0.6154853 , 0.61901194, 0.59202623,\n",
       "        0.6292933 , 0.61573756, 0.6189001 , 0.59189194, 0.6294135 ,\n",
       "        0.6157752 , 0.6190296 , 0.59201014, 0.6296959 , 0.61590517,\n",
       "        0.6194046 , 0.5924605 , 0.6293207 , 0.61528224, 0.61834776,\n",
       "        0.59143573, 0.6299665 , 0.6179912 , 0.6224838 , 0.59694326,\n",
       "        0.62790275, 0.6124618 , 0.60192275, 0.5553545 ], dtype=float32),\n",
       " array([0.52145755, 0.57083124, 0.6314136 , 0.5864714 , 0.6651987 ,\n",
       "        0.6048132 , 0.64477444, 0.5812534 , 0.66400766, 0.60872406,\n",
       "        0.6479872 , 0.5836713 , 0.66583437, 0.60825   , 0.6481452 ,\n",
       "        0.5830804 , 0.6651484 , 0.6080749 , 0.64836025, 0.5830895 ,\n",
       "        0.66519845, 0.60842675, 0.6484022 , 0.58327913, 0.665119  ,\n",
       "        0.60873747, 0.6481592 , 0.58311105, 0.6639712 , 0.6080621 ,\n",
       "        0.6476681 , 0.5827063 , 0.6632093 , 0.60713536, 0.64749056,\n",
       "        0.58254105, 0.6634102 , 0.60683846, 0.6471979 , 0.5825228 ,\n",
       "        0.6637177 , 0.6069447 , 0.64669055, 0.58247876, 0.66350585,\n",
       "        0.6068565 , 0.64641833, 0.5825234 , 0.6636264 , 0.60698646,\n",
       "        0.64677024, 0.5826932 , 0.6635132 , 0.6067246 , 0.6462979 ,\n",
       "        0.58221626, 0.66512537, 0.6088073 , 0.6493162 , 0.5864773 ,\n",
       "        0.66134995, 0.6044551 , 0.63691837, 0.55107474], dtype=float32),\n",
       " array([0.43658972, 0.5488922 , 0.5811043 , 0.57516176, 0.5808871 ,\n",
       "        0.5915669 , 0.5917185 , 0.56999224, 0.5779489 , 0.5945595 ,\n",
       "        0.59426266, 0.5729917 , 0.57977396, 0.5951464 , 0.59429634,\n",
       "        0.5725724 , 0.58029234, 0.5954897 , 0.5942609 , 0.5726243 ,\n",
       "        0.5805333 , 0.59570146, 0.5944598 , 0.57282573, 0.58072805,\n",
       "        0.5957876 , 0.5942677 , 0.5724471 , 0.5805133 , 0.59538776,\n",
       "        0.5934689 , 0.5718445 , 0.579988  , 0.5947265 , 0.59295005,\n",
       "        0.5715893 , 0.57943404, 0.5941467 , 0.5927996 , 0.5716158 ,\n",
       "        0.57903767, 0.5938416 , 0.59266555, 0.57150406, 0.57865953,\n",
       "        0.5936539 , 0.5925165 , 0.5714259 , 0.57859683, 0.5937038 ,\n",
       "        0.592695  , 0.5714137 , 0.5785025 , 0.5934659 , 0.5922936 ,\n",
       "        0.57137656, 0.57877606, 0.5942165 , 0.59584767, 0.5738408 ,\n",
       "        0.5777852 , 0.5920859 , 0.5828915 , 0.54023373], dtype=float32),\n",
       " array([0.5346631 , 0.58009017, 0.6871694 , 0.5913475 , 0.6929    ,\n",
       "        0.6143751 , 0.7008469 , 0.58941513, 0.69409704, 0.61872274,\n",
       "        0.7034615 , 0.59140015, 0.6952086 , 0.6182809 , 0.70255446,\n",
       "        0.590928  , 0.69525844, 0.61819696, 0.7023978 , 0.5909312 ,\n",
       "        0.6953167 , 0.61832553, 0.70213556, 0.590896  , 0.69506437,\n",
       "        0.61815214, 0.7012854 , 0.5905465 , 0.69430494, 0.6174625 ,\n",
       "        0.70073843, 0.5902783 , 0.6938336 , 0.616917  , 0.70118463,\n",
       "        0.5904912 , 0.6937198 , 0.6166663 , 0.7011662 , 0.5904966 ,\n",
       "        0.69342446, 0.6166541 , 0.7009731 , 0.5904095 , 0.6931056 ,\n",
       "        0.6165816 , 0.7008534 , 0.5902767 , 0.6929961 , 0.61665326,\n",
       "        0.70108604, 0.59038186, 0.692872  , 0.61621934, 0.7005497 ,\n",
       "        0.58984995, 0.694993  , 0.61894447, 0.7056335 , 0.59378755,\n",
       "        0.6888464 , 0.61160415, 0.6611405 , 0.55163133], dtype=float32),\n",
       " array([0.44999564, 0.5712409 , 0.58941454, 0.5865005 , 0.62397146,\n",
       "        0.6115532 , 0.6169531 , 0.58921343, 0.62766784, 0.6172656 ,\n",
       "        0.6206088 , 0.59220016, 0.63030255, 0.61592364, 0.62034166,\n",
       "        0.5916911 , 0.6301566 , 0.61557496, 0.62044334, 0.59182745,\n",
       "        0.6302887 , 0.6155518 , 0.620368  , 0.59184545, 0.63003564,\n",
       "        0.61509645, 0.619891  , 0.5914103 , 0.62919664, 0.61424875,\n",
       "        0.6192083 , 0.59093314, 0.6285945 , 0.6138618 , 0.61895484,\n",
       "        0.5912388 , 0.6286627 , 0.6139585 , 0.6186879 , 0.5911416 ,\n",
       "        0.628272  , 0.61407924, 0.61838424, 0.5910301 , 0.6279527 ,\n",
       "        0.61408865, 0.6180457 , 0.5907193 , 0.6278223 , 0.61418843,\n",
       "        0.61809313, 0.5909386 , 0.62765086, 0.61382425, 0.61750025,\n",
       "        0.59013265, 0.62870896, 0.61648804, 0.62194   , 0.5960949 ,\n",
       "        0.62697864, 0.61089504, 0.60141206, 0.554801  ], dtype=float32),\n",
       " array([0.5215606 , 0.5707908 , 0.6319775 , 0.58596927, 0.66508746,\n",
       "        0.60435885, 0.6441938 , 0.5797395 , 0.6621599 , 0.607587  ,\n",
       "        0.64668584, 0.5817569 , 0.66316706, 0.60653603, 0.6462594 ,\n",
       "        0.58080095, 0.66226673, 0.6061807 , 0.64640844, 0.58062476,\n",
       "        0.66216534, 0.6061184 , 0.64641154, 0.5805441 , 0.6614473 ,\n",
       "        0.6056029 , 0.6458166 , 0.58008313, 0.6603551 , 0.60465723,\n",
       "        0.64500344, 0.579562  , 0.6602552 , 0.60441774, 0.64500284,\n",
       "        0.5800546 , 0.66117364, 0.60480607, 0.6451407 , 0.58036375,\n",
       "        0.661397  , 0.6050436 , 0.6451279 , 0.58064663, 0.66125154,\n",
       "        0.60487384, 0.6445468 , 0.58046365, 0.6608643 , 0.6047014 ,\n",
       "        0.6441543 , 0.58044064, 0.66029334, 0.6043903 , 0.6433618 ,\n",
       "        0.5798208 , 0.6617553 , 0.60656375, 0.64683455, 0.5845026 ,\n",
       "        0.6587852 , 0.60255593, 0.63570577, 0.5502391 ], dtype=float32),\n",
       " array([0.4364953 , 0.5481536 , 0.58082604, 0.5743462 , 0.5809086 ,\n",
       "        0.5903371 , 0.5903647 , 0.56802857, 0.5774728 , 0.5928361 ,\n",
       "        0.5920429 , 0.5703931 , 0.57889223, 0.59307504, 0.5914555 ,\n",
       "        0.5695165 , 0.5792092 , 0.59328777, 0.59135413, 0.56937444,\n",
       "        0.5794116 , 0.59338725, 0.5912622 , 0.5692745 , 0.57925344,\n",
       "        0.5929247 , 0.5904542 , 0.5685563 , 0.57849675, 0.59192395,\n",
       "        0.5894292 , 0.56778556, 0.5778699 , 0.59152085, 0.5898153 ,\n",
       "        0.5682259 , 0.57777715, 0.5915551 , 0.59017646, 0.56862336,\n",
       "        0.57768273, 0.5915034 , 0.59027785, 0.56887954, 0.57728505,\n",
       "        0.591058  , 0.5897519 , 0.5685217 , 0.57677376, 0.5905649 ,\n",
       "        0.58930016, 0.5681473 , 0.57637453, 0.59009105, 0.5885877 ,\n",
       "        0.5677617 , 0.5767465 , 0.5913666 , 0.59262556, 0.5707808 ,\n",
       "        0.576138  , 0.5900449 , 0.58134335, 0.5390083 ], dtype=float32),\n",
       " array([0.53284055, 0.57965165, 0.6903324 , 0.59208244, 0.69337595,\n",
       "        0.6154914 , 0.7069819 , 0.59146905, 0.69625753, 0.6201242 ,\n",
       "        0.70950055, 0.59283096, 0.69682246, 0.619379  , 0.708731  ,\n",
       "        0.5922635 , 0.6967946 , 0.6193132 , 0.70874083, 0.59221125,\n",
       "        0.69677067, 0.6192199 , 0.7085066 , 0.5922166 , 0.69609475,\n",
       "        0.6184775 , 0.70759344, 0.5917949 , 0.6951377 , 0.6175989 ,\n",
       "        0.7073217 , 0.5915513 , 0.6954475 , 0.6179348 , 0.7085701 ,\n",
       "        0.59206057, 0.6959492 , 0.6180858 , 0.7085768 , 0.5922593 ,\n",
       "        0.69579834, 0.618092  , 0.70831734, 0.59232867, 0.69515866,\n",
       "        0.6176337 , 0.7075457 , 0.592016  , 0.69450605, 0.61730224,\n",
       "        0.70736706, 0.59188956, 0.69392407, 0.6167706 , 0.70685077,\n",
       "        0.5913456 , 0.6964308 , 0.6198378 , 0.7105476 , 0.5949994 ,\n",
       "        0.69045496, 0.61233896, 0.66289574, 0.5518099 ], dtype=float32),\n",
       " array([0.4500965 , 0.5713792 , 0.5876291 , 0.5874157 , 0.6302011 ,\n",
       "        0.6149539 , 0.6188373 , 0.59335417, 0.636088  , 0.6221515 ,\n",
       "        0.62244827, 0.59559137, 0.6380112 , 0.6204096 , 0.6217252 ,\n",
       "        0.5949323 , 0.63800657, 0.6200827 , 0.6216867 , 0.59494185,\n",
       "        0.63810426, 0.61978406, 0.62154067, 0.59495497, 0.63757956,\n",
       "        0.6188537 , 0.6206789 , 0.5943935 , 0.636578  , 0.6181326 ,\n",
       "        0.61981064, 0.5940573 , 0.63650167, 0.6190008 , 0.6204155 ,\n",
       "        0.59475017, 0.6370327 , 0.61943376, 0.6207981 , 0.5950721 ,\n",
       "        0.636829  , 0.619608  , 0.62082183, 0.5951752 , 0.63622266,\n",
       "        0.6191297 , 0.6200984 , 0.59469354, 0.635437  , 0.61886024,\n",
       "        0.61954916, 0.5944299 , 0.6349705 , 0.618442  , 0.61859775,\n",
       "        0.59378004, 0.6361287 , 0.6215042 , 0.62297976, 0.59961843,\n",
       "        0.6328889 , 0.6145115 , 0.6026109 , 0.5560856 ], dtype=float32),\n",
       " array([0.5241326 , 0.5718866 , 0.6306404 , 0.5897283 , 0.6729589 ,\n",
       "        0.6104983 , 0.6496807 , 0.58745205, 0.6741642 , 0.6146001 ,\n",
       "        0.6520008 , 0.5888021 , 0.67438364, 0.61312985, 0.6513288 ,\n",
       "        0.587937  , 0.6740153 , 0.6127585 , 0.65136546, 0.58774054,\n",
       "        0.67391056, 0.61249924, 0.6513825 , 0.5876729 , 0.67334425,\n",
       "        0.6117681 , 0.65082145, 0.5873657 , 0.67305577, 0.6112434 ,\n",
       "        0.65042156, 0.58747095, 0.674147  , 0.6120439 , 0.65102255,\n",
       "        0.58820176, 0.6748439 , 0.61263967, 0.6513041 , 0.58843106,\n",
       "        0.67449534, 0.6128201 , 0.65133625, 0.58856905, 0.6740168 ,\n",
       "        0.61243737, 0.65085536, 0.5884622 , 0.6737855 , 0.6121578 ,\n",
       "        0.65043503, 0.5885324 , 0.6736015 , 0.611781  , 0.64987284,\n",
       "        0.5883794 , 0.67471564, 0.61381996, 0.65348613, 0.59183496,\n",
       "        0.6684935 , 0.6071    , 0.6390164 , 0.5510679 ], dtype=float32),\n",
       " array([0.4377132 , 0.55217063, 0.5854468 , 0.58065504, 0.5838365 ,\n",
       "        0.6005379 , 0.601491  , 0.57993263, 0.58240145, 0.6037855 ,\n",
       "        0.60287976, 0.5822017 , 0.58384234, 0.6035956 , 0.602304  ,\n",
       "        0.5815402 , 0.5838342 , 0.6036256 , 0.6022359 , 0.5813842 ,\n",
       "        0.5838542 , 0.6035449 , 0.60212016, 0.58115923, 0.58348566,\n",
       "        0.6029065 , 0.60143065, 0.5806833 , 0.5827201 , 0.60215867,\n",
       "        0.60117185, 0.5808841 , 0.58252084, 0.60238266, 0.6021206 ,\n",
       "        0.58161855, 0.5829429 , 0.6027612 , 0.60234386, 0.58171296,\n",
       "        0.58297944, 0.60279846, 0.60226077, 0.58167136, 0.5826638 ,\n",
       "        0.60228264, 0.60181385, 0.5814338 , 0.58208454, 0.6016392 ,\n",
       "        0.6014552 , 0.5812536 , 0.5814594 , 0.6010435 , 0.601017  ,\n",
       "        0.5814624 , 0.5816579 , 0.6017972 , 0.6031203 , 0.5823824 ,\n",
       "        0.5792719 , 0.5956058 , 0.5850873 , 0.54258776], dtype=float32),\n",
       " array([0.5067802 , 0.56514984, 0.65299875, 0.567517  , 0.6515069 ,\n",
       "        0.5961676 , 0.6601005 , 0.5701006 , 0.6508037 , 0.5997861 ,\n",
       "        0.65850616, 0.57151675, 0.6504444 , 0.5993196 , 0.65847886,\n",
       "        0.571209  , 0.6504468 , 0.599238  , 0.6585354 , 0.5711256 ,\n",
       "        0.6503731 , 0.5990344 , 0.6584587 , 0.57101655, 0.64996964,\n",
       "        0.59825927, 0.6578477 , 0.57073224, 0.6493583 , 0.59770465,\n",
       "        0.65764326, 0.5707261 , 0.64926916, 0.59829074, 0.6583501 ,\n",
       "        0.5710955 , 0.6497948 , 0.5985812 , 0.6585169 , 0.57127655,\n",
       "        0.6499202 , 0.59862304, 0.6583924 , 0.57130814, 0.6496756 ,\n",
       "        0.59812033, 0.6579185 , 0.5711199 , 0.64912075, 0.5975638 ,\n",
       "        0.65756416, 0.57096905, 0.64847916, 0.5969588 , 0.6570654 ,\n",
       "        0.570633  , 0.6488405 , 0.59847003, 0.65865576, 0.5712853 ,\n",
       "        0.6421881 , 0.58751774, 0.6244945 , 0.5322936 ], dtype=float32),\n",
       " array([0.44304574, 0.5496191 , 0.5429998 , 0.5463761 , 0.5759508 ,\n",
       "        0.5752207 , 0.5665246 , 0.5542369 , 0.5800658 , 0.5797234 ,\n",
       "        0.5687502 , 0.5555354 , 0.5806677 , 0.5788111 , 0.568538  ,\n",
       "        0.5551668 , 0.580679  , 0.5785982 , 0.5684378 , 0.55504495,\n",
       "        0.5806597 , 0.5783147 , 0.5684133 , 0.55491924, 0.5801864 ,\n",
       "        0.5776152 , 0.56802595, 0.5546414 , 0.5792997 , 0.5774148 ,\n",
       "        0.5674473 , 0.55452573, 0.57909906, 0.5782025 , 0.5675729 ,\n",
       "        0.5548118 , 0.57961416, 0.57844466, 0.56803674, 0.5551399 ,\n",
       "        0.5798054 , 0.57855374, 0.5683112 , 0.555304  , 0.5794241 ,\n",
       "        0.57813156, 0.5681548 , 0.55507815, 0.5785793 , 0.57773954,\n",
       "        0.5677518 , 0.55482495, 0.5777556 , 0.5773723 , 0.56676954,\n",
       "        0.55424327, 0.57815266, 0.57864326, 0.56873083, 0.55426514,\n",
       "        0.57342106, 0.5669364 , 0.5514857 , 0.5165353 ], dtype=float32)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(pred_img[0][:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18,6))\n",
    "gs = gridspec.GridSpec(1, 10)\n",
    "gs.update(wspace = 0., hspace = 0.)\n",
    "ts = [0,5,9,10,12,14,16,18,19]\n",
    "xlables = [round(i,2) for i in list(np.linspace(np.min(lon),np.max(lon),5))]\n",
    "ylabels = [round(i,2) for i  in list(np.linspace(np.max(lat),np.min(lat),5))] \n",
    "for t in range(len(ts)):\n",
    "    #if t==0 : ax1=plt.subplot(gs[t])\n",
    "    ax1 = plt.subplot(gs[t])\n",
    "    input_image = input_images_[ts[t], :, :, 0] * (321.46630859375 - 235.2141571044922) + 235.2141571044922\n",
    "    plt.imshow(input_image, cmap = 'jet', vmin=270, vmax=300)\n",
    "    ax1.title.set_text(\"t = \" + str(ts[t]+1))\n",
    "    plt.setp([ax1], xticks = [], xticklabels = [], yticks = [], yticklabels = [])\n",
    "    if t == 0:\n",
    "        plt.setp([ax1], xticks = list(np.linspace(0, 64, 3)), xticklabels = xlables, yticks = list(np.linspace(0, 64, 3)), yticklabels = ylabels)\n",
    "        plt.ylabel(\"Ground Truth\", fontsize=10)\n",
    "plt.savefig(os.path.join(args.output_png_dir, \"Ground_Truth_Sample_\" + str(name) + \".jpg\"))\n",
    "plt.clf()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
