{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gongbing/anaconda3/envs/GAN_practice/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/gongbing/anaconda3/envs/GAN_practice/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/gongbing/anaconda3/envs/GAN_practice/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/gongbing/anaconda3/envs/GAN_practice/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/gongbing/anaconda3/envs/GAN_practice/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/gongbing/anaconda3/envs/GAN_practice/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print'. Did you mean print('GeneratorModel: saved summaries')? (avg_g_model.py, line 292)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/Users/gongbing/anaconda3/envs/GAN_practice/lib/python3.6/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3331\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-cfbc23dc3c80>\"\u001b[0;36m, line \u001b[0;32m16\u001b[0;36m, in \u001b[0;35m<module>\u001b[0;36m\u001b[0m\n\u001b[0;31m    from avg_g_model import *\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"/Users/gongbing/PycharmProjects/GAN_practice/avg_g_model.py\"\u001b[0;36m, line \u001b[0;32m292\u001b[0m\n\u001b[0;31m    print 'GeneratorModel: saved summaries'\u001b[0m\n\u001b[0m                                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m Missing parentheses in call to 'print'. Did you mean print('GeneratorModel: saved summaries')?\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import importlib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.slim import fully_connected as fc\n",
    "import matplotlib.pyplot as plt \n",
    "import glob\n",
    "from collections import OrderedDict\n",
    "%matplotlib inline\n",
    "from datetime import datetime\n",
    "import os\n",
    "from pathlib import Path\n",
    "import layer_def as ld\n",
    "import BasicConvLSTMCell\n",
    "#from BasicConvLSTMCell import BasicConvLSTMCell\n",
    "from avg_g_model import *\n",
    "from avg_d_model import *\n",
    "importlib.reload(ld)\n",
    "\n",
    "train_files = \"/Users/gongbing/PycharmProjects/video_prediction_savp/data/era5_size_64_64_3_3t_norm/train\"\n",
    "test_files = \"/Users/gongbing/PycharmProjects/video_prediction_savp/data/era5_size_64_64_3_3t_norm/test\"\n",
    "val_files = \"/Users/gongbing/PycharmProjects/video_prediction_savp/data/era5_size_64_64_3_3t_norm/train\"\n",
    "#hyparameters\n",
    "\n",
    "def set_save_name(name):\n",
    "    \"\"\"\n",
    "    Edits all constants dependent on SAVE_NAME.\n",
    "\n",
    "    @param name: The new save name.\n",
    "    \"\"\"\n",
    "    #global SAVE_NAME, MODEL_SAVE_DIR, SUMMARY_SAVE_DIR, IMG_SAVE_DIR\n",
    "\n",
    "    SAVE_NAME = name\n",
    "    MODEL_SAVE_DIR = get_dir(os.path.join(SAVE_DIR, 'Models/', SAVE_NAME))\n",
    "    SUMMARY_SAVE_DIR = get_dir(os.path.join(SAVE_DIR, 'Summaries/', SAVE_NAME))\n",
    "    IMG_SAVE_DIR = get_dir(os.path.join(SAVE_DIR, 'Images/', SAVE_NAME))\n",
    "    return SAVE_NAME, MODEL_SAVE_DIR,SUMMARY_SAVE_DIR,IMG_SAVE_DIR\n",
    "\n",
    "def get_dir(directory):\n",
    "    \"\"\"\n",
    "    Creates the given directory if it does not exist.\n",
    "\n",
    "    @param directory: The path to the directory.\n",
    "    @return: The path to the directory.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    return directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AVG(object):\n",
    "    \n",
    "        def __init__(self, learning_rate_g=0.00004, learning_rate_d=0.02,batch_size=32,\n",
    "                     checkpoint_dir=None,context_frames=10,\n",
    "                     sequence_length=20,adversarial=None,tranpose=[0,2,3,1],\n",
    "                     train_height=32,train_width=32,padding_g=\"SAME\",num_epochs=50,\n",
    "                     stats_freq=10,summary_freq=100,img_save_freq=1000,\n",
    "                     test_freq=5000,model_save_freq=10000):\n",
    "            \"\"\"\n",
    "            @params tranpose:None or list<int>, if tranpose the raw dataset, which tensor shape is [sequence_length, height,width,channel]\n",
    "            @params train_width/train_height: int, trian_height, train_width: the height and width of the patches to train on \n",
    "            @params padding_g:padding for convolutions in the generator model\n",
    "            @params num_epochs: int, the number of epochs for iteration\n",
    "            @params stats_freq: int, how often to print loss/train error stats, in # steps\n",
    "            @params summary_sesq:int, how often to save the summaries, in # steps\n",
    "            @params img_save_freq:int, how often to save generated images, in # steps\n",
    "            @params test_freq:int, how often to test the model on test data, in # steps\n",
    "            @params model_save_freq: how often to save the model, in # steps\n",
    "            \"\"\"\n",
    "            self.learning_rate_g = learning_rate_g\n",
    "            self.learning_rate_d = learning_rate_d\n",
    "            self.batch_size = batch_size\n",
    "            self.sequence_length = sequence_length\n",
    "            self.context_frames = context_frames\n",
    "            self.adversarial = adversarial\n",
    "            self.transpose = transpose\n",
    "            self.train_height = train_height \n",
    "            self.train_width = train_width\n",
    "            self.padding_g = padding_g\n",
    "            self.num_epochs = num_epochs\n",
    "            self.stats_freq = stats_freq\n",
    "            self.test_freq = test_freq\n",
    "            self.summary_freq = summary_freq\n",
    "            self.img_save_freq = img_save_freq\n",
    "            self.model_save_freq = model_save_freq\n",
    "            self.save_name,self.model_save_name,self.summary_save_dir,self.image_save_dir = set_save_name(cls.__name__)\n",
    "                      \n",
    "            \n",
    "        def runner(self):\n",
    "            self.load_checkpoints()\n",
    "            self.build_graph()\n",
    "            self.start_session_and_initialize()\n",
    "            self.train()\n",
    "            #self.test()\n",
    "            self.save()\n",
    "            \n",
    "        \n",
    "        def make_dataset(self,type=\"train\"):\n",
    "            \"\"\"\n",
    "            @param tranpose:None or list<int>, if tranpose the raw dataset, which tensor shape is [sequence_length, height,width,channel]\n",
    "            @return: A interator\n",
    "            \"\"\"\n",
    "            if type==\"train\": filenames = glob.glob(\"/Users/gongbing/PycharmProjects/video_prediction_savp/data/era5_size_64_64_3_3t_norm/train/*.tfrecords\")\n",
    "            if type==\"val\":filenames = glob.glob(\"/Users/gongbing/PycharmProjects/video_prediction_savp/data/era5_size_64_64_3_3t_norm/val/*.tfrecords\")\n",
    "            if type==\"test\":filenames = glob.glob(\"/Users/gongbing/PycharmProjects/video_prediction_savp/data/era5_size_64_64_3_3t_norm/test/*.tfrecords\")\n",
    "            def parser(serialized_example):\n",
    "                    seqs = OrderedDict()\n",
    "                    keys_to_features = {\n",
    "                        # 'width': tf.FixedLenFeature([], tf.int64),\n",
    "                        # 'height': tf.FixedLenFeature([], tf.int64),\n",
    "                        'sequence_length': tf.FixedLenFeature([], tf.int64),\n",
    "                        # 'channels': tf.FixedLenFeature([],tf.int64),\n",
    "                        # 'images/encoded':  tf.FixedLenFeature([], tf.string)\n",
    "                        'images/encoded': tf.VarLenFeature(tf.float32)\n",
    "                    }\n",
    "                    parsed_features = tf.parse_single_example(serialized_example, keys_to_features)\n",
    "                    seq = tf.sparse_tensor_to_dense(parsed_features[\"images/encoded\"])\n",
    "                    images = tf.reshape(seq, [self.sequence_length,64, 64,3], name=\"reshape_new\")\n",
    "                    if self.tranpose:\n",
    "                        images = tf.transpose(images,self.transpose)\n",
    "                    seqs[\"images\"] = images\n",
    "                    return seqs\n",
    "            dataset = tf.data.TFRecordDataset(filenames, buffer_size = 8 * 1024 * 1024)\n",
    "            dataset = dataset.repeat(num_epochs)\n",
    "            dataset = dataset.apply(tf.contrib.data.map_and_batch(\n",
    "                    parser, self.batch_size, drop_remainder = True, num_parallel_calls = None))\n",
    "            dataset = dataset.prefetch(self.batch_size) \n",
    "            iterator = dataset.make_initializable_iterator()\n",
    "            return iterator\n",
    "\n",
    "            \n",
    "        def data_construct(self):\n",
    "                  \n",
    "            self.train_iterator = make_dataset(type=\"train\",tranpose=self.tranpose,batch_size=self.batch_size)\n",
    "            self.val_iterator = make_dataset(type=\"val\",,tranpose=self.tranpose,batch_size=self.batch_size)\n",
    "            self.test_iterator = make_dataset(type=\"test\",tranpose=self.tranpose,batch_size=self.batch_size) \n",
    "            \n",
    "            dat_shape = self.train_iterator.get_shape().tolist()\n",
    "            self.height_test = dat_shape[1]\n",
    "            self.width_test = dat_shape[2]\n",
    "            self.channel = dat_shape[4]\n",
    "                               \n",
    "            with tf.name_scope('data'):\n",
    "                self.input_frames_train = tf.placeholder(\n",
    "                    tf.float32, shape=[None, self.height_train, self.width_train, self.channel * self.context_frames])\n",
    "                self.gt_frames_train = tf.placeholder(\n",
    "                    tf.float32, shape=[None, self.height_train, self.width_train, self.channel])\n",
    "\n",
    "                self.input_frames_test = tf.placeholder(\n",
    "                    tf.float32, shape=[None, self.height_test, self.width_test, self.channel * self.context_frames])\n",
    "                self.gt_frames_test = tf.placeholder(\n",
    "                    tf.float32, shape=[None, self.height_test, self.width_test, self.channel])\n",
    "\n",
    "                # use variable batch_size for more flexibility\n",
    "                self.batch_size_train = tf.shape(self.input_frames_train)[0]\n",
    "                self.batch_size_test = tf.shape(self.input_frames_test)[0]\n",
    "\n",
    "            ##\n",
    "            # Scale network setup and calculation\n",
    "            ##\n",
    "\n",
    "            self.summaries_train = []\n",
    "            self.scale_preds_train = []  # the generated images at each scale\n",
    "            self.scale_gts_train = []  # the ground truth images at each scale\n",
    "            self.d_scale_preds = []  # the predictions from the discriminator model\n",
    "\n",
    "            self.summaries_test = []\n",
    "            self.scale_preds_test = []  # the generated images at each scale\n",
    "            self.scale_gts_test = []  # the ground truth images at each scale\n",
    "\n",
    "            for scale_num in xrange(self.num_scale_nets):\n",
    "                with tf.name_scope('scale_' + str(scale_num)):\n",
    "                    with tf.name_scope('setup'):\n",
    "                        ws = []\n",
    "                        bs = []\n",
    "\n",
    "                        # create weights for kernels\n",
    "                        for i in xrange(len(self.scale_kernel_sizes[scale_num])):\n",
    "                            ws.append(w([self.scale_kernel_sizes[scale_num][i],\n",
    "                                         self.scale_kernel_sizes[scale_num][i],\n",
    "                                         self.scale_layer_fms[scale_num][i],\n",
    "                                         self.scale_layer_fms[scale_num][i + 1]]))\n",
    "                            bs.append(b([self.scale_layer_fms[scale_num][i + 1]]))\n",
    "\n",
    "                    with tf.name_scope('calculation'):\n",
    "                        def calculate(height, width, inputs, gts, last_gen_frames):\n",
    "                            # scale inputs and gts\n",
    "                            scale_factor = 1. / 2 ** ((self.num_scale_nets - 1) - scale_num)\n",
    "                            scale_height = int(height * scale_factor)\n",
    "                            scale_width = int(width * scale_factor)\n",
    "\n",
    "                            inputs = tf.image.resize_images(inputs, [scale_height, scale_width])\n",
    "                            scale_gts = tf.image.resize_images(gts, [scale_height, scale_width])\n",
    "\n",
    "                            # for all scales but the first, add the frame generated by the last\n",
    "                            # scale to the input\n",
    "                            if scale_num > 0:\n",
    "                                last_gen_frames = tf.image.resize_images(\n",
    "                                    last_gen_frames,[scale_height, scale_width])\n",
    "                                inputs = tf.concat(3, [inputs, last_gen_frames])\n",
    "\n",
    "                            # generated frame predictions\n",
    "                            preds = inputs\n",
    "\n",
    "                            # perform convolutions\n",
    "                            with tf.name_scope('convolutions'):\n",
    "                                for i in xrange(len(self.scale_kernel_sizes[scale_num])):\n",
    "                                    # Convolve layer\n",
    "                                    preds = tf.nn.conv2d(\n",
    "                                        preds, ws[i], [1, 1, 1, 1], padding=self.padding_g)\n",
    "\n",
    "                                    # Activate with ReLU (or Tanh for last layer)\n",
    "                                    if i == len(self.scale_kernel_sizes[scale_num]) - 1:\n",
    "                                        preds = tf.nn.tanh(preds + bs[i])\n",
    "                                    else:\n",
    "                                        preds = tf.nn.relu(preds + bs[i])\n",
    "\n",
    "                            return preds, scale_gts\n",
    "\n",
    "                        ##\n",
    "                        # Perform train calculation\n",
    "                        ##\n",
    "\n",
    "                        # for all scales but the first, add the frame generated by the last\n",
    "                        # scale to the input\n",
    "                        if scale_num > 0:\n",
    "                            last_scale_pred_train = self.scale_preds_train[scale_num - 1]\n",
    "                        else:\n",
    "                            last_scale_pred_train = None\n",
    "\n",
    "                        # calculate\n",
    "                        train_preds, train_gts = calculate(self.height_train,\n",
    "                                                           self.width_train,\n",
    "                                                           self.input_frames_train,\n",
    "                                                           self.gt_frames_train,\n",
    "                                                           last_scale_pred_train)\n",
    "                        self.scale_preds_train.append(train_preds)\n",
    "                        self.scale_gts_train.append(train_gts)\n",
    "\n",
    "                        # We need to run the network first to get generated frames, run the\n",
    "                        # discriminator on those frames to get d_scale_preds, then run this\n",
    "                        # again for the loss optimization.\n",
    "                        if self.adversarial:\n",
    "                            self.d_scale_preds.append(tf.placeholder(tf.float32, [None, 1]))\n",
    "\n",
    "                        ##\n",
    "                        # Perform test calculation\n",
    "                        ##\n",
    "\n",
    "                        # for all scales but the first, add the frame generated by the last\n",
    "                        # scale to the input\n",
    "                        if scale_num > 0:\n",
    "                            last_scale_pred_test = self.scale_preds_test[scale_num - 1]\n",
    "                        else:\n",
    "                            last_scale_pred_test = None\n",
    "\n",
    "                        # calculate\n",
    "                        test_preds, test_gts = calculate(self.height_test,\n",
    "                                                         self.width_test,\n",
    "                                                         self.input_frames_test,\n",
    "                                                         self.gt_frames_test,\n",
    "                                                         last_scale_pred_test)\n",
    "                        self.scale_preds_test.append(test_preds)\n",
    "                        self.scale_gts_test.append(test_gts)\n",
    "                        \n",
    "                        \n",
    "        def generator_training_construct(self):\n",
    "            with tf.name_scope('train'):\n",
    "                # global loss is the combined loss from every scale network\n",
    "                self.global_loss = combined_loss(self.scale_preds_train,\n",
    "                                                 self.scale_gts_train,\n",
    "                                                 self.d_scale_preds)\n",
    "                self.global_step = tf.Variable(0, trainable=False)\n",
    "                self.optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate_g, name='optimizer')\n",
    "                self.train_op = self.optimizer.minimize(self.global_loss,\n",
    "                                                        global_step=self.global_step,\n",
    "                                                        name='train_op')\n",
    "\n",
    "\n",
    "        def loss_summary_writer_construct(self):\n",
    "            # train loss summary\n",
    "            loss_summary = tf.scalar_summary('train_loss_G', self.global_loss)\n",
    "            self.summaries_train.append(loss_summary)\n",
    " \n",
    "\n",
    "        def performance_eval_construct(self):\n",
    "            with tf.name_scope('error'):\n",
    "                # error computation\n",
    "                # get error at largest scale\n",
    "                self.psnr_error_train = psnr_error(self.scale_preds_train[-1],\n",
    "                                                   self.gt_frames_train)\n",
    "                self.sharpdiff_error_train = sharp_diff_error(self.scale_preds_train[-1],\n",
    "                                                              self.gt_frames_train)\n",
    "                self.psnr_error_test = psnr_error(self.scale_preds_test[-1],\n",
    "                                                  self.gt_frames_test)\n",
    "                self.sharpdiff_error_test = sharp_diff_error(self.scale_preds_test[-1],\n",
    "                                                             self.gt_frames_test)\n",
    "                # train error summaries\n",
    "                summary_psnr_train = tf.scalar_summary('train_PSNR',\n",
    "                                                       self.psnr_error_train)\n",
    "                summary_sharpdiff_train = tf.scalar_summary('train_SharpDiff',\n",
    "                                                            self.sharpdiff_error_train)\n",
    "                self.summaries_train += [summary_psnr_train, summary_sharpdiff_train]\n",
    "\n",
    "                # test error\n",
    "                summary_psnr_test = tf.scalar_summary('test_PSNR',\n",
    "                                                      self.psnr_error_test)\n",
    "                summary_sharpdiff_test = tf.scalar_summary('test_SharpDiff',\n",
    "                                                           self.sharpdiff_error_test)\n",
    "                self.summaries_test += [summary_psnr_test, summary_sharpdiff_test]\n",
    "\n",
    "            # add summaries to visualize in TensorBoard\n",
    "            self.summaries_train = tf.merge_summary(self.summaries_train)\n",
    "            self.summaries_test = tf.merge_summary(self.summaries_test)\n",
    "        \n",
    "        \n",
    "        def train_generator(self,batch,discriminator=None):\n",
    "            \"\"\"\n",
    "            Runs a training step using the global loss on each of the scale networks.\n",
    "\n",
    "            @param batch: An array of shape\n",
    "                          [self.batch_size x self.height x self.width x (3 * (self.context_frames + 1))].\n",
    "                          The input and output frames, concatenated along the channel axis (index 3).\n",
    "            @param discriminator: The discriminator model. Default = None, if not adversarial.\n",
    "\n",
    "            @return: The global step.\n",
    "            \"\"\"\n",
    "            ##\n",
    "            # Split into inputs and outputs\n",
    "            ##\n",
    "\n",
    "            input_frames = batch[:, :, :, :-3]\n",
    "            gt_frames = batch[:, :, :, -3:]\n",
    "\n",
    "            ##\n",
    "            # Train\n",
    "            ##\n",
    "\n",
    "            feed_dict = {self.input_frames_train: input_frames, self.gt_frames_train: gt_frames}\n",
    "\n",
    "            if self.adversarial:\n",
    "                # Run the generator first to get generated frames\n",
    "                scale_preds = self.sess.run(self.scale_preds_train, feed_dict=feed_dict)\n",
    "\n",
    "                # Run the discriminator nets on those frames to get predictions\n",
    "                d_feed_dict = {}\n",
    "                for scale_num, gen_frames in enumerate(scale_preds):\n",
    "                    d_feed_dict[discriminator.scale_nets[scale_num].input_frames] = gen_frames\n",
    "                d_scale_preds = self.sess.run(discriminator.scale_preds, feed_dict=d_feed_dict)\n",
    "\n",
    "                # Add discriminator predictions to the\n",
    "                for i, preds in enumerate(d_scale_preds):\n",
    "                    feed_dict[self.d_scale_preds[i]] = preds\n",
    "\n",
    "            _, global_loss, global_psnr_error, global_sharpdiff_error, global_step, summaries = \\\n",
    "                self.sess.run([self.train_op,\n",
    "                               self.global_loss,\n",
    "                               self.psnr_error_train,\n",
    "                               self.sharpdiff_error_train,\n",
    "                               self.global_step,\n",
    "                               self.summaries_train],\n",
    "                              feed_dict=feed_dict)\n",
    "\n",
    "            ##\n",
    "            # User output\n",
    "            ##\n",
    "            if global_step % self.stats_freq == 0:\n",
    "                print('GeneratorModel : Step ', global_step)\n",
    "                print('                 Global Loss    : ', global_loss)\n",
    "                print('                 PSNR Error     : ', global_psnr_error)\n",
    "                print('                 Sharpdiff Error: ', global_sharpdiff_error)\n",
    "            if global_step % self.summary_freq == 0:\n",
    "                self.summary_writer.add_summary(summaries, global_step)\n",
    "                print ('GeneratorModel: saved summaries')\n",
    "            if global_step % self.img_save_freq == 0:\n",
    "                print ('-' * 30)\n",
    "                print ('Saving images...')\n",
    "\n",
    "                # if not adversarial, we didn't get the preds for each scale net before for the\n",
    "                # discriminator prediction, so do it now\n",
    "                if not self.adversarial:\n",
    "                    scale_preds = self.sess.run(self.scale_preds_train, feed_dict=feed_dict)\n",
    "\n",
    "                # re-generate scale gt_frames to avoid having to run through TensorFlow.\n",
    "                scale_gts = []\n",
    "                for scale_num in xrange(self.num_scale_nets):\n",
    "                    scale_factor = 1. / 2 ** ((self.num_scale_nets - 1) - scale_num)\n",
    "                    scale_height = int(self.height_train * scale_factor)\n",
    "                    scale_width = int(self.width_train * scale_factor)\n",
    "\n",
    "                    # resize gt_output_frames for scale and append to scale_gts_train\n",
    "                    scaled_gt_frames = np.empty([self.batch_size, scale_height, scale_width, 3])\n",
    "                    for i, img in enumerate(gt_frames):\n",
    "                        # for skimage.transform.resize, images need to be in range [0, 1], so normalize\n",
    "                        # to [0, 1] before resize and back to [-1, 1] after\n",
    "                        sknorm_img = (img / 2) + 0.5\n",
    "                        resized_frame = resize(sknorm_img, [scale_height, scale_width, 3])\n",
    "                        scaled_gt_frames[i] = (resized_frame - 0.5) * 2\n",
    "                    scale_gts.append(scaled_gt_frames)\n",
    "\n",
    "                # for every clip in the batch, save the inputs, scale preds and scale gts\n",
    "                for pred_num in xrange(len(input_frames)):\n",
    "                    pred_dir = get_dir(os.path.join(self.img_save_dir, 'Step_' + str(global_step),\n",
    "                                                      str(pred_num)))\n",
    "\n",
    "                    # save input images\n",
    "                    for frame_num in xrange(self.context_frames):\n",
    "                        img = input_frames[pred_num, :, :, (frame_num * 3):((frame_num + 1) * 3)]\n",
    "                        imsave(os.path.join(pred_dir, 'input_' + str(frame_num) + '.png'), img)\n",
    "\n",
    "                    # save preds and gts at each scale\n",
    "                    # noinspection PyUnboundLocalVariable\n",
    "                    for scale_num, scale_pred in enumerate(scale_preds):\n",
    "                        gen_img = scale_pred[pred_num]\n",
    "\n",
    "                        path = os.path.join(pred_dir, 'scale' + str(scale_num))\n",
    "                        gt_img = scale_gts[scale_num][pred_num]\n",
    "\n",
    "                        imsave(path + '_gen.png', gen_img)\n",
    "                        imsave(path + '_gt.png', gt_img)\n",
    "\n",
    "                print ('Saved images!')\n",
    "                print ('-' * 30)\n",
    "            return global_step\n",
    "        \n",
    "        \n",
    "        def train_discriminator(self):\n",
    "            pass\n",
    "    \n",
    "        def train(self,batch):\n",
    "            \"\"\"\n",
    "            Runs a training loop on the model networks.\n",
    "            \"\"\"\n",
    "            for i in xrange(self.num_epochs):\n",
    "                if self.adversarial:\n",
    "                    # update discriminator\n",
    "                    batch = get_train_batch()\n",
    "                    print ('Training discriminator...')\n",
    "                    self.d_model.train_step(batch, self.g_model)\n",
    "\n",
    "                # update generator\n",
    "                batch = get_train_batch() #Bing replace with iterator\n",
    "                print ('Training generator...')\n",
    "                self.global_step = self.g_model.train_step(\n",
    "                    batch, discriminator=(self.d_model if self.adversarial else None))\n",
    "\n",
    "                # save the models\n",
    "                if self.global_step % c.model_save_freq == 0:\n",
    "                    print ('-' * 30)\n",
    "                    print ('Saving models...')\n",
    "                    self.saver.save(self.sess,\n",
    "                                    self.model_save_dir + 'model.ckpt',\n",
    "                                    global_step=self.global_step)\n",
    "                    print ('Saved models!')\n",
    "                    print ('-' * 30)\n",
    "\n",
    "                # test generator model\n",
    "                if self.global_step % c.test_freq == 0:\n",
    "                    self.test()\n",
    "                    \n",
    "                    \n",
    "        def test(self):\n",
    "            \"\"\"\n",
    "            Runs one test step on the generator network.\n",
    "            \"\"\"\n",
    "            batch = get_test_batch(self.batch_size, num_rec_out=self.num_test_rec)\n",
    "            self.g_model.test_batch(\n",
    "                batch, self.global_step, num_rec_out=self.num_test_rec)\n",
    "            \n",
    "                  \n",
    "        def load_checkpoints(self):\n",
    "            pass\n",
    "        \n",
    "        \n",
    "    \n",
    "        \n",
    "\n",
    "        \n",
    "        def start_session_and_initialize(self):\n",
    "            print 'Init variables...'\n",
    "            self.saver = tf.train.Saver(keep_checkpoint_every_n_hours=2)\n",
    "            self.sess.run(tf.global_variables_initializer())\n",
    "            return None\n",
    "\n",
    "                    \n",
    "        def build_graph(self):\n",
    "            tf.reset_default_graph()\n",
    "            tf.set_random_seed(12345)\n",
    "            self.data_construct()\n",
    "            self.global_step = tf.train.get_or_create_global_step()\n",
    "            self.generator_training_construct()\n",
    "            self.loss_summary_writer_construct()\n",
    "            self.performance_eval_construct()\n",
    "         \n",
    "          \n",
    "        def predict(self):\n",
    "            pass\n",
    "               \n",
    "\n",
    "        \n",
    "        \n",
    "            \n",
    "            \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
