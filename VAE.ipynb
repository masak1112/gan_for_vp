{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial from https://github.com/shaohua0116/VAE-Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gongbing/anaconda3/envs/GAN_practice/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/gongbing/anaconda3/envs/GAN_practice/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/gongbing/anaconda3/envs/GAN_practice/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/gongbing/anaconda3/envs/GAN_practice/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/gongbing/anaconda3/envs/GAN_practice/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/gongbing/anaconda3/envs/GAN_practice/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.slim import fully_connected as fc\n",
    "import matplotlib.pyplot as plt \n",
    "import glob\n",
    "from collections import OrderedDict\n",
    "%matplotlib inline\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = \"/Users/gongbing/PycharmProjects/video_prediction_savp/data/era5_size_64_64_3_3t_norm/train\"\n",
    "test_files = \"/Users/gongbing/PycharmProjects/video_prediction_savp/data/era5_size_64_64_3_3t_norm/test\"\n",
    "val_files = \"/Users/gongbing/PycharmProjects/video_prediction_savp/data/era5_size_64_64_3_3t_norm/train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "batch_size=40\n",
    "input_dim=3\n",
    "\n",
    "num_sample = 1500\n",
    "def make_dataset(type=\"train\"):\n",
    "    if type==\"train\": filenames = glob.glob(\"/Users/gongbing/PycharmProjects/video_prediction_savp/data/era5_size_64_64_3_3t_norm/train/*.tfrecords\")\n",
    "    if type==\"val\":filenames = glob.glob(\"/Users/gongbing/PycharmProjects/video_prediction_savp/data/era5_size_64_64_3_3t_norm/val/*.tfrecords\")\n",
    "    if type==\"test\":filenames = glob.glob(\"/Users/gongbing/PycharmProjects/video_prediction_savp/data/era5_size_64_64_3_3t_norm/test/*.tfrecords\")\n",
    "    \n",
    "    def parser(serialized_example):\n",
    "            seqs = OrderedDict()\n",
    "            keys_to_features = {\n",
    "                # 'width': tf.FixedLenFeature([], tf.int64),\n",
    "                # 'height': tf.FixedLenFeature([], tf.int64),\n",
    "                'sequence_length': tf.FixedLenFeature([], tf.int64),\n",
    "                # 'channels': tf.FixedLenFeature([],tf.int64),\n",
    "                # 'images/encoded':  tf.FixedLenFeature([], tf.string)\n",
    "                'images/encoded': tf.VarLenFeature(tf.float32)\n",
    "            }\n",
    "\n",
    "            parsed_features = tf.parse_single_example(serialized_example, keys_to_features)\n",
    "            seq = tf.sparse_tensor_to_dense(parsed_features[\"images/encoded\"])\n",
    "            print(\"Seq= \",seq.shape)\n",
    "            images = tf.reshape(seq, [20,64, 64,3], name = \"reshape_new\")\n",
    "            seqs[\"images\"] = images\n",
    "            return seqs\n",
    "    dataset = tf.data.TFRecordDataset(filenames, buffer_size = 8 * 1024 * 1024)\n",
    "    dataset = dataset.repeat(num_epochs)\n",
    "    dataset = dataset.apply(tf.contrib.data.map_and_batch(\n",
    "            parser, batch_size, drop_remainder = True, num_parallel_calls = None))\n",
    "    #dataset = dataset.map(parser)\n",
    "    # num_parallel_calls = None if shuffle else 1  # for reproducibility (e.g. sampled subclips from the test set)\n",
    "    # dataset = dataset.apply(tf.contrib.data.map_and_batch(\n",
    "    #    _parser, batch_size, drop_remainder=True, num_parallel_calls=num_parallel_calls)) #  Bing: Parallel data mapping, num_parallel_calls normally depends on the hardware, however, normally should be equal to be the usalbe number of CPUs\n",
    "    dataset = dataset.prefetch(batch_size)  # Bing: Take the data to buffer inorder to save the waiting time for GPU\n",
    "    print(\"dataset\",dataset)\n",
    "    #dataset = dataset.repeat(max_step)\n",
    "    #dataset = dataset.batch(batch_size)\n",
    "    #iterator = dataset.make_one_shot_iterator() #One shot iterator will pool all the data once and memery issue\n",
    "    iterator = dataset.make_initializable_iterator()\n",
    "    return iterator\n",
    "\n",
    "class VariantionalAutoencoder(object):\n",
    "\n",
    "    def __init__(self, learning_rate=1e-4, batch_size=64, n_z=16):\n",
    "        # Set hyperparameters\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.n_z = n_z\n",
    "\n",
    "        # Build the graph\n",
    "        self.build()\n",
    "        # Initialize paramters\n",
    "        self.sess = tf.InteractiveSession()\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        # Summary op\n",
    "        self.loss_summary = tf.summary.scalar(\"losses\", self.recon_loss)\n",
    "        self.summary_op = tf.summary.merge_all()\n",
    "        self.summary_dir = \"./\"\n",
    "        self.train_log_file = self.summary_dir + \"/train_\"  + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        self.val_log_file = self.summary_dir + \"/val_\"  + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        self.train_writer = tf.summary.FileWriter(self.train_log_file, self.sess.graph)\n",
    "        self.val_writer = tf.summary.FileWriter(self.val_log_file, self.sess.graph)\n",
    "        self.sess.run(self.train_iterator.initializer)\n",
    "        self.sess.run(self.val_iterator.initializer)\n",
    "        \n",
    "    def vae_arc1(self):\n",
    "        \n",
    "        # Encode\n",
    "        # x -> z_mean, z_sigma -> z\n",
    "        f1 = fc(self.x, 128, scope='enc_fc1', activation_fn=tf.nn.relu)\n",
    "        f2 = fc(f1, 64, scope='enc_fc2', activation_fn=tf.nn.relu)\n",
    "        f3 = fc(f2, 32, scope='enc_fc3', activation_fn=tf.nn.relu)\n",
    "        self.z_mu = fc(f3, self.n_z, scope='enc_fc4_mu', \n",
    "                       activation_fn=None)\n",
    "        self.z_log_sigma_sq = fc(f3, self.n_z, scope='enc_fc4_sigma', \n",
    "                                 activation_fn=None)\n",
    "        eps = tf.random_normal(shape=tf.shape(self.z_log_sigma_sq),mean=0, stddev=1, dtype=tf.float32)\n",
    "        \n",
    "        self.z = self.z_mu + tf.sqrt(tf.exp(self.z_log_sigma_sq)) * eps\n",
    "\n",
    "        # Decode\n",
    "        # z -> x_hat\n",
    "        g1 = fc(self.z, 32, scope='dec_fc1', activation_fn=tf.nn.relu)\n",
    "        g2 = fc(g1, 64, scope='dec_fc2', activation_fn=tf.nn.relu)\n",
    "        g3 = fc(g2, 128, scope='dec_fc3', activation_fn=tf.nn.relu)\n",
    "        self.x_hat = fc(g3, input_dim, scope='dec_fc4', activation_fn=tf.sigmoid)\n",
    "        return \n",
    "\n",
    "    def vae_arc2(self):\n",
    "        \n",
    "        # Encode\n",
    "        # x -> z_mean, z_sigma -> z\n",
    "        f3 = fc(self.x, 32, scope='enc_fc1', activation_fn=tf.nn.relu)\n",
    "\n",
    "        self.z_mu = fc(f3, self.n_z, scope='enc_fc4_mu', \n",
    "                       activation_fn=None)\n",
    "        self.z_log_sigma_sq = fc(f3, self.n_z, scope='enc_fc4_sigma', \n",
    "                                 activation_fn=None)\n",
    "        eps = tf.random_normal(shape=tf.shape(self.z_log_sigma_sq),mean=0, stddev=1, dtype=tf.float32)\n",
    "        self.z = self.z_mu + tf.sqrt(tf.exp(self.z_log_sigma_sq)) * eps\n",
    "        \n",
    "        # Decode\n",
    "        # z -> x_hat\n",
    "        g1 = fc(self.z, 32, scope='dec_fc1', activation_fn=tf.nn.relu)\n",
    "        self.x_hat = fc(g1, input_dim, scope='dec_fc4', activation_fn=tf.sigmoid)\n",
    "        return  \n",
    "    \n",
    "        \n",
    "    # Build the netowrk and the loss functions\n",
    "    def build(self):\n",
    "        \n",
    "        tf.reset_default_graph()\n",
    "        self.train_iterator = make_dataset(type=\"train\")\n",
    "        self.val_iterator = make_dataset(type=\"val\")\n",
    "        self.test_iterator = make_dataset(type=\"test\")\n",
    "        self.x = tf.placeholder(tf.float32, [None,20,64,64,3])\n",
    "        \n",
    "        #ARCHITECTURE\n",
    "        self.vae_arc2()\n",
    "\n",
    "        # Loss\n",
    "        # Reconstruction loss\n",
    "        # Minimize the cross-entropy loss\n",
    "        epsilon = 1e-10\n",
    "        recon_loss = -tf.reduce_sum(\n",
    "            self.x[:,1:,:,:,:] * tf.log(epsilon+self.x_hat[:,:-1,:,:,:]) + \n",
    "            (1-self.x[:,1:,:,:,:]) * tf.log(epsilon+1-self.x_hat[:,:-1,:,:,:]), \n",
    "            axis=1\n",
    "        )\n",
    "        self.recon_loss = tf.reduce_mean(recon_loss)\n",
    "\n",
    "        # Latent loss\n",
    "        # KL divergence: measure the difference between two distributions\n",
    "        # Here we measure the divergence between \n",
    "        # the latent distribution and N(0, 1)\n",
    "        latent_loss = -0.5 * tf.reduce_sum(\n",
    "            1 + self.z_log_sigma_sq - tf.square(self.z_mu) - \n",
    "            tf.exp(self.z_log_sigma_sq), axis=1)\n",
    "        self.latent_loss = tf.reduce_mean(latent_loss)\n",
    "\n",
    "        self.total_loss = self.recon_loss + self.latent_loss\n",
    "        self.train_op = tf.train.AdamOptimizer(\n",
    "            learning_rate=self.learning_rate).minimize(self.total_loss)\n",
    "        \n",
    "        # Build a saver\n",
    "        self.saver = tf.train.Saver(tf.global_variables())\n",
    "        \n",
    "        self.losses = {\n",
    "            'recon_loss': self.recon_loss,\n",
    "            'latent_loss': self.latent_loss,\n",
    "            'total_loss': self.total_loss,\n",
    "        }      # H(x, x_hat) = -\\Sigma x*log(x_hat) + (1-x)*log(1-x_hat)\n",
    "\n",
    "        \n",
    "        return\n",
    "\n",
    "    # Execute the forward and the backward pass\n",
    "    def run_single_step(self,step):\n",
    "        try:\n",
    "            train_batch = self.sess.run(self.train_iterator.get_next())\n",
    "            print(\"Train_batch shape\",train_batch[\"images\"].shape)\n",
    "            x_hat, train_summary, _, train_losses = self.sess.run([self.x_hat,self.summary_op,self.train_op, self.recon_loss], feed_dict={self.x: train_batch[\"images\"]})\n",
    "            self.train_writer.add_summary(train_summary, step)\n",
    "            print(\"x_hat.shape\",x_hat.shape)\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print(\"train out of range error\")\n",
    "        \n",
    "        try:\n",
    "            val_batch = self.sess.run(self.val_iterator.get_next())\n",
    "            val_summary, _, val_losses = self.sess.run([self.summary_op,self.train_op, self.recon_loss], feed_dict={self.x: val_batch[\"images\"]})\n",
    "            self.val_writer.add_summary(val_summary, step)\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print(\"train out of range error\")\n",
    "        \n",
    "        return train_losses,val_losses\n",
    "\n",
    "    # x -> x_hat\n",
    "    def reconstructor(self, x):\n",
    "        x_hat = self.sess.run(self.x_hat, feed_dict={self.x: x})\n",
    "        return x_hat\n",
    "\n",
    "    # z -> x\n",
    "    def generator(self, z):\n",
    "        x_hat = self.sess.run(self.x_hat, feed_dict={self.z: z})\n",
    "        return x_hat\n",
    "    \n",
    "    \n",
    "    # x -> z\n",
    "    def transformer(self, x):\n",
    "        z = self.sess.run(self.z, feed_dict={self.x: x})\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(model_class, learning_rate=1e-4, \n",
    "            batch_size=64, num_epoch=100, n_z=16, log_step=5):\n",
    "    # Create a model    \n",
    "    model = model_class(learning_rate=learning_rate, batch_size=batch_size, n_z=n_z)\n",
    "\n",
    "    # Training loop    \n",
    "    for epoch in range(num_epoch):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Run an epoch\n",
    "        for iter in range(num_sample // batch_size):\n",
    "            # Get a batch\n",
    "            step = epoch*(num_sample // batch_size) +  iter\n",
    "            train_losses,val_losses = model.run_single_step(step=step)\n",
    "            print (\"Train_loss: {}; Val_loss{}\".format(train_losses,val_losses))\n",
    "            checkpoint_path = os.path.join(model.summary_dir, 'model.ckpt')\n",
    "            model.saver.save(model.sess, checkpoint_path, global_step =step)\n",
    "        end_time = time.time()\n",
    "        \n",
    "        # Log the loss\n",
    "#         if epoch % log_step == 0:\n",
    "#             log_str = '[Epoch {}] '.format(epoch)\n",
    "#             for k, v in self.recon_loss.items():\n",
    "#                 log_str += '{}: {:.3f}  '.format(k, v)\n",
    "#             log_str += '({:.3f} sec/epoch)'.format(end_time - start_time)\n",
    "#             print(log_str)\n",
    "\n",
    "    \n",
    "    print('Done!')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vae = trainer(VariantionalAutoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 2527), started 3:45:29 ago. (Use '!kill 2527' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"600\"\n",
       "            src=\"http://localhost:6006\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x639488ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard.notebook\n",
    "%tensorboard --logdir=./ --host localhost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = VariantionalAutoencoder(learning_rate=1e-4, batch_size=64, n_z=16)\n",
    "#First let's load meta graph and restore weights\n",
    "sess=tf.Session()  \n",
    "saver = tf.train.import_meta_graph('model.ckpt-115.meta')\n",
    "saver.restore(sess,'model.ckpt-115')\n",
    "#latest_checkpoints = saver.restore(sess,tf.train.latest_checkpoint('./'))\n",
    "# Now, let's access and create placeholders variables and\n",
    "# create feed-dict to feed new data\n",
    "graph = tf.get_default_graph()\n",
    "#op = sess.graph.get_operations()\n",
    "#graph.get_tensor_by_name(\"dec_fc4\")\n",
    "loaded_vars = tf.trainable_variables() \n",
    "#loaded_vars\n",
    "op_to_restore = graph.get_tensor_by_name(\"dec_fc4/biases:0\")\n",
    "test_iterator = make_dataset(type=\"test\")\n",
    "sess.run(test_iterator.initializer)\n",
    "test_batch = sess.run(test_iterator.get_next())\n",
    "# print(\"test_batch\",test_batch[\"images\"].shape)\n",
    "op_to_restore.eval(feed_dict={model.x: test_batch[\"images\"]})\n",
    "sess.run([model.x_hat,op_to_restore], feed_dict={model.x: test_batch[\"images\"]})\n",
    "#https://jhui.github.io/2017/03/08/TensorFlow-variable-sharing/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_checkpoint(model,manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'enc_fc1/weights:0' shape=(3, 32) dtype=float32_ref>,\n",
       " <tf.Variable 'enc_fc1/biases:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'enc_fc4_mu/weights:0' shape=(32, 16) dtype=float32_ref>,\n",
       " <tf.Variable 'enc_fc4_mu/biases:0' shape=(16,) dtype=float32_ref>,\n",
       " <tf.Variable 'enc_fc4_sigma/weights:0' shape=(32, 16) dtype=float32_ref>,\n",
       " <tf.Variable 'enc_fc4_sigma/biases:0' shape=(16,) dtype=float32_ref>,\n",
       " <tf.Variable 'dec_fc1/weights:0' shape=(16, 32) dtype=float32_ref>,\n",
       " <tf.Variable 'dec_fc1/biases:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'dec_fc4/weights:0' shape=(32, 3) dtype=float32_ref>,\n",
       " <tf.Variable 'dec_fc4/biases:0' shape=(3,) dtype=float32_ref>,\n",
       " <tf.Variable 'enc_fc1/weights:0' shape=(3, 32) dtype=float32_ref>,\n",
       " <tf.Variable 'enc_fc1/biases:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'enc_fc4_mu/weights:0' shape=(32, 16) dtype=float32_ref>,\n",
       " <tf.Variable 'enc_fc4_mu/biases:0' shape=(16,) dtype=float32_ref>,\n",
       " <tf.Variable 'enc_fc4_sigma/weights:0' shape=(32, 16) dtype=float32_ref>,\n",
       " <tf.Variable 'enc_fc4_sigma/biases:0' shape=(16,) dtype=float32_ref>,\n",
       " <tf.Variable 'dec_fc1/weights:0' shape=(16, 32) dtype=float32_ref>,\n",
       " <tf.Variable 'dec_fc1/biases:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'dec_fc4/weights:0' shape=(32, 3) dtype=float32_ref>,\n",
       " <tf.Variable 'dec_fc4/biases:0' shape=(3,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_vars"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
