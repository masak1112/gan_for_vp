{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial from https://github.com/shaohua0116/VAE-Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'layer_def' from '/Users/gongbing/PycharmProjects/GAN_practice/layer_def.py'>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import importlib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.slim import fully_connected as fc\n",
    "import matplotlib.pyplot as plt \n",
    "import glob\n",
    "from collections import OrderedDict\n",
    "%matplotlib inline\n",
    "from datetime import datetime\n",
    "import os\n",
    "from pathlib import Path\n",
    "import layer_def as ld\n",
    "importlib.reload(ld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function transpose_conv_layer in module layer_def:\n",
      "\n",
      "transpose_conv_layer(inputs, kernel_size, stride, num_features, idx, activate='relu')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ld.transpose_conv_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = \"/Users/gongbing/PycharmProjects/video_prediction_savp/data/era5_size_64_64_3_3t_norm/train\"\n",
    "test_files = \"/Users/gongbing/PycharmProjects/video_prediction_savp/data/era5_size_64_64_3_3t_norm/test\"\n",
    "val_files = \"/Users/gongbing/PycharmProjects/video_prediction_savp/data/era5_size_64_64_3_3t_norm/train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "batch_size=40\n",
    "input_dim=3\n",
    "num_sample = 1500\n",
    "def make_dataset(type=\"train\"):\n",
    "    if type==\"train\": filenames = glob.glob(\"/Users/gongbing/PycharmProjects/video_prediction_savp/data/era5_size_64_64_3_3t_norm/train/*.tfrecords\")\n",
    "    if type==\"val\":filenames = glob.glob(\"/Users/gongbing/PycharmProjects/video_prediction_savp/data/era5_size_64_64_3_3t_norm/val/*.tfrecords\")\n",
    "    if type==\"test\":filenames = glob.glob(\"/Users/gongbing/PycharmProjects/video_prediction_savp/data/era5_size_64_64_3_3t_norm/test/*.tfrecords\")\n",
    "    \n",
    "    def parser(serialized_example):\n",
    "            seqs = OrderedDict()\n",
    "            keys_to_features = {\n",
    "                # 'width': tf.FixedLenFeature([], tf.int64),\n",
    "                # 'height': tf.FixedLenFeature([], tf.int64),\n",
    "                'sequence_length': tf.FixedLenFeature([], tf.int64),\n",
    "                # 'channels': tf.FixedLenFeature([],tf.int64),\n",
    "                # 'images/encoded':  tf.FixedLenFeature([], tf.string)\n",
    "                'images/encoded': tf.VarLenFeature(tf.float32)\n",
    "            }\n",
    "            parsed_features = tf.parse_single_example(serialized_example, keys_to_features)\n",
    "            seq = tf.sparse_tensor_to_dense(parsed_features[\"images/encoded\"])\n",
    "            print(\"Seq= \",seq.shape)\n",
    "            images = tf.reshape(seq, [20,64, 64,3], name = \"reshape_new\")\n",
    "            seqs[\"images\"] = images\n",
    "            return seqs\n",
    "    dataset = tf.data.TFRecordDataset(filenames, buffer_size = 8 * 1024 * 1024)\n",
    "    dataset = dataset.repeat(num_epochs)\n",
    "    dataset = dataset.apply(tf.contrib.data.map_and_batch(\n",
    "            parser, batch_size, drop_remainder = True, num_parallel_calls = None))\n",
    "    #dataset = dataset.map(parser)\n",
    "    # num_parallel_calls = None if shuffle else 1  # for reproducibility (e.g. sampled subclips from the test set)\n",
    "    # dataset = dataset.apply(tf.contrib.data.map_and_batch(\n",
    "    #    _parser, batch_size, drop_remainder=True, num_parallel_calls=num_parallel_calls)) #  Bing: Parallel data mapping, num_parallel_calls normally depends on the hardware, however, normally should be equal to be the usalbe number of CPUs\n",
    "    dataset = dataset.prefetch(batch_size)  # Bing: Take the data to buffer inorder to save the waiting time for GPU\n",
    "    print(\"dataset\",dataset)\n",
    "    #dataset = dataset.repeat(max_step)\n",
    "    #dataset = dataset.batch(batch_size)\n",
    "    #iterator = dataset.make_one_shot_iterator() #One shot iterator will pool all the data once and memery issue\n",
    "    iterator = dataset.make_initializable_iterator()\n",
    "    return iterator\n",
    "\n",
    "class VariantionalAutoencoder(object):\n",
    "\n",
    "    def __init__(self, learning_rate=1e-4, batch_size=64, n_z=16):\n",
    "        # Set hyperparameters\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.n_z = n_z\n",
    "        # Build the graph\n",
    "        self.build()\n",
    "        # Initialize paramters\n",
    "        self.sess = tf.InteractiveSession()\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        # Summary op\n",
    "        self.loss_summary = tf.summary.scalar(\"recon_losses\", self.recon_loss)\n",
    "        self.loss_summary = tf.summary.scalar(\"latent_losses\", self.latent_loss)\n",
    "        self.summary_op = tf.summary.merge_all()\n",
    "        self.summary_dir = \"./\"\n",
    "        self.base_dir = \"VAE\"\n",
    "        self.checkpoint_dir =  \"VAE\" + \"/checkpoint\"\n",
    "        Path(self.checkpoint_dir).mkdir(parents=True, exist_ok=True)\n",
    "        self.train_log_file = self.base_dir + \"/train_\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        self.val_log_file = self.base_dir + \"/val_\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        self.train_writer = tf.summary.FileWriter(self.train_log_file, self.sess.graph)\n",
    "        self.val_writer = tf.summary.FileWriter(self.val_log_file, self.sess.graph)\n",
    "\n",
    "         \n",
    "    def vae_arc1(self):\n",
    "        \n",
    "        # Encode\n",
    "        # x -> z_mean, z_sigma -> z\n",
    "        f1 = fc(self.x, 128, scope='enc_fc1', activation_fn=tf.nn.relu)\n",
    "        f2 = fc(f1, 64, scope='enc_fc2', activation_fn=tf.nn.relu)\n",
    "        f3 = fc(f2, 32, scope='enc_fc3', activation_fn=tf.nn.relu)\n",
    "        self.z_mu = fc(f3, self.n_z, scope='enc_fc4_mu', \n",
    "                       activation_fn=None)\n",
    "        self.z_log_sigma_sq = fc(f3, self.n_z, scope='enc_fc4_sigma', \n",
    "                                 activation_fn=None)\n",
    "        eps = tf.random_normal(shape=tf.shape(self.z_log_sigma_sq),mean=0, stddev=1, dtype=tf.float32)\n",
    "        \n",
    "        self.z = self.z_mu + tf.sqrt(tf.exp(self.z_log_sigma_sq)) * eps\n",
    "\n",
    "        # Decode\n",
    "        # z -> x_hat\n",
    "        g1 = fc(self.z, 32, scope='dec_fc1', activation_fn=tf.nn.relu)\n",
    "        g2 = fc(g1, 64, scope='dec_fc2', activation_fn=tf.nn.relu)\n",
    "        g3 = fc(g2, 128, scope='dec_fc3', activation_fn=tf.nn.relu)\n",
    "        self.x_hat = fc(g3, input_dim, scope='dec_fc4', activation_fn=tf.sigmoid)\n",
    "        return \n",
    "    \n",
    "\n",
    "    def vae_arc2(self):\n",
    "        \n",
    "        # Encode\n",
    "        # x -> z_mean, z_sigma -> z\n",
    "        f3 = fc(self.x, 32, scope='enc_fc1', activation_fn=tf.nn.relu)\n",
    "\n",
    "        self.z_mu = fc(f3, self.n_z, scope='enc_fc4_mu', \n",
    "                       activation_fn=None)\n",
    "        self.z_log_sigma_sq = fc(f3, self.n_z, scope='enc_fc4_sigma', \n",
    "                                 activation_fn=None)\n",
    "        eps = tf.random_normal(shape=tf.shape(self.z_log_sigma_sq),mean=0, stddev=1, dtype=tf.float32)\n",
    "        self.z = self.z_mu + tf.sqrt(tf.exp(self.z_log_sigma_sq)) * eps\n",
    "        \n",
    "        # Decode\n",
    "        # z -> x_hat\n",
    "        g1 = fc(self.z, 32, scope='dec_fc1', acxtivation_fn=tf.nn.relu)\n",
    "        self.x_hat = fc(g1, input_dim, scope='dec_fc4', activation_fn=tf.sigmoid)\n",
    "        return \n",
    "    \n",
    "    def mymodel(self):\n",
    "        pass\n",
    "        \n",
    "    @staticmethod\n",
    "    def vae_arc3(x, l_name=0):\n",
    "        seq_name = \"sq_\" + str(l_name) + \"_\"\n",
    "        print (\"DBBUG: INPUT\",x)\n",
    "        conv1 = ld.conv_layer(x, 3, 2, 8, seq_name + \"encode_1\")\n",
    "        print(\"Encode_1_shape\",conv1.shape) #(?,2,2,8)\n",
    "        # conv2\n",
    "        conv2 = ld.conv_layer(conv1, 3, 1, 8, seq_name +\"encode_2\") #(?,2,2,8)\n",
    "        print(\"Encode 2_shape,\",conv2.shape)\n",
    "        # conv3\n",
    "        conv3 = ld.conv_layer(conv2, 3, 2, 8, seq_name +\"encode_3\") # (?,1,1,8)\n",
    "        print(\"Encode 3_shape, \", conv3.shape)\n",
    "        #flatten\n",
    "        conv4 = tf.layers.Flatten()(conv3)\n",
    "        print(\"Encode 4_shape, \", conv4.shape)\n",
    "        #Todo: to conv3 to z \n",
    "        z_mu = ld.fc_layer(conv4, hiddens=16, idx= seq_name + \"enc_fc4_m\")\n",
    "        z_log_sigma_sq = ld.fc_layer(conv4, hiddens=16, idx= seq_name + \"enc_fc4_m\"'enc_fc4_sigma')        \n",
    "        eps = tf.random_normal(shape=tf.shape(z_log_sigma_sq), mean=0, stddev=1, dtype=tf.float32)\n",
    "        z = z_mu + tf.sqrt(tf.exp(z_log_sigma_sq)) * eps\n",
    "        print(\"latend variables z \", z)\n",
    "        z2 = ld.fc_layer(z, hiddens=16*16*8, idx= seq_name +\"deenc_fc1\")\n",
    "        print(\"latend variables z2 \", z2)\n",
    "        z3 = tf.reshape(z2,[-1,16,16,8])\n",
    "        print(\"latend variables z3 \", z3) \n",
    "        # conv5\n",
    "        conv5 = ld.transpose_conv_layer(z3, 3, 2, 8, seq_name +\"decode_5\") #(16,1,1,8)inputs, kernel_size, stride, num_features\n",
    "        print(\"Decode 5 shape\",conv5.shape)\n",
    "        conv6 = ld.transpose_conv_layer(z3, 3, 4, 8, seq_name +\"decode_6\") #(16,1,1,8)inputs, kernel_size, stride, num_features\n",
    "        print(\"Decode 6 shape\",conv6.shape)\n",
    "        # conv7\n",
    "        #conv7 = ld.transpose_conv_layer(conv6, 2, 1, 8, \"decode_7\") #(16,2,2,8)\n",
    "        #conv7 = ld.transpose_conv_layer(conv6, 3, 1, 8, \"decode_7\")\n",
    "        #print(\"Decode 7 shape\", conv7.shape)\n",
    "        # x_1\n",
    "        x_hat = ld.transpose_conv_layer(conv6, 2, 1, 3, seq_name +\"decode_8\")  # set activation to linear\n",
    "        print(\"X_hat\", x_hat.shape)\n",
    "        return x_hat, z_mu,z_log_sigma_sq, z\n",
    "    \n",
    "    def vae_arc_all(self):\n",
    "        X = []\n",
    "        z_log_sigma_sq_all = []\n",
    "        z_mu_all = []\n",
    "        for i in range(20):\n",
    "            q, z_mu, z_log_sigma_sq, z = VariantionalAutoencoder.vae_arc3(self.x[:,i,:,:,:], l_name=i)\n",
    "            X.append(q)\n",
    "            z_log_sigma_sq_all.append(z_log_sigma_sq)\n",
    "            z_mu_all.append(z_mu)\n",
    "        x_hat = tf.stack(X,axis = 1)\n",
    "        z_log_sigma_sq_all = tf.stack(z_log_sigma_sq_all,axis = 1)\n",
    "        z_mu_all = tf.stack(z_mu_all,axis = 1)\n",
    "        print (\"X_hat\",x_hat.shape)\n",
    "        print (\"zlog_sigma_sq_all\",z_log_sigma_sq_all.shape)\n",
    "        return x_hat,z_log_sigma_sq_all,z_mu_all\n",
    "        \n",
    "        \n",
    "    # Build the netowrk and the loss functions\n",
    "    def build(self):\n",
    "        tf.reset_default_graph()\n",
    "        self.train_iterator = make_dataset(type=\"train\")\n",
    "        self.val_iterator = make_dataset(type=\"val\")\n",
    "        self.test_iterator = make_dataset(type=\"test\")\n",
    "        self.x = tf.placeholder(tf.float32, [None,20,64,64,3])\n",
    "        self.global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "        self.increment_global_step = tf.assign_add(self.global_step,1,name = 'increment_global_step')\n",
    "        \n",
    "        \n",
    "        #ARCHITECTURE\n",
    "        #self.mymodel()\n",
    "        \n",
    "        self.x_hat,self.z_log_sigma_sq,self.z_mu = self.vae_arc_all()\n",
    "        # Loss\n",
    "        # Reconstruction loss\n",
    "        # Minimize the cross-entropy loss\n",
    "#         epsilon = 1e-10\n",
    "#         recon_loss = -tf.reduce_sum(\n",
    "#             self.x[:,1:,:,:,:] * tf.log(epsilon+self.x_hat[:,:-1,:,:,:]) + \n",
    "#             (1-self.x[:,1:,:,:,:]) * tf.log(epsilon+1-self.x_hat[:,:-1,:,:,:]), \n",
    "#             axis=1\n",
    "#         )\n",
    "\n",
    "#        self.recon_loss = tf.reduce_mean(recon_loss)\n",
    "        self.recon_loss = tf.reduce_mean(tf.square(self.x[:,1:,:,:,0]  - self.x_hat[:,:-1,:,:,0]))\n",
    "\n",
    "        # Latent loss\n",
    "        # KL divergence: measure the difference between two distributions\n",
    "        # Here we measure the divergence between \n",
    "        # the latent distribution and N(0, 1)\n",
    "        latent_loss = -0.5 * tf.reduce_sum(\n",
    "            1 + self.z_log_sigma_sq - tf.square(self.z_mu) - \n",
    "            tf.exp(self.z_log_sigma_sq), axis=1)\n",
    "        self.latent_loss = tf.reduce_mean(latent_loss)\n",
    "\n",
    "        self.total_loss = self.recon_loss + self.latent_loss\n",
    "        self.train_op = tf.train.AdamOptimizer(\n",
    "            learning_rate=self.learning_rate).minimize(self.total_loss,global_step=self.global_step)\n",
    "        \n",
    "        # Build a saver\n",
    "        self.saver = tf.train.Saver(tf.global_variables())\n",
    "        \n",
    "        self.losses = {\n",
    "            'recon_loss': self.recon_loss,\n",
    "            'latent_loss': self.latent_loss,\n",
    "            'total_loss': self.total_loss,\n",
    "        }      # H(x, x_hat) = -\\Sigma x*log(x_hat) + (1-x)*log(1-x_hat)\n",
    "\n",
    "        \n",
    "        #self.ckpt = tf.train.Checkpoint(model=self.vae_arc2())\n",
    "        #self.manager = tf.train.CheckpointManager(self.ckpt,self.checkpoint_dir,max_to_keep=3)\n",
    "        return\n",
    "\n",
    "    # Execute the forward and the backward pass\n",
    "    def run_single_step(self):\n",
    "        global_step = self.sess.run(self.global_step)\n",
    "        try:\n",
    "            train_batch = self.sess.run(self.train_iterator.get_next())\n",
    "            print(\"Train_batch shape\", train_batch[\"images\"].shape)\n",
    "            x_hat, train_summary, _, train_losses = self.sess.run([self.x_hat, self.summary_op, self.train_op, self.losses], feed_dict={self.x: train_batch[\"images\"]})\n",
    "            self.train_writer.add_summary(train_summary, global_step)\n",
    "            print(\"x_hat.shape\", x_hat.shape)\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print(\"train out of range error\")\n",
    "        \n",
    "        try:\n",
    "            val_batch = self.sess.run(self.val_iterator.get_next())\n",
    "            val_summary, _, val_losses = self.sess.run([self.summary_op,self.train_op, self.losses], feed_dict={self.x: val_batch[\"images\"]})\n",
    "            self.val_writer.add_summary(val_summary, global_step)\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print(\"train out of range error\")\n",
    "        \n",
    "        return train_losses,val_losses\n",
    "\n",
    "    # x -> x_hat\n",
    "    def reconstructor(self, x):\n",
    "        x_hat = self.sess.run(self.x_hat, feed_dict={self.x: x})\n",
    "        return x_hat\n",
    "\n",
    "    # z -> x\n",
    "    def generator(self, z):\n",
    "        x_hat = self.sess.run(self.x_hat, feed_dict={self.z: z})\n",
    "        return x_hat\n",
    "    \n",
    "    \n",
    "    # x -> z\n",
    "    def transformer(self, x):\n",
    "        z = self.sess.run(self.z, feed_dict={self.x: x})\n",
    "        return z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(model_class, learning_rate=1e-4, \n",
    "            batch_size=64, num_epoch=100, n_z=16, log_step=5):\n",
    "    # Create a model    \n",
    "    model = model_class(learning_rate=learning_rate, batch_size=batch_size, n_z=n_z)\n",
    "\n",
    "    # Training loop    \n",
    "    for epoch in range(num_epoch):\n",
    "        start_time = time.time()\n",
    "        # Run an epoch\n",
    "        for iter in range(num_sample // batch_size):\n",
    "            # Get a batch\n",
    "            step = epoch*(num_sample // batch_size) +  iter\n",
    "            train_losses,val_losses = model.run_single_step()\n",
    "            print (\"Train_loss: {}; Val_loss{}\".format(train_losses,val_losses))\n",
    "            checkpoint_path = os.path.join(model.checkpoint_dir, 'model.ckpt')\n",
    "            model.saver.save(model.sess, model.checkpoint_path, global_step =step)\n",
    "        end_time = time.time()\n",
    "        \n",
    "        # Log the loss\n",
    "#         if epoch % log_step == 0:\n",
    "#             log_str = '[Epoch {}] '.format(epoch)\n",
    "#             for k, v in self.recon_loss.items():\n",
    "#                 log_str += '{}: {:.3f}  '.format(k, v)\n",
    "#             log_str += '({:.3f} sec/epoch)'.format(end_time - start_time)\n",
    "#             print(log_str)\n",
    "\n",
    "    print('Done!')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vae = trainer(VariantionalAutoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard.notebook\n",
    "%tensorboard --logdir=./ --host localhost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer_and_checkpoint(model_class, learning_rate=1e-4, \n",
    "            batch_size=64, num_epoch=100, n_z=16, log_step=5):\n",
    "    #restore the existing checkpoints  \n",
    "    \n",
    "    model = model_class(learning_rate=learning_rate, batch_size=batch_size, n_z=n_z)\n",
    "    ckpt = tf.train.get_checkpoint_state(model.checkpoint_dir)\n",
    "    \n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "        #Extract from checkpoint filename\n",
    "        global_step = int(os.path.basename(ckpt.model_checkpoint_path).split('-')[1])\n",
    "        sess = tf.Session()\n",
    "        print(\"Restore from {}\".format(ckpt.model_checkpoint_path))\n",
    "        graph = tf.get_default_graph()\n",
    "        saver = tf.train.Saver(tf.global_variables())\n",
    "        #saver = tf.train.import_meta_graph(os.path.join(model.checkpoint_dir,'model.ckpt-{}.meta'.format(global_step)))\n",
    "        saver.restore(sess,tf.train.latest_checkpoint(model.checkpoint_dir))\n",
    "        loaded_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=tf.get_variable_scope().name)\n",
    "        print(\"loaded_vars\",loaded_vars)\n",
    "        \n",
    "##        The following for extract global step does not work, it always reset to 0 \n",
    "#         increment_global_step = graph.get_tensor_by_name(\"increment_global_step:0\").eval()\n",
    "#         other_var = graph.get_tensor_by_name(\"enc_fc1/weights:0\").eval()\n",
    "#         print (\"Recover global step\",increment_global_step)\n",
    "#         print (\"other var\",other_var)\n",
    "    else:\n",
    "        print(\"Initializer from scratch\")\n",
    "        global_step = model.sess.run(model.global_step)\n",
    "    # Training loop    \n",
    "    for epoch in range(num_epoch):\n",
    "        model.sess.run(model.train_iterator.initializer)\n",
    "        model.sess.run(model.val_iterator.initializer)\n",
    "        start_time = time.time()\n",
    "        # Run an epoch\n",
    "        for iter in range(num_sample // batch_size):\n",
    "            # Get a batch\n",
    "            #step = epoch*(num_sample // batch_size) +  iter\n",
    "            print (\"global step\",model.global_step)\n",
    "            train_losses,val_losses = model.run_single_step()\n",
    "            print (\"Train_loss: {}; Val_loss{} for global step {}\".format(train_losses,val_losses,global_step))\n",
    "            checkpoint_path = os.path.join(model.checkpoint_dir, 'model_arc4.ckpt')\n",
    "            model.saver.save(model.sess,checkpoint_path, global_step = global_step)\n",
    "            global_step = global_step  +1\n",
    "        end_time = time.time()\n",
    "        \n",
    "        # Log the loss\n",
    "#         if epoch % log_step == 0:\n",
    "#             log_str = '[Epoch {}] '.format(epoch)\n",
    "#             for k, v in self.recon_loss.items():\n",
    "#                 log_str += '{}: {:.3f}  '.format(k, v)\n",
    "#             log_str += '({:.3f} sec/epoch)'.format(end_time - start_time)\n",
    "#             print(log_str)\n",
    "    print('Done!')\n",
    "    return model    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seq=  (?,)\n",
      "dataset <DatasetV1Adapter shapes: OrderedDict([(images, (40, 20, 64, 64, 3))]), types: OrderedDict([(images, tf.float32)])>\n",
      "Seq=  (?,)\n",
      "dataset <DatasetV1Adapter shapes: OrderedDict([(images, (40, 20, 64, 64, 3))]), types: OrderedDict([(images, tf.float32)])>\n",
      "Seq=  (?,)\n",
      "dataset <DatasetV1Adapter shapes: OrderedDict([(images, (40, 20, 64, 64, 3))]), types: OrderedDict([(images, tf.float32)])>\n",
      "DBBUG: INPUT Tensor(\"strided_slice:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 64, 64, 3)\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "Encode 4_shape,  (?, 2048)\n",
      "latend variables z  Tensor(\"add:0\", shape=(?, 16), dtype=float32)\n",
      "latend variables z2  Tensor(\"sq_0_deenc_fc1_fc/Relu:0\", shape=(?, 2048), dtype=float32)\n",
      "latend variables z3  Tensor(\"Reshape:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_0_decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 5 shape (?, 32, 32, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_0_decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 6 shape (?, 64, 64, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_0_decode_8_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "X_hat (?, 64, 64, 3)\n",
      "DBBUG: INPUT Tensor(\"strided_slice_1:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 64, 64, 3)\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "Encode 4_shape,  (?, 2048)\n",
      "latend variables z  Tensor(\"add_1:0\", shape=(?, 16), dtype=float32)\n",
      "latend variables z2  Tensor(\"sq_1_deenc_fc1_fc/Relu:0\", shape=(?, 2048), dtype=float32)\n",
      "latend variables z3  Tensor(\"Reshape_1:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_1_decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 5 shape (?, 32, 32, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_1_decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 6 shape (?, 64, 64, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_1_decode_8_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "X_hat (?, 64, 64, 3)\n",
      "DBBUG: INPUT Tensor(\"strided_slice_2:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 64, 64, 3)\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "Encode 4_shape,  (?, 2048)\n",
      "latend variables z  Tensor(\"add_2:0\", shape=(?, 16), dtype=float32)\n",
      "latend variables z2  Tensor(\"sq_2_deenc_fc1_fc/Relu:0\", shape=(?, 2048), dtype=float32)\n",
      "latend variables z3  Tensor(\"Reshape_2:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_2_decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 5 shape (?, 32, 32, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_2_decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 6 shape (?, 64, 64, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_2_decode_8_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "X_hat (?, 64, 64, 3)\n",
      "DBBUG: INPUT Tensor(\"strided_slice_3:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 64, 64, 3)\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "Encode 4_shape,  (?, 2048)\n",
      "latend variables z  Tensor(\"add_3:0\", shape=(?, 16), dtype=float32)\n",
      "latend variables z2  Tensor(\"sq_3_deenc_fc1_fc/Relu:0\", shape=(?, 2048), dtype=float32)\n",
      "latend variables z3  Tensor(\"Reshape_3:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_3_decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 5 shape (?, 32, 32, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_3_decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 6 shape (?, 64, 64, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_3_decode_8_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "X_hat (?, 64, 64, 3)\n",
      "DBBUG: INPUT Tensor(\"strided_slice_4:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 64, 64, 3)\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "Encode 4_shape,  (?, 2048)\n",
      "latend variables z  Tensor(\"add_4:0\", shape=(?, 16), dtype=float32)\n",
      "latend variables z2  Tensor(\"sq_4_deenc_fc1_fc/Relu:0\", shape=(?, 2048), dtype=float32)\n",
      "latend variables z3  Tensor(\"Reshape_4:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_4_decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 5 shape (?, 32, 32, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_4_decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 6 shape (?, 64, 64, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_4_decode_8_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "X_hat (?, 64, 64, 3)\n",
      "DBBUG: INPUT Tensor(\"strided_slice_5:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 64, 64, 3)\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "Encode 4_shape,  (?, 2048)\n",
      "latend variables z  Tensor(\"add_5:0\", shape=(?, 16), dtype=float32)\n",
      "latend variables z2  Tensor(\"sq_5_deenc_fc1_fc/Relu:0\", shape=(?, 2048), dtype=float32)\n",
      "latend variables z3  Tensor(\"Reshape_5:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_5_decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 5 shape (?, 32, 32, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_5_decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 6 shape (?, 64, 64, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_5_decode_8_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "X_hat (?, 64, 64, 3)\n",
      "DBBUG: INPUT Tensor(\"strided_slice_6:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 64, 64, 3)\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "Encode 4_shape,  (?, 2048)\n",
      "latend variables z  Tensor(\"add_6:0\", shape=(?, 16), dtype=float32)\n",
      "latend variables z2  Tensor(\"sq_6_deenc_fc1_fc/Relu:0\", shape=(?, 2048), dtype=float32)\n",
      "latend variables z3  Tensor(\"Reshape_6:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_6_decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 5 shape (?, 32, 32, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_6_decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 6 shape (?, 64, 64, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_6_decode_8_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "X_hat (?, 64, 64, 3)\n",
      "DBBUG: INPUT Tensor(\"strided_slice_7:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 64, 64, 3)\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "Encode 4_shape,  (?, 2048)\n",
      "latend variables z  Tensor(\"add_7:0\", shape=(?, 16), dtype=float32)\n",
      "latend variables z2  Tensor(\"sq_7_deenc_fc1_fc/Relu:0\", shape=(?, 2048), dtype=float32)\n",
      "latend variables z3  Tensor(\"Reshape_7:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_7_decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 5 shape (?, 32, 32, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_7_decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 6 shape (?, 64, 64, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_7_decode_8_trans_conv/stack:0\", shape=(4,), dtype=int32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_hat (?, 64, 64, 3)\n",
      "DBBUG: INPUT Tensor(\"strided_slice_8:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 64, 64, 3)\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "Encode 4_shape,  (?, 2048)\n",
      "latend variables z  Tensor(\"add_8:0\", shape=(?, 16), dtype=float32)\n",
      "latend variables z2  Tensor(\"sq_8_deenc_fc1_fc/Relu:0\", shape=(?, 2048), dtype=float32)\n",
      "latend variables z3  Tensor(\"Reshape_8:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_8_decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 5 shape (?, 32, 32, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_8_decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 6 shape (?, 64, 64, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_8_decode_8_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "X_hat (?, 64, 64, 3)\n",
      "DBBUG: INPUT Tensor(\"strided_slice_9:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 64, 64, 3)\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "Encode 4_shape,  (?, 2048)\n",
      "latend variables z  Tensor(\"add_9:0\", shape=(?, 16), dtype=float32)\n",
      "latend variables z2  Tensor(\"sq_9_deenc_fc1_fc/Relu:0\", shape=(?, 2048), dtype=float32)\n",
      "latend variables z3  Tensor(\"Reshape_9:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_9_decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 5 shape (?, 32, 32, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_9_decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 6 shape (?, 64, 64, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_9_decode_8_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "X_hat (?, 64, 64, 3)\n",
      "DBBUG: INPUT Tensor(\"strided_slice_10:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 64, 64, 3)\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "Encode 4_shape,  (?, 2048)\n",
      "latend variables z  Tensor(\"add_10:0\", shape=(?, 16), dtype=float32)\n",
      "latend variables z2  Tensor(\"sq_10_deenc_fc1_fc/Relu:0\", shape=(?, 2048), dtype=float32)\n",
      "latend variables z3  Tensor(\"Reshape_10:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_10_decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 5 shape (?, 32, 32, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_10_decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 6 shape (?, 64, 64, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_10_decode_8_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "X_hat (?, 64, 64, 3)\n",
      "DBBUG: INPUT Tensor(\"strided_slice_11:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 64, 64, 3)\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "Encode 4_shape,  (?, 2048)\n",
      "latend variables z  Tensor(\"add_11:0\", shape=(?, 16), dtype=float32)\n",
      "latend variables z2  Tensor(\"sq_11_deenc_fc1_fc/Relu:0\", shape=(?, 2048), dtype=float32)\n",
      "latend variables z3  Tensor(\"Reshape_11:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_11_decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 5 shape (?, 32, 32, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_11_decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 6 shape (?, 64, 64, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_11_decode_8_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "X_hat (?, 64, 64, 3)\n",
      "DBBUG: INPUT Tensor(\"strided_slice_12:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 64, 64, 3)\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "Encode 4_shape,  (?, 2048)\n",
      "latend variables z  Tensor(\"add_12:0\", shape=(?, 16), dtype=float32)\n",
      "latend variables z2  Tensor(\"sq_12_deenc_fc1_fc/Relu:0\", shape=(?, 2048), dtype=float32)\n",
      "latend variables z3  Tensor(\"Reshape_12:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_12_decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 5 shape (?, 32, 32, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_12_decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 6 shape (?, 64, 64, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_12_decode_8_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "X_hat (?, 64, 64, 3)\n",
      "DBBUG: INPUT Tensor(\"strided_slice_13:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 64, 64, 3)\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "Encode 4_shape,  (?, 2048)\n",
      "latend variables z  Tensor(\"add_13:0\", shape=(?, 16), dtype=float32)\n",
      "latend variables z2  Tensor(\"sq_13_deenc_fc1_fc/Relu:0\", shape=(?, 2048), dtype=float32)\n",
      "latend variables z3  Tensor(\"Reshape_13:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_13_decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 5 shape (?, 32, 32, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_13_decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 6 shape (?, 64, 64, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_13_decode_8_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "X_hat (?, 64, 64, 3)\n",
      "DBBUG: INPUT Tensor(\"strided_slice_14:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 64, 64, 3)\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "Encode 4_shape,  (?, 2048)\n",
      "latend variables z  Tensor(\"add_14:0\", shape=(?, 16), dtype=float32)\n",
      "latend variables z2  Tensor(\"sq_14_deenc_fc1_fc/Relu:0\", shape=(?, 2048), dtype=float32)\n",
      "latend variables z3  Tensor(\"Reshape_14:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_14_decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 5 shape (?, 32, 32, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_14_decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 6 shape (?, 64, 64, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_14_decode_8_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "X_hat (?, 64, 64, 3)\n",
      "DBBUG: INPUT Tensor(\"strided_slice_15:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 64, 64, 3)\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "Encode 4_shape,  (?, 2048)\n",
      "latend variables z  Tensor(\"add_15:0\", shape=(?, 16), dtype=float32)\n",
      "latend variables z2  Tensor(\"sq_15_deenc_fc1_fc/Relu:0\", shape=(?, 2048), dtype=float32)\n",
      "latend variables z3  Tensor(\"Reshape_15:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_15_decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 5 shape (?, 32, 32, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_15_decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 6 shape (?, 64, 64, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_15_decode_8_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "X_hat (?, 64, 64, 3)\n",
      "DBBUG: INPUT Tensor(\"strided_slice_16:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 64, 64, 3)\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "Encode 4_shape,  (?, 2048)\n",
      "latend variables z  Tensor(\"add_16:0\", shape=(?, 16), dtype=float32)\n",
      "latend variables z2  Tensor(\"sq_16_deenc_fc1_fc/Relu:0\", shape=(?, 2048), dtype=float32)\n",
      "latend variables z3  Tensor(\"Reshape_16:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_16_decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 5 shape (?, 32, 32, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_16_decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 6 shape (?, 64, 64, 8)\n",
      "input_channel 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_shape Tensor(\"sq_16_decode_8_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "X_hat (?, 64, 64, 3)\n",
      "DBBUG: INPUT Tensor(\"strided_slice_17:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 64, 64, 3)\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "Encode 4_shape,  (?, 2048)\n",
      "latend variables z  Tensor(\"add_17:0\", shape=(?, 16), dtype=float32)\n",
      "latend variables z2  Tensor(\"sq_17_deenc_fc1_fc/Relu:0\", shape=(?, 2048), dtype=float32)\n",
      "latend variables z3  Tensor(\"Reshape_17:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_17_decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 5 shape (?, 32, 32, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_17_decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 6 shape (?, 64, 64, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_17_decode_8_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "X_hat (?, 64, 64, 3)\n",
      "DBBUG: INPUT Tensor(\"strided_slice_18:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 64, 64, 3)\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "Encode 4_shape,  (?, 2048)\n",
      "latend variables z  Tensor(\"add_18:0\", shape=(?, 16), dtype=float32)\n",
      "latend variables z2  Tensor(\"sq_18_deenc_fc1_fc/Relu:0\", shape=(?, 2048), dtype=float32)\n",
      "latend variables z3  Tensor(\"Reshape_18:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_18_decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 5 shape (?, 32, 32, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_18_decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 6 shape (?, 64, 64, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_18_decode_8_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "X_hat (?, 64, 64, 3)\n",
      "DBBUG: INPUT Tensor(\"strided_slice_19:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 64, 64, 3)\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "Encode 4_shape,  (?, 2048)\n",
      "latend variables z  Tensor(\"add_19:0\", shape=(?, 16), dtype=float32)\n",
      "latend variables z2  Tensor(\"sq_19_deenc_fc1_fc/Relu:0\", shape=(?, 2048), dtype=float32)\n",
      "latend variables z3  Tensor(\"Reshape_19:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_19_decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 5 shape (?, 32, 32, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_19_decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 6 shape (?, 64, 64, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_19_decode_8_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "X_hat (?, 64, 64, 3)\n",
      "X_hat (?, 20, 64, 64, 3)\n",
      "zlog_sigma_sq_all (?, 20, 16)\n",
      "Initializer from scratch\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.2161216, 'latent_loss': 0.5703039, 'total_loss': 0.78642553}; Val_loss{'recon_loss': 0.20574068, 'latent_loss': 0.48346177, 'total_loss': 0.6892024} for global step 0\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.23339605, 'latent_loss': 0.40916577, 'total_loss': 0.6425618}; Val_loss{'recon_loss': 0.22141427, 'latent_loss': 0.3456381, 'total_loss': 0.56705236} for global step 1\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.23292725, 'latent_loss': 0.29152104, 'total_loss': 0.5244483}; Val_loss{'recon_loss': 0.22148173, 'latent_loss': 0.24573267, 'total_loss': 0.4672144} for global step 2\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.1639642, 'latent_loss': 0.20717445, 'total_loss': 0.37113863}; Val_loss{'recon_loss': 0.20488751, 'latent_loss': 0.17481312, 'total_loss': 0.37970063} for global step 3\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.1481706, 'latent_loss': 0.14765331, 'total_loss': 0.29582393}; Val_loss{'recon_loss': 0.2005531, 'latent_loss': 0.124927424, 'total_loss': 0.32548052} for global step 4\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.14962022, 'latent_loss': 0.10582683, 'total_loss': 0.25544706}; Val_loss{'recon_loss': 0.20354392, 'latent_loss': 0.08973895, 'total_loss': 0.29328287} for global step 5\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.14116691, 'latent_loss': 0.07619814, 'total_loss': 0.21736506}; Val_loss{'recon_loss': 0.22315447, 'latent_loss': 0.06474177, 'total_loss': 0.28789625} for global step 6\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.13505943, 'latent_loss': 0.0550112, 'total_loss': 0.19007063}; Val_loss{'recon_loss': 0.2402746, 'latent_loss': 0.04669019, 'total_loss': 0.28696477} for global step 7\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.12816535, 'latent_loss': 0.03956732, 'total_loss': 0.16773267}; Val_loss{'recon_loss': 0.25172463, 'latent_loss': 0.033495434, 'total_loss': 0.28522006} for global step 8\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.15863955, 'latent_loss': 0.02834556, 'total_loss': 0.1869851}; Val_loss{'recon_loss': 0.238989, 'latent_loss': 0.023979759, 'total_loss': 0.26296875} for global step 9\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.22154409, 'latent_loss': 0.020311063, 'total_loss': 0.24185514}; Val_loss{'recon_loss': 0.22633547, 'latent_loss': 0.017212564, 'total_loss': 0.24354804} for global step 10\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.23410715, 'latent_loss': 0.014575246, 'total_loss': 0.2486824}; Val_loss{'recon_loss': 0.24739219, 'latent_loss': 0.012334815, 'total_loss': 0.259727} for global step 11\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.22837478, 'latent_loss': 0.010438329, 'total_loss': 0.2388131}; Val_loss{'recon_loss': 0.23357005, 'latent_loss': 0.008848387, 'total_loss': 0.24241844} for global step 12\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.12973453, 'latent_loss': 0.007532311, 'total_loss': 0.13726684}; Val_loss{'recon_loss': 0.18134959, 'latent_loss': 0.0064458353, 'total_loss': 0.18779543} for global step 13\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.13755022, 'latent_loss': 0.005563957, 'total_loss': 0.14311418}; Val_loss{'recon_loss': 0.1887385, 'latent_loss': 0.0048480546, 'total_loss': 0.19358654} for global step 14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.14134276, 'latent_loss': 0.004266409, 'total_loss': 0.14560917}; Val_loss{'recon_loss': 0.19403718, 'latent_loss': 0.003782743, 'total_loss': 0.19781993} for global step 15\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.14720733, 'latent_loss': 0.0033752532, 'total_loss': 0.15058258}; Val_loss{'recon_loss': 0.24069917, 'latent_loss': 0.0030258459, 'total_loss': 0.24372502} for global step 16\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.15892862, 'latent_loss': 0.0027190535, 'total_loss': 0.16164768}; Val_loss{'recon_loss': 0.24238637, 'latent_loss': 0.002446074, 'total_loss': 0.24483244} for global step 17\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.16012676, 'latent_loss': 0.0021968018, 'total_loss': 0.16232356}; Val_loss{'recon_loss': 0.22910489, 'latent_loss': 0.0019673365, 'total_loss': 0.23107223} for global step 18\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.12136548, 'latent_loss': 0.0017550936, 'total_loss': 0.123120576}; Val_loss{'recon_loss': 0.20582709, 'latent_loss': 0.0015606692, 'total_loss': 0.20738776} for global step 19\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.10992632, 'latent_loss': 0.0013818805, 'total_loss': 0.1113082}; Val_loss{'recon_loss': 0.18992493, 'latent_loss': 0.0012178306, 'total_loss': 0.19114275} for global step 20\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.10820524, 'latent_loss': 0.001067051, 'total_loss': 0.10927229}; Val_loss{'recon_loss': 0.18519801, 'latent_loss': 0.0009298084, 'total_loss': 0.18612781} for global step 21\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.12057252, 'latent_loss': 0.0008051306, 'total_loss': 0.121377654}; Val_loss{'recon_loss': 0.22102825, 'latent_loss': 0.00069287285, 'total_loss': 0.22172113} for global step 22\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.2110412, 'latent_loss': 0.0005922639, 'total_loss': 0.21163346}; Val_loss{'recon_loss': 0.20103161, 'latent_loss': 0.00050280814, 'total_loss': 0.20153442} for global step 23\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.22788718, 'latent_loss': 0.0004238654, 'total_loss': 0.22831105}; Val_loss{'recon_loss': 0.21627362, 'latent_loss': 0.000354811, 'total_loss': 0.21662843} for global step 24\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.2275445, 'latent_loss': 0.0002948122, 'total_loss': 0.22783932}; Val_loss{'recon_loss': 0.21641062, 'latent_loss': 0.0002428297, 'total_loss': 0.21665345} for global step 25\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.1607492, 'latent_loss': 0.00019825893, 'total_loss': 0.16094746}; Val_loss{'recon_loss': 0.20033906, 'latent_loss': 0.00016029915, 'total_loss': 0.20049936} for global step 26\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.14552383, 'latent_loss': 0.00012862445, 'total_loss': 0.14565246}; Val_loss{'recon_loss': 0.19614218, 'latent_loss': 0.00010226108, 'total_loss': 0.19624445} for global step 27\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.14692158, 'latent_loss': 8.100327e-05, 'total_loss': 0.14700258}; Val_loss{'recon_loss': 0.19909741, 'latent_loss': 6.3906795e-05, 'total_loss': 0.19916132} for global step 28\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.13883008, 'latent_loss': 5.0746043e-05, 'total_loss': 0.13888083}; Val_loss{'recon_loss': 0.2182208, 'latent_loss': 4.055938e-05, 'total_loss': 0.21826136} for global step 29\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.13298438, 'latent_loss': 3.269119e-05, 'total_loss': 0.13301708}; Val_loss{'recon_loss': 0.23493455, 'latent_loss': 2.6168582e-05, 'total_loss': 0.23496072} for global step 30\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.12638801, 'latent_loss': 2.1044165e-05, 'total_loss': 0.12640905}; Val_loss{'recon_loss': 0.24612804, 'latent_loss': 1.6603992e-05, 'total_loss': 0.24614464} for global step 31\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.15592021, 'latent_loss': 1.3044197e-05, 'total_loss': 0.15593325}; Val_loss{'recon_loss': 0.23374414, 'latent_loss': 9.970087e-06, 'total_loss': 0.23375411} for global step 32\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.21675329, 'latent_loss': 7.511396e-06, 'total_loss': 0.2167608}; Val_loss{'recon_loss': 0.221454, 'latent_loss': 5.5167825e-06, 'total_loss': 0.22145951} for global step 33\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.22903796, 'latent_loss': 3.9245e-06, 'total_loss': 0.22904187}; Val_loss{'recon_loss': 0.24199937, 'latent_loss': 2.6839784e-06, 'total_loss': 0.24200206} for global step 34\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.22360675, 'latent_loss': 1.7521903e-06, 'total_loss': 0.22360851}; Val_loss{'recon_loss': 0.22856124, 'latent_loss': 1.0567717e-06, 'total_loss': 0.2285623} for global step 35\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.12799194, 'latent_loss': 5.9716405e-07, 'total_loss': 0.12799254}; Val_loss{'recon_loss': 0.17782022, 'latent_loss': 2.6496127e-07, 'total_loss': 0.17782049} for global step 36\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.13548869, 'latent_loss': 8.614734e-08, 'total_loss': 0.13548878}; Val_loss{'recon_loss': 0.18500651, 'latent_loss': 5.2154063e-09, 'total_loss': 0.18500651} for global step 37\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.13914217, 'latent_loss': 0.0, 'total_loss': 0.13914217}; Val_loss{'recon_loss': 0.19015105, 'latent_loss': 0.0, 'total_loss': 0.19015105} for global step 38\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.14486207, 'latent_loss': 0.0, 'total_loss': 0.14486207}; Val_loss{'recon_loss': 0.23565786, 'latent_loss': 0.0, 'total_loss': 0.23565786} for global step 39\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.15616074, 'latent_loss': 0.0, 'total_loss': 0.15616074}; Val_loss{'recon_loss': 0.23732272, 'latent_loss': 0.0, 'total_loss': 0.23732272} for global step 40\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.15732256, 'latent_loss': 0.0, 'total_loss': 0.15732256}; Val_loss{'recon_loss': 0.2243969, 'latent_loss': 0.0, 'total_loss': 0.2243969} for global step 41\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.12025744, 'latent_loss': 0.0, 'total_loss': 0.12025744}; Val_loss{'recon_loss': 0.20173736, 'latent_loss': 0.0, 'total_loss': 0.20173736} for global step 42\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.10923984, 'latent_loss': 0.0, 'total_loss': 0.10923984}; Val_loss{'recon_loss': 0.18631876, 'latent_loss': 0.0, 'total_loss': 0.18631876} for global step 43\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.10759877, 'latent_loss': 0.0, 'total_loss': 0.10759877}; Val_loss{'recon_loss': 0.18172634, 'latent_loss': 0.0, 'total_loss': 0.18172634} for global step 44\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.1193627, 'latent_loss': 0.0, 'total_loss': 0.1193627}; Val_loss{'recon_loss': 0.21668117, 'latent_loss': 0.0, 'total_loss': 0.21668117} for global step 45\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.20688923, 'latent_loss': 0.0, 'total_loss': 0.20688923}; Val_loss{'recon_loss': 0.19717538, 'latent_loss': 0.0, 'total_loss': 0.19717538} for global step 46\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.22332023, 'latent_loss': 0.0, 'total_loss': 0.22332023}; Val_loss{'recon_loss': 0.21199988, 'latent_loss': 0.0, 'total_loss': 0.21199988} for global step 47\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.22305976, 'latent_loss': 0.0, 'total_loss': 0.22305976}; Val_loss{'recon_loss': 0.21218504, 'latent_loss': 0.0, 'total_loss': 0.21218504} for global step 48\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.15811497, 'latent_loss': 0.0, 'total_loss': 0.15811497}; Val_loss{'recon_loss': 0.19654377, 'latent_loss': 0.0, 'total_loss': 0.19654377} for global step 49\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.1433888, 'latent_loss': 0.0, 'total_loss': 0.1433888}; Val_loss{'recon_loss': 0.19244547, 'latent_loss': 0.0, 'total_loss': 0.19244547} for global step 50\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.14473239, 'latent_loss': 0.0, 'total_loss': 0.14473239}; Val_loss{'recon_loss': 0.19536285, 'latent_loss': 0.0, 'total_loss': 0.19536285} for global step 51\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.13694343, 'latent_loss': 0.0, 'total_loss': 0.13694343}; Val_loss{'recon_loss': 0.21404336, 'latent_loss': 0.0, 'total_loss': 0.21404336} for global step 52\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.13132545, 'latent_loss': 0.0, 'total_loss': 0.13132545}; Val_loss{'recon_loss': 0.23038395, 'latent_loss': 0.0, 'total_loss': 0.23038395} for global step 53\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.124987654, 'latent_loss': 0.0, 'total_loss': 0.124987654}; Val_loss{'recon_loss': 0.24133526, 'latent_loss': 0.0, 'total_loss': 0.24133526} for global step 54\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.15367813, 'latent_loss': 0.0, 'total_loss': 0.15367813}; Val_loss{'recon_loss': 0.22925706, 'latent_loss': 0.0, 'total_loss': 0.22925706} for global step 55\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.21266006, 'latent_loss': 0.0, 'total_loss': 0.21266006}; Val_loss{'recon_loss': 0.21727042, 'latent_loss': 0.0, 'total_loss': 0.21727042} for global step 56\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.22468035, 'latent_loss': 0.0, 'total_loss': 0.22468035}; Val_loss{'recon_loss': 0.23735632, 'latent_loss': 0.0, 'total_loss': 0.23735632} for global step 57\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.21952195, 'latent_loss': 0.0, 'total_loss': 0.21952195}; Val_loss{'recon_loss': 0.22425093, 'latent_loss': 0.0, 'total_loss': 0.22425093} for global step 58\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.12657982, 'latent_loss': 0.0, 'total_loss': 0.12657982}; Val_loss{'recon_loss': 0.17482185, 'latent_loss': 0.0, 'total_loss': 0.17482185} for global step 59\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.13378446, 'latent_loss': 0.0, 'total_loss': 0.13378446}; Val_loss{'recon_loss': 0.18181294, 'latent_loss': 0.0, 'total_loss': 0.18181294} for global step 60\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.13729995, 'latent_loss': 0.0, 'total_loss': 0.13729995}; Val_loss{'recon_loss': 0.18677765, 'latent_loss': 0.0, 'total_loss': 0.18677765} for global step 61\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.1428373, 'latent_loss': 0.0, 'total_loss': 0.1428373}; Val_loss{'recon_loss': 0.2311794, 'latent_loss': 0.0, 'total_loss': 0.2311794} for global step 62\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.15366301, 'latent_loss': 0.0, 'total_loss': 0.15366301}; Val_loss{'recon_loss': 0.23269907, 'latent_loss': 0.0, 'total_loss': 0.23269907} for global step 63\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.15467437, 'latent_loss': 0.0, 'total_loss': 0.15467437}; Val_loss{'recon_loss': 0.21994737, 'latent_loss': 0.0, 'total_loss': 0.21994737} for global step 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.11904074, 'latent_loss': 0.0, 'total_loss': 0.11904074}; Val_loss{'recon_loss': 0.1977042, 'latent_loss': 0.0, 'total_loss': 0.1977042} for global step 65\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.10830036, 'latent_loss': 0.0, 'total_loss': 0.10830036}; Val_loss{'recon_loss': 0.18258892, 'latent_loss': 0.0, 'total_loss': 0.18258892} for global step 66\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.10661815, 'latent_loss': 0.0, 'total_loss': 0.10661815}; Val_loss{'recon_loss': 0.1779859, 'latent_loss': 0.0, 'total_loss': 0.1779859} for global step 67\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.117701985, 'latent_loss': 0.0, 'total_loss': 0.117701985}; Val_loss{'recon_loss': 0.21195243, 'latent_loss': 0.0, 'total_loss': 0.21195243} for global step 68\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.20227651, 'latent_loss': 0.0, 'total_loss': 0.20227651}; Val_loss{'recon_loss': 0.19276954, 'latent_loss': 0.0, 'total_loss': 0.19276954} for global step 69\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.21816012, 'latent_loss': 0.0, 'total_loss': 0.21816012}; Val_loss{'recon_loss': 0.2070556, 'latent_loss': 0.0, 'total_loss': 0.2070556} for global step 70\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.21781407, 'latent_loss': 0.0, 'total_loss': 0.21781407}; Val_loss{'recon_loss': 0.20712095, 'latent_loss': 0.0, 'total_loss': 0.20712095} for global step 71\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.1545936, 'latent_loss': 0.0, 'total_loss': 0.1545936}; Val_loss{'recon_loss': 0.19176985, 'latent_loss': 0.0, 'total_loss': 0.19176985} for global step 72\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.14022337, 'latent_loss': 0.0, 'total_loss': 0.14022337}; Val_loss{'recon_loss': 0.18765365, 'latent_loss': 0.0, 'total_loss': 0.18765365} for global step 73\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.14140521, 'latent_loss': 0.0, 'total_loss': 0.14140521}; Val_loss{'recon_loss': 0.19038996, 'latent_loss': 0.0, 'total_loss': 0.19038996} for global step 74\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.13383606, 'latent_loss': 0.0, 'total_loss': 0.13383606}; Val_loss{'recon_loss': 0.20848204, 'latent_loss': 0.0, 'total_loss': 0.20848204} for global step 75\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.12833272, 'latent_loss': 0.0, 'total_loss': 0.12833272}; Val_loss{'recon_loss': 0.22429997, 'latent_loss': 0.0, 'total_loss': 0.22429997} for global step 76\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.12216478, 'latent_loss': 0.0, 'total_loss': 0.12216478}; Val_loss{'recon_loss': 0.23486982, 'latent_loss': 0.0, 'total_loss': 0.23486982} for global step 77\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.14985344, 'latent_loss': 0.0, 'total_loss': 0.14985344}; Val_loss{'recon_loss': 0.22299589, 'latent_loss': 0.0, 'total_loss': 0.22299589} for global step 78\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.20675531, 'latent_loss': 0.0, 'total_loss': 0.20675531}; Val_loss{'recon_loss': 0.21122222, 'latent_loss': 0.0, 'total_loss': 0.21122222} for global step 79\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.21839918, 'latent_loss': 0.0, 'total_loss': 0.21839918}; Val_loss{'recon_loss': 0.2306781, 'latent_loss': 0.0, 'total_loss': 0.2306781} for global step 80\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.2133562, 'latent_loss': 0.0, 'total_loss': 0.2133562}; Val_loss{'recon_loss': 0.21783164, 'latent_loss': 0.0, 'total_loss': 0.21783164} for global step 81\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.123290226, 'latent_loss': 0.0, 'total_loss': 0.123290226}; Val_loss{'recon_loss': 0.16972189, 'latent_loss': 0.0, 'total_loss': 0.16972189} for global step 82\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.13008907, 'latent_loss': 0.0, 'total_loss': 0.13008907}; Val_loss{'recon_loss': 0.17640951, 'latent_loss': 0.0, 'total_loss': 0.17640951} for global step 83\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.13337496, 'latent_loss': 0.0, 'total_loss': 0.13337496}; Val_loss{'recon_loss': 0.18116322, 'latent_loss': 0.0, 'total_loss': 0.18116322} for global step 84\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.13872004, 'latent_loss': 0.0, 'total_loss': 0.13872004}; Val_loss{'recon_loss': 0.22434373, 'latent_loss': 0.0, 'total_loss': 0.22434373} for global step 85\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.14911206, 'latent_loss': 0.0, 'total_loss': 0.14911206}; Val_loss{'recon_loss': 0.22583646, 'latent_loss': 0.0, 'total_loss': 0.22583646} for global step 86\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.15012059, 'latent_loss': 0.0, 'total_loss': 0.15012059}; Val_loss{'recon_loss': 0.2134859, 'latent_loss': 0.0, 'total_loss': 0.2134859} for global step 87\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-cb3ff0ef0cab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_vae2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer_and_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariantionalAutoencoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-88-6747448f7fe8>\u001b[0m in \u001b[0;36mtrainer_and_checkpoint\u001b[0;34m(model_class, learning_rate, batch_size, num_epoch, n_z, log_step)\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;31m#step = epoch*(num_sample // batch_size) +  iter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"global step\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_single_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m             \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Train_loss: {}; Val_loss{} for global step {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_losses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mcheckpoint_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model_arc4.ckpt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-87-f4f85cb4343c>\u001b[0m in \u001b[0;36mrun_single_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0mtrain_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Train_batch shape\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"images\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m             \u001b[0mx_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_summary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"images\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_summary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"x_hat.shape\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_hat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/GAN_practice/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/GAN_practice/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/GAN_practice/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/GAN_practice/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/GAN_practice/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/GAN_practice/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_vae2 = trainer_and_checkpoint(VariantionalAutoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seq=  (?,)\n",
      "dataset <DatasetV1Adapter shapes: OrderedDict([(images, (40, 20, 64, 64, 3))]), types: OrderedDict([(images, tf.float32)])>\n",
      "Seq=  (?,)\n",
      "dataset <DatasetV1Adapter shapes: OrderedDict([(images, (40, 20, 64, 64, 3))]), types: OrderedDict([(images, tf.float32)])>\n",
      "Seq=  (?,)\n",
      "dataset <DatasetV1Adapter shapes: OrderedDict([(images, (40, 20, 64, 64, 3))]), types: OrderedDict([(images, tf.float32)])>\n",
      "DBBUG: INPUT Tensor(\"strided_slice:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 64, 64, 3)\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "Encode 4_shape,  (?, 2048)\n",
      "latend variables z  Tensor(\"add:0\", shape=(?, 16), dtype=float32)\n",
      "latend variables z2  Tensor(\"sq_0_deenc_fc1_fc/Relu:0\", shape=(?, 2048), dtype=float32)\n",
      "latend variables z3  Tensor(\"Reshape:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_0_decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 5 shape (?, 32, 32, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_0_decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 6 shape (?, 64, 64, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_0_decode_8_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "X_hat (?, 64, 64, 3)\n",
      "DBBUG: INPUT Tensor(\"strided_slice_1:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 64, 64, 3)\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "Encode 4_shape,  (?, 2048)\n",
      "latend variables z  Tensor(\"add_1:0\", shape=(?, 16), dtype=float32)\n",
      "latend variables z2  Tensor(\"sq_1_deenc_fc1_fc/Relu:0\", shape=(?, 2048), dtype=float32)\n",
      "latend variables z3  Tensor(\"Reshape_1:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_1_decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 5 shape (?, 32, 32, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_1_decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 6 shape (?, 64, 64, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_1_decode_8_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "X_hat (?, 64, 64, 3)\n",
      "DBBUG: INPUT Tensor(\"strided_slice_2:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 64, 64, 3)\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "Encode 4_shape,  (?, 2048)\n",
      "latend variables z  Tensor(\"add_2:0\", shape=(?, 16), dtype=float32)\n",
      "latend variables z2  Tensor(\"sq_2_deenc_fc1_fc/Relu:0\", shape=(?, 2048), dtype=float32)\n",
      "latend variables z3  Tensor(\"Reshape_2:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_2_decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 5 shape (?, 32, 32, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_2_decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 6 shape (?, 64, 64, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_2_decode_8_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "X_hat (?, 64, 64, 3)\n",
      "DBBUG: INPUT Tensor(\"strided_slice_3:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 64, 64, 3)\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "Encode 4_shape,  (?, 2048)\n",
      "latend variables z  Tensor(\"add_3:0\", shape=(?, 16), dtype=float32)\n",
      "latend variables z2  Tensor(\"sq_3_deenc_fc1_fc/Relu:0\", shape=(?, 2048), dtype=float32)\n",
      "latend variables z3  Tensor(\"Reshape_3:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_3_decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 5 shape (?, 32, 32, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_3_decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 6 shape (?, 64, 64, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_3_decode_8_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "X_hat (?, 64, 64, 3)\n",
      "DBBUG: INPUT Tensor(\"strided_slice_4:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 64, 64, 3)\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "Encode 4_shape,  (?, 2048)\n",
      "latend variables z  Tensor(\"add_4:0\", shape=(?, 16), dtype=float32)\n",
      "latend variables z2  Tensor(\"sq_4_deenc_fc1_fc/Relu:0\", shape=(?, 2048), dtype=float32)\n",
      "latend variables z3  Tensor(\"Reshape_4:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_4_decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 5 shape (?, 32, 32, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_4_decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 6 shape (?, 64, 64, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_4_decode_8_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "X_hat (?, 64, 64, 3)\n",
      "DBBUG: INPUT Tensor(\"strided_slice_5:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 64, 64, 3)\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "Encode 4_shape,  (?, 2048)\n",
      "latend variables z  Tensor(\"add_5:0\", shape=(?, 16), dtype=float32)\n",
      "latend variables z2  Tensor(\"sq_5_deenc_fc1_fc/Relu:0\", shape=(?, 2048), dtype=float32)\n",
      "latend variables z3  Tensor(\"Reshape_5:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_5_decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 5 shape (?, 32, 32, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_5_decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 6 shape (?, 64, 64, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_5_decode_8_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "X_hat (?, 64, 64, 3)\n",
      "DBBUG: INPUT Tensor(\"strided_slice_6:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 64, 64, 3)\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "Encode 4_shape,  (?, 2048)\n",
      "latend variables z  Tensor(\"add_6:0\", shape=(?, 16), dtype=float32)\n",
      "latend variables z2  Tensor(\"sq_6_deenc_fc1_fc/Relu:0\", shape=(?, 2048), dtype=float32)\n",
      "latend variables z3  Tensor(\"Reshape_6:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_6_decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 5 shape (?, 32, 32, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_6_decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 6 shape (?, 64, 64, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_6_decode_8_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "X_hat (?, 64, 64, 3)\n",
      "DBBUG: INPUT Tensor(\"strided_slice_7:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 64, 64, 3)\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "Encode 4_shape,  (?, 2048)\n",
      "latend variables z  Tensor(\"add_7:0\", shape=(?, 16), dtype=float32)\n",
      "latend variables z2  Tensor(\"sq_7_deenc_fc1_fc/Relu:0\", shape=(?, 2048), dtype=float32)\n",
      "latend variables z3  Tensor(\"Reshape_7:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_7_decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 5 shape (?, 32, 32, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_7_decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 6 shape (?, 64, 64, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_7_decode_8_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "X_hat (?, 64, 64, 3)\n",
      "DBBUG: INPUT Tensor(\"strided_slice_8:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 64, 64, 3)\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "Encode 4_shape,  (?, 2048)\n",
      "latend variables z  Tensor(\"add_8:0\", shape=(?, 16), dtype=float32)\n",
      "latend variables z2  Tensor(\"sq_8_deenc_fc1_fc/Relu:0\", shape=(?, 2048), dtype=float32)\n",
      "latend variables z3  Tensor(\"Reshape_8:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_8_decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 5 shape (?, 32, 32, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_8_decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 6 shape (?, 64, 64, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_8_decode_8_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "X_hat (?, 64, 64, 3)\n",
      "DBBUG: INPUT Tensor(\"strided_slice_9:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 64, 64, 3)\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "Encode 4_shape,  (?, 2048)\n",
      "latend variables z  Tensor(\"add_9:0\", shape=(?, 16), dtype=float32)\n",
      "latend variables z2  Tensor(\"sq_9_deenc_fc1_fc/Relu:0\", shape=(?, 2048), dtype=float32)\n",
      "latend variables z3  Tensor(\"Reshape_9:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_9_decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 5 shape (?, 32, 32, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_9_decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 6 shape (?, 64, 64, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_9_decode_8_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "X_hat (?, 64, 64, 3)\n",
      "DBBUG: INPUT Tensor(\"strided_slice_10:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 64, 64, 3)\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "Encode 4_shape,  (?, 2048)\n",
      "latend variables z  Tensor(\"add_10:0\", shape=(?, 16), dtype=float32)\n",
      "latend variables z2  Tensor(\"sq_10_deenc_fc1_fc/Relu:0\", shape=(?, 2048), dtype=float32)\n",
      "latend variables z3  Tensor(\"Reshape_10:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_10_decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 5 shape (?, 32, 32, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_10_decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 6 shape (?, 64, 64, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_10_decode_8_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "X_hat (?, 64, 64, 3)\n",
      "DBBUG: INPUT Tensor(\"strided_slice_11:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 64, 64, 3)\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "Encode 4_shape,  (?, 2048)\n",
      "latend variables z  Tensor(\"add_11:0\", shape=(?, 16), dtype=float32)\n",
      "latend variables z2  Tensor(\"sq_11_deenc_fc1_fc/Relu:0\", shape=(?, 2048), dtype=float32)\n",
      "latend variables z3  Tensor(\"Reshape_11:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_11_decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 5 shape (?, 32, 32, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_11_decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 6 shape (?, 64, 64, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_11_decode_8_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "X_hat (?, 64, 64, 3)\n",
      "DBBUG: INPUT Tensor(\"strided_slice_12:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 64, 64, 3)\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "Encode 4_shape,  (?, 2048)\n",
      "latend variables z  Tensor(\"add_12:0\", shape=(?, 16), dtype=float32)\n",
      "latend variables z2  Tensor(\"sq_12_deenc_fc1_fc/Relu:0\", shape=(?, 2048), dtype=float32)\n",
      "latend variables z3  Tensor(\"Reshape_12:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_12_decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 5 shape (?, 32, 32, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_12_decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 6 shape (?, 64, 64, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_12_decode_8_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "X_hat (?, 64, 64, 3)\n",
      "DBBUG: INPUT Tensor(\"strided_slice_13:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 64, 64, 3)\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "Encode 4_shape,  (?, 2048)\n",
      "latend variables z  Tensor(\"add_13:0\", shape=(?, 16), dtype=float32)\n",
      "latend variables z2  Tensor(\"sq_13_deenc_fc1_fc/Relu:0\", shape=(?, 2048), dtype=float32)\n",
      "latend variables z3  Tensor(\"Reshape_13:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_13_decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 5 shape (?, 32, 32, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_13_decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 6 shape (?, 64, 64, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_13_decode_8_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "X_hat (?, 64, 64, 3)\n",
      "DBBUG: INPUT Tensor(\"strided_slice_14:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 64, 64, 3)\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "Encode 4_shape,  (?, 2048)\n",
      "latend variables z  Tensor(\"add_14:0\", shape=(?, 16), dtype=float32)\n",
      "latend variables z2  Tensor(\"sq_14_deenc_fc1_fc/Relu:0\", shape=(?, 2048), dtype=float32)\n",
      "latend variables z3  Tensor(\"Reshape_14:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_14_decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 5 shape (?, 32, 32, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_14_decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 6 shape (?, 64, 64, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_14_decode_8_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "X_hat (?, 64, 64, 3)\n",
      "DBBUG: INPUT Tensor(\"strided_slice_15:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 64, 64, 3)\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "Encode 4_shape,  (?, 2048)\n",
      "latend variables z  Tensor(\"add_15:0\", shape=(?, 16), dtype=float32)\n",
      "latend variables z2  Tensor(\"sq_15_deenc_fc1_fc/Relu:0\", shape=(?, 2048), dtype=float32)\n",
      "latend variables z3  Tensor(\"Reshape_15:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_15_decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 5 shape (?, 32, 32, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_15_decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 6 shape (?, 64, 64, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_15_decode_8_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "X_hat (?, 64, 64, 3)\n",
      "DBBUG: INPUT Tensor(\"strided_slice_16:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 64, 64, 3)\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "Encode 4_shape,  (?, 2048)\n",
      "latend variables z  Tensor(\"add_16:0\", shape=(?, 16), dtype=float32)\n",
      "latend variables z2  Tensor(\"sq_16_deenc_fc1_fc/Relu:0\", shape=(?, 2048), dtype=float32)\n",
      "latend variables z3  Tensor(\"Reshape_16:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_16_decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 5 shape (?, 32, 32, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_16_decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 6 shape (?, 64, 64, 8)\n",
      "input_channel 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_shape Tensor(\"sq_16_decode_8_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "X_hat (?, 64, 64, 3)\n",
      "DBBUG: INPUT Tensor(\"strided_slice_17:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 64, 64, 3)\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "Encode 4_shape,  (?, 2048)\n",
      "latend variables z  Tensor(\"add_17:0\", shape=(?, 16), dtype=float32)\n",
      "latend variables z2  Tensor(\"sq_17_deenc_fc1_fc/Relu:0\", shape=(?, 2048), dtype=float32)\n",
      "latend variables z3  Tensor(\"Reshape_17:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_17_decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 5 shape (?, 32, 32, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_17_decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 6 shape (?, 64, 64, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_17_decode_8_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "X_hat (?, 64, 64, 3)\n",
      "DBBUG: INPUT Tensor(\"strided_slice_18:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 64, 64, 3)\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "Encode 4_shape,  (?, 2048)\n",
      "latend variables z  Tensor(\"add_18:0\", shape=(?, 16), dtype=float32)\n",
      "latend variables z2  Tensor(\"sq_18_deenc_fc1_fc/Relu:0\", shape=(?, 2048), dtype=float32)\n",
      "latend variables z3  Tensor(\"Reshape_18:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_18_decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 5 shape (?, 32, 32, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_18_decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 6 shape (?, 64, 64, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_18_decode_8_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "X_hat (?, 64, 64, 3)\n",
      "DBBUG: INPUT Tensor(\"strided_slice_19:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 64, 64, 3)\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "Encode 4_shape,  (?, 2048)\n",
      "latend variables z  Tensor(\"add_19:0\", shape=(?, 16), dtype=float32)\n",
      "latend variables z2  Tensor(\"sq_19_deenc_fc1_fc/Relu:0\", shape=(?, 2048), dtype=float32)\n",
      "latend variables z3  Tensor(\"Reshape_19:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_19_decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 5 shape (?, 32, 32, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_19_decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 6 shape (?, 64, 64, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_19_decode_8_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "X_hat (?, 64, 64, 3)\n",
      "X_hat (?, 20, 64, 64, 3)\n",
      "zlog_sigma_sq_all (?, 20, 16)\n",
      "INFO:tensorflow:Restoring parameters from VAE/checkpoint/model_arc4.ckpt-87\n",
      "Seq=  (?,)\n",
      "dataset <DatasetV1Adapter shapes: OrderedDict([(images, (40, 20, 64, 64, 3))]), types: OrderedDict([(images, tf.float32)])>\n",
      "recon_loss 0.1198711\n",
      "real_image (20, 64, 64, 3)\n",
      "predic image (20, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "#def model_prediction():\n",
    "model = VariantionalAutoencoder(learning_rate=1e-4, batch_size=64, n_z=16)\n",
    "ckpt = tf.train.get_checkpoint_state(model.checkpoint_dir)\n",
    "global_step = int(os.path.basename(ckpt.model_checkpoint_path).split('-')[1])\n",
    "#First let's load meta graph and restore weights\n",
    "sess = tf.Session()  \n",
    "saver = tf.train.Saver(tf.global_variables())\n",
    "saver.restore(sess,tf.train.latest_checkpoint(model.checkpoint_dir))\n",
    "#latest_checkpoints = saver.restore(sess,tf.train.latest_checkpoint('./'))\n",
    "graph = tf.get_default_graph()\n",
    "#op = sess.graph.get_operations()\n",
    "#graph.get_tensor_by_name(\"dec_fc4\")\n",
    "loaded_vars = tf.trainable_variables() \n",
    "#loaded_vars\n",
    "#op_to_restore = graph.get_tensor_by_name(\"dec_fc4/biases:0\")\n",
    "test_iterator = make_dataset(type=\"test\")\n",
    "sess.run(test_iterator.initializer)\n",
    "for i in range(1):\n",
    "    test_batch = sess.run(test_iterator.get_next())\n",
    "    # print(\"test_batch\",test_batch[\"images\"].shape)\n",
    "    #op_to_restore.eval(feed_dict={model.x: test_batch[\"images\"]})\n",
    "    predict_images,  recon_loss = sess.run([model.x_hat, model.recon_loss], feed_dict={model.x: test_batch[\"images\"]})\n",
    "    #plot real and predicted images\n",
    "    real_img = test_batch[\"images\"][0]\n",
    "    pred_img = predict_images[0]\n",
    "    #plt.figure(figsize=(8, 8))\n",
    "    #plt.imshow(real_img[0])\n",
    "    print(\"recon_loss\",recon_loss)\n",
    "    print(\"real_image\",real_img.shape)\n",
    "    print(\"predic image\", pred_img.shape)\n",
    "#https://jhui.github.io/2017/03/08/TensorFlow-variable-sharing/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.5560357 , 0.5554696 , 0.5550167 , 0.55508465, 0.55508465,\n",
       "        0.55490345, 0.5546091 , 0.55422413, 0.55320513, 0.5519144 ,\n",
       "        0.5500576 , 0.5483366 , 0.54668355, 0.54464555, 0.54299253,\n",
       "        0.54215467, 0.54122627, 0.54025257, 0.5384863 , 0.5368785 ,\n",
       "        0.53554255, 0.5287492 , 0.5191933 , 0.512717  , 0.45368317,\n",
       "        0.4614049 , 0.4616087 , 0.45902723, 0.46871904, 0.47924864,\n",
       "        0.49399012, 0.49879074, 0.5079164 , 0.5121962 , 0.51584196,\n",
       "        0.51824224, 0.51969147, 0.52066517, 0.51609105, 0.51217353,\n",
       "        0.5048821 , 0.48690245, 0.47519532, 0.46878695, 0.46280885,\n",
       "        0.45766857, 0.452166  , 0.44648227, 0.44734275, 0.44849762,\n",
       "        0.46081614, 0.44849762, 0.4451236 , 0.43957573, 0.4354318 ,\n",
       "        0.43414107, 0.4350695 , 0.43713015, 0.44000596, 0.45092055,\n",
       "        0.4548154 , 0.45830262, 0.4615634 , 0.46244654], dtype=float32),\n",
       " array([0.55576396, 0.5558998 , 0.55601305, 0.5557413 , 0.5555602 ,\n",
       "        0.5554922 , 0.5548582 , 0.5539071 , 0.55300134, 0.55182385,\n",
       "        0.5501255 , 0.5484951 , 0.54688734, 0.545257  , 0.5436945 ,\n",
       "        0.54224527, 0.54138476, 0.54079604, 0.5389845 , 0.5371277 ,\n",
       "        0.5351802 , 0.53334606, 0.5315798 , 0.52859074, 0.52634895,\n",
       "        0.52512616, 0.5208916 , 0.5154796 , 0.5175176 , 0.5185819 ,\n",
       "        0.519465  , 0.5208237 , 0.52243143, 0.52320135, 0.5233599 ,\n",
       "        0.52236354, 0.51969147, 0.5162269 , 0.5124453 , 0.50891274,\n",
       "        0.5043386 , 0.48701566, 0.47315732, 0.4644166 , 0.4563099 ,\n",
       "        0.44947132, 0.44362906, 0.438285  , 0.43819442, 0.43880582,\n",
       "        0.44077587, 0.4386926 , 0.43454868, 0.43178606, 0.42972544,\n",
       "        0.4290914 , 0.4321031 , 0.43697163, 0.4487467 , 0.45173576,\n",
       "        0.45606083, 0.45918575, 0.46174455, 0.46113315], dtype=float32),\n",
       " array([0.55596775, 0.5564433 , 0.55703205, 0.5566018 , 0.55626214,\n",
       "        0.55612624, 0.5551752 , 0.55381656, 0.5525258 , 0.55116713,\n",
       "        0.54964995, 0.5479743 , 0.5462533 , 0.54482675, 0.54337746,\n",
       "        0.54186034, 0.5405696 , 0.5393468 , 0.5382372 , 0.53681064,\n",
       "        0.5347953 , 0.53248554, 0.52999467, 0.5290436 , 0.52816045,\n",
       "        0.5274132 , 0.52646214, 0.52539784, 0.5272094 , 0.52845484,\n",
       "        0.52854544, 0.5289077 , 0.52936065, 0.52621305, 0.5227258 ,\n",
       "        0.516476  , 0.49145398, 0.5047009 , 0.5045424 , 0.50390834,\n",
       "        0.5023006 , 0.4955073 , 0.4742669 , 0.46088406, 0.4532303 ,\n",
       "        0.44546327, 0.4401192 , 0.43599793, 0.43432224, 0.43280506,\n",
       "        0.4316502 , 0.43099353, 0.43060857, 0.43063122, 0.43051797,\n",
       "        0.43015566, 0.4340958 , 0.44018713, 0.44958454, 0.45255095,\n",
       "        0.45766857, 0.46027267, 0.46163133, 0.45474744], dtype=float32),\n",
       " array([0.5562848 , 0.5567603 , 0.5573717 , 0.5570547 , 0.5565339 ,\n",
       "        0.5556507 , 0.5545412 , 0.55329573, 0.5518691 , 0.5503293 ,\n",
       "        0.5485857 , 0.5470006 , 0.54550606, 0.54367185, 0.54197353,\n",
       "        0.54054695, 0.5390751 , 0.5376032 , 0.53642565, 0.53520286,\n",
       "        0.5338895 , 0.5327573 , 0.53171563, 0.5305155 , 0.5297909 ,\n",
       "        0.52999467, 0.5305608 , 0.53126276, 0.53287053, 0.53345925,\n",
       "        0.53203267, 0.52947384, 0.52634895, 0.52134454, 0.49072933,\n",
       "        0.48153573, 0.48135456, 0.49727356, 0.49890396, 0.49897188,\n",
       "        0.5011005 , 0.49625456, 0.48898572, 0.4615634 , 0.4551324 ,\n",
       "        0.44686723, 0.44238362, 0.43982482, 0.4369037 , 0.4344581 ,\n",
       "        0.43294093, 0.43214837, 0.4316955 , 0.43323532, 0.43484306,\n",
       "        0.43654138, 0.4387379 , 0.44784093, 0.450128  , 0.45565322,\n",
       "        0.46104258, 0.46287677, 0.46387312, 0.4577818 ], dtype=float32),\n",
       " array([0.557417  , 0.5574623 , 0.55707735, 0.5565112 , 0.555696  ,\n",
       "        0.5544053 , 0.553024  , 0.55162   , 0.5503972 , 0.548948  ,\n",
       "        0.5470006 , 0.5453928 , 0.5439436 , 0.5423585 , 0.54079604,\n",
       "        0.5393015 , 0.537422  , 0.5353614 , 0.5350444 , 0.5347953 ,\n",
       "        0.5346594 , 0.53452355, 0.53436506, 0.5340027 , 0.53379893,\n",
       "        0.5339348 , 0.5346594 , 0.5356331 , 0.5350897 , 0.5336178 ,\n",
       "        0.51133573, 0.51018083, 0.5126717 , 0.49016324, 0.48540792,\n",
       "        0.48019972, 0.48042616, 0.49500912, 0.49727356, 0.49962857,\n",
       "        0.50033057, 0.4977944 , 0.49371842, 0.48640427, 0.45841584,\n",
       "        0.44747862, 0.44258744, 0.4406853 , 0.43853408, 0.4370169 ,\n",
       "        0.4366999 , 0.43602055, 0.43513742, 0.4364055 , 0.43876052,\n",
       "        0.44335735, 0.44582558, 0.45295855, 0.45642313, 0.46219745,\n",
       "        0.4647789 , 0.46697542, 0.46928513, 0.47025883], dtype=float32),\n",
       " array([0.5571679 , 0.55694145, 0.5565339 , 0.55576396, 0.55469966,\n",
       "        0.55309194, 0.5514162 , 0.54969525, 0.5480649 , 0.5463213 ,\n",
       "        0.5443738 , 0.5431963 , 0.54224527, 0.5412489 , 0.5400941 ,\n",
       "        0.538826  , 0.53719556, 0.5355652 , 0.5350444 , 0.53540665,\n",
       "        0.53656155, 0.5374673 , 0.5382372 , 0.53871274, 0.53880334,\n",
       "        0.53866744, 0.53866744, 0.537807  , 0.5342065 , 0.530357  ,\n",
       "        0.506286  , 0.5031611 , 0.4975906 , 0.48846492, 0.48502296,\n",
       "        0.48327935, 0.4846833 , 0.49451095, 0.49897188, 0.5003079 ,\n",
       "        0.4999456 , 0.4958017 , 0.49075198, 0.4840266 , 0.47558028,\n",
       "        0.45080733, 0.443697  , 0.43998334, 0.43835294, 0.43697163,\n",
       "        0.43636024, 0.43692634, 0.438987  , 0.4404815 , 0.44220248,\n",
       "        0.44476128, 0.44876933, 0.45732892, 0.46104258, 0.46545824,\n",
       "        0.4693757 , 0.47277236, 0.47598785, 0.4783429 ], dtype=float32),\n",
       " array([0.55562806, 0.5553564 , 0.555062  , 0.5545412 , 0.55368066,\n",
       "        0.55232203, 0.5504425 , 0.548314  , 0.5457325 , 0.54367185,\n",
       "        0.5419509 , 0.54152066, 0.54127157, 0.54113567, 0.5401393 ,\n",
       "        0.5389392 , 0.53782964, 0.53715026, 0.53681064, 0.5379202 ,\n",
       "        0.53927886, 0.54070544, 0.54122627, 0.54143006, 0.54147536,\n",
       "        0.54075074, 0.53948265, 0.5370597 , 0.5328026 , 0.5263942 ,\n",
       "        0.5070786 , 0.5033196 , 0.49944744, 0.49476004, 0.4909105 ,\n",
       "        0.48903102, 0.48828375, 0.4879441 , 0.4901859 , 0.49883604,\n",
       "        0.49451095, 0.48986885, 0.48540792, 0.47761825, 0.47089288,\n",
       "        0.44827116, 0.44276857, 0.43835294, 0.4371075 , 0.4379227 ,\n",
       "        0.440323  , 0.4455765 , 0.4489958 , 0.44938073, 0.45006007,\n",
       "        0.45082998, 0.45864227, 0.4622201 , 0.4671792 , 0.47168544,\n",
       "        0.47582936, 0.4794751 , 0.4824415 , 0.48486444], dtype=float32),\n",
       " array([0.55368066, 0.55386186, 0.5539071 , 0.55392975, 0.5534995 ,\n",
       "        0.5523447 , 0.54998964, 0.5472497 , 0.5442153 , 0.5423585 ,\n",
       "        0.5413395 , 0.5405696 , 0.5401167 , 0.5400714 , 0.5397997 ,\n",
       "        0.53927886, 0.5379655 , 0.5371729 , 0.5367427 , 0.5380561 ,\n",
       "        0.5397544 , 0.5419962 , 0.5430152 , 0.5435813 , 0.543536  ,\n",
       "        0.5423132 , 0.5403205 , 0.53651625, 0.53155714, 0.5248318 ,\n",
       "        0.5065351 , 0.5024138 , 0.49885866, 0.49625456, 0.49426186,\n",
       "        0.49129546, 0.48975563, 0.49521294, 0.49659422, 0.4959602 ,\n",
       "        0.4872874 , 0.47974682, 0.47297618, 0.45698926, 0.45255095,\n",
       "        0.44729745, 0.4449198 , 0.4426327 , 0.43826234, 0.43817177,\n",
       "        0.45137343, 0.46588847, 0.47397253, 0.47234213, 0.468402  ,\n",
       "        0.46545824, 0.46862844, 0.47200245, 0.47571614, 0.478909  ,\n",
       "        0.48210183, 0.48522675, 0.48767236, 0.4894839 ], dtype=float32),\n",
       " array([0.55241257, 0.5528202 , 0.55329573, 0.5530693 , 0.5525258 ,\n",
       "        0.55148417, 0.5494688 , 0.5470912 , 0.5441247 , 0.5419962 ,\n",
       "        0.5404337 , 0.5400714 , 0.53961855, 0.5389845 , 0.5381014 ,\n",
       "        0.53715026, 0.53631246, 0.5361539 , 0.53647095, 0.53762585,\n",
       "        0.53923357, 0.54143006, 0.54278874, 0.5434454 , 0.5422679 ,\n",
       "        0.54059225, 0.53855425, 0.53447825, 0.529338  , 0.5225447 ,\n",
       "        0.5085731 , 0.5053123 , 0.50166655, 0.4985643 , 0.4958017 ,\n",
       "        0.49505442, 0.49426186, 0.49444303, 0.49292585, 0.4907067 ,\n",
       "        0.4701909 , 0.46862844, 0.46122375, 0.4589593 , 0.45678544,\n",
       "        0.44621053, 0.43885112, 0.43762833, 0.44016448, 0.4443084 ,\n",
       "        0.47048527, 0.47852403, 0.48183012, 0.47795793, 0.4763502 ,\n",
       "        0.47582936, 0.4774371 , 0.47976947, 0.48257738, 0.4850456 ,\n",
       "        0.4874912 , 0.48986885, 0.49197477, 0.49353725], dtype=float32),\n",
       " array([0.5528881 , 0.5526164 , 0.55270696, 0.5520503 , 0.5511445 ,\n",
       "        0.5498538 , 0.54790634, 0.5457325 , 0.54326427, 0.5407734 ,\n",
       "        0.5382372 , 0.5375126 , 0.5369465 , 0.53656155, 0.5359728 ,\n",
       "        0.53540665, 0.5351349 , 0.5349538 , 0.53486323, 0.53617656,\n",
       "        0.53782964, 0.5399808 , 0.54192823, 0.54335487, 0.5427208 ,\n",
       "        0.54075074, 0.53787494, 0.5330743 , 0.5268471 , 0.5185819 ,\n",
       "        0.51434743, 0.50166655, 0.5003532 , 0.4991757 , 0.49808878,\n",
       "        0.497183  , 0.49301642, 0.48925745, 0.48900837, 0.4888725 ,\n",
       "        0.46736038, 0.46194836, 0.45572117, 0.4612011 , 0.47023618,\n",
       "        0.45080733, 0.43760568, 0.4377189 , 0.44999215, 0.45510978,\n",
       "        0.48266795, 0.48486444, 0.48475122, 0.48124135, 0.48262265,\n",
       "        0.48522675, 0.48792145, 0.49045762, 0.4929032 , 0.4934693 ,\n",
       "        0.49383163, 0.49394485, 0.4945336 , 0.49539408], dtype=float32),\n",
       " array([0.5513483 , 0.5507369 , 0.55046517, 0.54974055, 0.54881215,\n",
       "        0.54765725, 0.54546076, 0.54294723, 0.5401393 , 0.537807  ,\n",
       "        0.535769  , 0.5345009 , 0.5339121 , 0.5337763 , 0.5340254 ,\n",
       "        0.5350897 , 0.5369918 , 0.53821456, 0.5390524 , 0.5393468 ,\n",
       "        0.5400488 , 0.54079604, 0.541498  , 0.5420415 , 0.5422226 ,\n",
       "        0.5403205 , 0.5379428 , 0.53520286, 0.5284322 , 0.52039343,\n",
       "        0.51074696, 0.5041122 , 0.50248176, 0.50001353, 0.49761322,\n",
       "        0.49512234, 0.49202007, 0.48980093, 0.48835167, 0.48706096,\n",
       "        0.47911277, 0.4645298 , 0.4602274 , 0.45963863, 0.48583817,\n",
       "        0.4854985 , 0.484638  , 0.4850909 , 0.48812523, 0.49202007,\n",
       "        0.4937637 , 0.4932655 , 0.49102372, 0.49374104, 0.4957564 ,\n",
       "        0.4968886 , 0.49797553, 0.4985643 , 0.4981114 , 0.49702448,\n",
       "        0.49577904, 0.494828  , 0.49408072, 0.49367312], dtype=float32),\n",
       " array([0.55055577, 0.54989904, 0.5481554 , 0.5476799 , 0.547227  ,\n",
       "        0.54677415, 0.5446003 , 0.5419056 , 0.5385769 , 0.53579164,\n",
       "        0.5333687 , 0.53189677, 0.531693  , 0.5323497 , 0.53379893,\n",
       "        0.5361087 , 0.5392562 , 0.54219997, 0.5436492 , 0.5425623 ,\n",
       "        0.542517  , 0.5428567 , 0.5436492 , 0.5436492 , 0.5430605 ,\n",
       "        0.5409772 , 0.5382372 , 0.5349991 , 0.5273453 , 0.5184234 ,\n",
       "        0.5078032 , 0.50399894, 0.5025497 , 0.49922097, 0.49799818,\n",
       "        0.49756795, 0.49797553, 0.49802083, 0.4968207 , 0.49281263,\n",
       "        0.48518148, 0.4782523 , 0.4793845 , 0.48581553, 0.48986885,\n",
       "        0.49215594, 0.4942166 , 0.4968886 , 0.4973415 , 0.49706978,\n",
       "        0.49883604, 0.4997418 , 0.49992296, 0.50209683, 0.5025044 ,\n",
       "        0.5006702 , 0.500172  , 0.49899453, 0.49557525, 0.4845248 ,\n",
       "        0.4727497 , 0.46822086, 0.46989653, 0.47551233], dtype=float32),\n",
       " array([0.54503053, 0.5461175 , 0.5464571 , 0.54595894, 0.54541546,\n",
       "        0.5447588 , 0.5426302 , 0.54020727, 0.53753525, 0.5351123 ,\n",
       "        0.5329611 , 0.531693  , 0.53151184, 0.53207797, 0.5338895 ,\n",
       "        0.5361539 , 0.53884864, 0.5417018 , 0.5434001 , 0.5431284 ,\n",
       "        0.5429699 , 0.54283404, 0.5426755 , 0.5423132 , 0.5417018 ,\n",
       "        0.5401846 , 0.53733146, 0.5334366 , 0.52489966, 0.51536644,\n",
       "        0.50451976, 0.5037725 , 0.505335  , 0.5029573 , 0.49926627,\n",
       "        0.4959149 , 0.49582434, 0.4967754 , 0.49788496, 0.49138603,\n",
       "        0.48332465, 0.4764181 , 0.48056203, 0.4835058 , 0.48321143,\n",
       "        0.47983742, 0.47990534, 0.49204272, 0.4973415 , 0.49849635,\n",
       "        0.5006702 , 0.50139487, 0.50103253, 0.50166655, 0.49971914,\n",
       "        0.49442038, 0.4896424 , 0.4840719 , 0.456876  , 0.43826234,\n",
       "        0.41681814, 0.4080095 , 0.40993425, 0.41799566], dtype=float32),\n",
       " array([0.52451473, 0.5373541 , 0.540479  , 0.5410678 , 0.54161125,\n",
       "        0.542132  , 0.5415886 , 0.54054695, 0.53880334, 0.53715026,\n",
       "        0.53579164, 0.535384  , 0.5351349 , 0.5350217 , 0.53570104,\n",
       "        0.5369238 , 0.53835046, 0.5397091 , 0.5406375 , 0.54095453,\n",
       "        0.54084134, 0.5408187 , 0.54045635, 0.5400941 , 0.5396638 ,\n",
       "        0.5383957 , 0.536086  , 0.53305167, 0.5259413 , 0.5169968 ,\n",
       "        0.5063766 , 0.50506324, 0.5083014 , 0.5051991 , 0.50134957,\n",
       "        0.49793026, 0.49675274, 0.49566582, 0.4955526 , 0.49172568,\n",
       "        0.48210183, 0.4784108 , 0.4740631 , 0.45264152, 0.442678  ,\n",
       "        0.44217983, 0.45320764, 0.4588461 , 0.4854985 , 0.49149925,\n",
       "        0.49645838, 0.49430716, 0.49118224, 0.488714  , 0.4832567 ,\n",
       "        0.4598877 , 0.44535005, 0.43439016, 0.41829002, 0.4062885 ,\n",
       "        0.39813656, 0.39700434, 0.39863473, 0.39985752], dtype=float32),\n",
       " array([0.51910275, 0.5186046 , 0.53375363, 0.53635776, 0.5383731 ,\n",
       "        0.53977704, 0.5400941 , 0.5400941 , 0.5397544 , 0.53943735,\n",
       "        0.53918827, 0.5390298 , 0.5390298 , 0.5388713 , 0.5384863 ,\n",
       "        0.5388939 , 0.53923357, 0.53952795, 0.53943735, 0.5389392 ,\n",
       "        0.5380561 , 0.53787494, 0.5373541 , 0.5364936 , 0.53520286,\n",
       "        0.5333913 , 0.53105897, 0.529338  , 0.5249676 , 0.51794785,\n",
       "        0.51099604, 0.50667095, 0.51018083, 0.5061501 , 0.5028894 ,\n",
       "        0.5003985 , 0.49874544, 0.4977944 , 0.49756795, 0.49274468,\n",
       "        0.47847876, 0.4696248 , 0.46004623, 0.45200747, 0.44548592,\n",
       "        0.4456444 , 0.44888255, 0.455223  , 0.45866492, 0.4654356 ,\n",
       "        0.48067525, 0.46792647, 0.46158606, 0.45805353, 0.454204  ,\n",
       "        0.44845232, 0.44082117, 0.4274157 , 0.4162294 , 0.40721694,\n",
       "        0.40293714, 0.4010124 , 0.40141997, 0.40189552], dtype=float32),\n",
       " array([0.5169515 , 0.51366806, 0.5224541 , 0.52902097, 0.5333913 ,\n",
       "        0.53554255, 0.5365389 , 0.53733146, 0.53787494, 0.5380787 ,\n",
       "        0.5382372 , 0.5383731 , 0.5386448 , 0.5384863 , 0.5379655 ,\n",
       "        0.5379881 , 0.5379655 , 0.53782964, 0.5368785 , 0.5356784 ,\n",
       "        0.53427446, 0.5333913 , 0.5321685 , 0.53062874, 0.5273453 ,\n",
       "        0.52532995, 0.52422035, 0.5224994 , 0.5190348 , 0.51384926,\n",
       "        0.5104752 , 0.50558406, 0.50701064, 0.50413483, 0.50184774,\n",
       "        0.5001494 , 0.5008514 , 0.5009193 , 0.5003985 , 0.49435243,\n",
       "        0.4844795 , 0.47073436, 0.4615634 , 0.45610613, 0.45438513,\n",
       "        0.45248303, 0.4515999 , 0.45175838, 0.45474744, 0.45610613,\n",
       "        0.4638505 , 0.4559929 , 0.45454365, 0.45139608, 0.4473201 ,\n",
       "        0.4429271 , 0.43819442, 0.42961222, 0.42263776, 0.41729367,\n",
       "        0.41432726, 0.41040978, 0.40554124, 0.4059262 ], dtype=float32),\n",
       " array([0.51867247, 0.5140304 , 0.5112225 , 0.52211446, 0.5266207 ,\n",
       "        0.5289077 , 0.53049284, 0.5321006 , 0.53370833, 0.53443295,\n",
       "        0.535067  , 0.5356105 , 0.53570104, 0.5356784 , 0.5355199 ,\n",
       "        0.5358822 , 0.53579164, 0.53524816, 0.5309004 , 0.5267339 ,\n",
       "        0.5227485 , 0.52435625, 0.515457  , 0.5231787 , 0.5142795 ,\n",
       "        0.51790255, 0.51486826, 0.5144606 , 0.51314723, 0.51088285,\n",
       "        0.5073956 , 0.50540286, 0.5048821 , 0.50261766, 0.50048906,\n",
       "        0.49849635, 0.49999088, 0.501191  , 0.50214213, 0.4972509 ,\n",
       "        0.4895745 , 0.47909015, 0.4701456 , 0.4636014 , 0.45943484,\n",
       "        0.45400017, 0.45110172, 0.4507394 , 0.45259625, 0.45341143,\n",
       "        0.45316234, 0.4522792 , 0.4515999 , 0.45116964, 0.44535005,\n",
       "        0.44020978, 0.4357262 , 0.4308803 , 0.42718926, 0.42463046,\n",
       "        0.42152816, 0.41702193, 0.41113442, 0.4093002 ], dtype=float32),\n",
       " array([0.5233599 , 0.51824224, 0.51323783, 0.5154796 , 0.52186537,\n",
       "        0.5247185 , 0.52519405, 0.5264395 , 0.5286586 , 0.53044754,\n",
       "        0.5323497 , 0.53436506, 0.53529346, 0.5359728 , 0.53647095,\n",
       "        0.536086  , 0.53477263, 0.5324629 , 0.5227032 , 0.5165666 ,\n",
       "        0.5032064 , 0.5081881 , 0.50968266, 0.50947887, 0.51045257,\n",
       "        0.5105205 , 0.5097053 , 0.5095921 , 0.5088222 , 0.5073956 ,\n",
       "        0.50612754, 0.50495   , 0.50384045, 0.5009193 , 0.498202  ,\n",
       "        0.49571112, 0.49589226, 0.49686596, 0.49860957, 0.49824727,\n",
       "        0.49521294, 0.48943862, 0.48022237, 0.47123256, 0.4624918 ,\n",
       "        0.45424926, 0.44994685, 0.44958454, 0.453502  , 0.4548607 ,\n",
       "        0.45366052, 0.4522792 , 0.44999215, 0.44679928, 0.4422704 ,\n",
       "        0.4380812 , 0.43418637, 0.43414107, 0.43269184, 0.4298613 ,\n",
       "        0.42530978, 0.42125645, 0.41767862, 0.41502923], dtype=float32),\n",
       " array([0.5258055 , 0.5230202 , 0.51828754, 0.5144606 , 0.5109734 ,\n",
       "        0.5099091 , 0.5082787 , 0.509026  , 0.5223862 , 0.5264848 ,\n",
       "        0.53058344, 0.53463674, 0.53681064, 0.5378523 , 0.537807  ,\n",
       "        0.5370144 , 0.5345915 , 0.5305155 , 0.52014434, 0.51396245,\n",
       "        0.5001268 , 0.50748616, 0.5091166 , 0.5091166 , 0.50916183,\n",
       "        0.50913924, 0.50904864, 0.50793904, 0.50671625, 0.5053576 ,\n",
       "        0.50447446, 0.50350076, 0.50243646, 0.4998324 , 0.49704713,\n",
       "        0.49405807, 0.49260882, 0.49267676, 0.49426186, 0.4963225 ,\n",
       "        0.49607342, 0.4935146 , 0.4850909 , 0.4752859 , 0.4640543 ,\n",
       "        0.45372847, 0.44827116, 0.44765976, 0.4529812 , 0.45526826,\n",
       "        0.45458895, 0.452166  , 0.4487014 , 0.44419518, 0.44045886,\n",
       "        0.43722072, 0.4344581 , 0.43602055, 0.43504685, 0.43155962,\n",
       "        0.4268043 , 0.42401904, 0.4231812 , 0.42105263], dtype=float32),\n",
       " array([0.5246506 , 0.52349573, 0.51964617, 0.5138945 , 0.50866365,\n",
       "        0.5039763 , 0.5027988 , 0.5041122 , 0.51994056, 0.52591866,\n",
       "        0.5308552 , 0.5349991 , 0.5379655 , 0.5388939 , 0.53830516,\n",
       "        0.5370144 , 0.5329611 , 0.5237448 , 0.5165213 , 0.50972795,\n",
       "        0.50696534, 0.51022613, 0.510679  , 0.51070166, 0.5098865 ,\n",
       "        0.50879955, 0.50768995, 0.5065804 , 0.5051764 , 0.503931  ,\n",
       "        0.5034328 , 0.50232327, 0.50073814, 0.49817935, 0.49722826,\n",
       "        0.49577904, 0.49374104, 0.4926994 , 0.49235973, 0.49215594,\n",
       "        0.49288055, 0.49174833, 0.48719683, 0.47689363, 0.46649987,\n",
       "        0.45705718, 0.4539549 , 0.4519169 , 0.4519169 , 0.45445308,\n",
       "        0.4552456 , 0.45386434, 0.44738802, 0.4429724 , 0.4401192 ,\n",
       "        0.43744716, 0.4352733 , 0.43416372, 0.43167284, 0.42743835,\n",
       "        0.42352086, 0.42313594, 0.42329443, 0.42263776], dtype=float32),\n",
       " array([0.52105016, 0.5205746 , 0.5189895 , 0.5146418 , 0.5097053 ,\n",
       "        0.50442916, 0.50395364, 0.5055614 , 0.52145773, 0.5287039 ,\n",
       "        0.5339574 , 0.5375126 , 0.53859955, 0.53859955, 0.53753525,\n",
       "        0.53379893, 0.5304249 , 0.51731384, 0.5103394 , 0.508007  ,\n",
       "        0.5075541 , 0.5092071 , 0.5101356 , 0.5102488 , 0.50850517,\n",
       "        0.5065351 , 0.50472355, 0.50354606, 0.5016892 , 0.4999003 ,\n",
       "        0.49860957, 0.4965263 , 0.4939675 , 0.49079728, 0.4901406 ,\n",
       "        0.4889631 , 0.4865628 , 0.48624575, 0.48735532, 0.49007267,\n",
       "        0.49143133, 0.4907067 , 0.48778558, 0.47757298, 0.46894547,\n",
       "        0.46201628, 0.46092936, 0.45900458, 0.45653635, 0.45556265,\n",
       "        0.4532303 , 0.44999215, 0.44711632, 0.44489715, 0.44283652,\n",
       "        0.43950778, 0.43622437, 0.43319002, 0.4311294 , 0.42845735,\n",
       "        0.4262382 , 0.42650995, 0.42515126, 0.423068  ], dtype=float32),\n",
       " array([0.51575136, 0.51532114, 0.51532114, 0.51287556, 0.5117433 ,\n",
       "        0.5112225 , 0.5160231 , 0.5213672 , 0.52630365, 0.5312854 ,\n",
       "        0.5352255 , 0.53728616, 0.53753525, 0.5364936 , 0.5332781 ,\n",
       "        0.5302664 , 0.52018964, 0.512717  , 0.50787115, 0.5058558 ,\n",
       "        0.50549346, 0.50574255, 0.5060143 , 0.50599164, 0.5045877 ,\n",
       "        0.5025497 , 0.5011684 , 0.5012363 , 0.5005117 , 0.4984737 ,\n",
       "        0.4953035 , 0.49072933, 0.48563436, 0.48117343, 0.47786734,\n",
       "        0.46969274, 0.46391842, 0.46165398, 0.4642128 , 0.47648603,\n",
       "        0.48563436, 0.48973298, 0.48654014, 0.47961095, 0.47295353,\n",
       "        0.46831143, 0.4638505 , 0.4597745 , 0.4567628 , 0.45710248,\n",
       "        0.45510978, 0.45132816, 0.4463464 , 0.44530475, 0.44351584,\n",
       "        0.4408891 , 0.43774155, 0.43529594, 0.43196723, 0.42700812,\n",
       "        0.4218452 , 0.42356616, 0.4264873 , 0.4250154 ], dtype=float32),\n",
       " array([0.5133058 , 0.5123774 , 0.511698  , 0.51298875, 0.5134869 ,\n",
       "        0.51527584, 0.51706475, 0.52243143, 0.5281378 , 0.5329384 ,\n",
       "        0.5352255 , 0.53475   , 0.53198737, 0.5267565 , 0.52410716,\n",
       "        0.52206916, 0.51366806, 0.5094562 , 0.5068748 , 0.5052897 ,\n",
       "        0.50451976, 0.50399894, 0.5037725 , 0.50354606, 0.5022553 ,\n",
       "        0.49969652, 0.49740943, 0.49614134, 0.49444303, 0.49048024,\n",
       "        0.48513618, 0.4799959 , 0.47904485, 0.4793166 , 0.47979212,\n",
       "        0.47614637, 0.46763209, 0.4592084 , 0.45741948, 0.46631873,\n",
       "        0.47562554, 0.48332465, 0.4855438 , 0.48257738, 0.47798055,\n",
       "        0.4740631 , 0.4693757 , 0.46443924, 0.4595254 , 0.45563057,\n",
       "        0.4525736 , 0.4489505 , 0.4440593 , 0.44179487, 0.4399607 ,\n",
       "        0.438285  , 0.43622437, 0.43472984, 0.4320578 , 0.4277554 ,\n",
       "        0.42284155, 0.4250607 , 0.42660052, 0.4172484 ], dtype=float32),\n",
       " array([0.50374985, 0.50069284, 0.49874544, 0.5030479 , 0.5055614 ,\n",
       "        0.5075994 , 0.51206034, 0.52431095, 0.5280699 , 0.5324176 ,\n",
       "        0.5310816 , 0.5281378 , 0.5231787 , 0.52141243, 0.516476  ,\n",
       "        0.5119471 , 0.50859576, 0.5062634 , 0.50476885, 0.50379515,\n",
       "        0.5032064 , 0.50293463, 0.5023912 , 0.50146276, 0.4995833 ,\n",
       "        0.49414864, 0.48665336, 0.47755033, 0.46894547, 0.4621295 ,\n",
       "        0.45769122, 0.45784974, 0.46403164, 0.4692172 , 0.47148165,\n",
       "        0.4716175 , 0.4711646 , 0.47093818, 0.47211567, 0.47404045,\n",
       "        0.4763049 , 0.478909  , 0.481966  , 0.4796789 , 0.474833  ,\n",
       "        0.4690134 , 0.46770003, 0.46425807, 0.45866492, 0.45189425,\n",
       "        0.44849762, 0.44657284, 0.44546327, 0.44265535, 0.44095704,\n",
       "        0.43987012, 0.43842086, 0.43753773, 0.4360432 , 0.43330324,\n",
       "        0.42528713, 0.42127907, 0.4191505 , 0.41672757], dtype=float32),\n",
       " array([0.5027535 , 0.5013269 , 0.49867752, 0.5029573 , 0.50782585,\n",
       "        0.52023494, 0.5256017 , 0.5298588 , 0.53198737, 0.52990407,\n",
       "        0.5258734 , 0.5213898 , 0.51930654, 0.5144833 , 0.5118792 ,\n",
       "        0.50986385, 0.5082787 , 0.5074182 , 0.5067842 , 0.50594634,\n",
       "        0.50447446, 0.5032743 , 0.5022327 , 0.50175714, 0.50359136,\n",
       "        0.4987681 , 0.48751384, 0.4691266 , 0.46194836, 0.4569213 ,\n",
       "        0.45440778, 0.45592496, 0.46138224, 0.46468833, 0.46428072,\n",
       "        0.4627409 , 0.46276355, 0.4641675 , 0.46715656, 0.47173074,\n",
       "        0.473814  , 0.47317997, 0.47252327, 0.47159487, 0.46824348,\n",
       "        0.4602274 , 0.45105642, 0.4450783 , 0.4419081 , 0.43987012,\n",
       "        0.4388964 , 0.43790004, 0.4363376 , 0.4284347 , 0.426442  ,\n",
       "        0.42902344, 0.4344581 , 0.43597528, 0.43597528, 0.43488833,\n",
       "        0.43155962, 0.4287291 , 0.4255815 , 0.42107528], dtype=float32),\n",
       " array([0.5434001 , 0.5460269 , 0.5453023 , 0.5450985 , 0.54507583,\n",
       "        0.545189  , 0.5453702 , 0.5373541 , 0.53379893, 0.5285228 ,\n",
       "        0.5285228 , 0.52630365, 0.52256733, 0.517812  , 0.51371336,\n",
       "        0.5101582 , 0.50710124, 0.503931  , 0.502278  , 0.50125897,\n",
       "        0.50033057, 0.4955073 , 0.49072933, 0.48780823, 0.49288055,\n",
       "        0.49548465, 0.4938769 , 0.48674393, 0.4701909 , 0.46251446,\n",
       "        0.46228802, 0.46824348, 0.46606964, 0.46183515, 0.45714775,\n",
       "        0.4525283 , 0.44976568, 0.44781828, 0.4456897 , 0.45049033,\n",
       "        0.4565137 , 0.46190307, 0.45954806, 0.4535926 , 0.44591615,\n",
       "        0.43753773, 0.43208045, 0.4283894 , 0.42662317, 0.4281177 ,\n",
       "        0.43092558, 0.4297481 , 0.42175463, 0.40218988, 0.3928604 ,\n",
       "        0.3936756 , 0.40721694, 0.4165917 , 0.42528713, 0.43371084,\n",
       "        0.43371084, 0.43085766, 0.42641935, 0.42161876], dtype=float32),\n",
       " array([0.56402916, 0.5643688 , 0.56350833, 0.5623761 , 0.5610401 ,\n",
       "        0.5591606 , 0.55601305, 0.5447588 , 0.5403884 , 0.5340254 ,\n",
       "        0.5322138 , 0.5297682 , 0.5262357 , 0.52071047, 0.5136907 ,\n",
       "        0.5070786 , 0.5012816 , 0.4973415 , 0.49521294, 0.49340138,\n",
       "        0.49077463, 0.48078847, 0.47057587, 0.4624692 , 0.46434867,\n",
       "        0.47164014, 0.47816172, 0.48103756, 0.46824348, 0.46527708,\n",
       "        0.46908134, 0.47481036, 0.46428072, 0.45300382, 0.44523683,\n",
       "        0.4432894 , 0.44596145, 0.44840702, 0.44417253, 0.44041356,\n",
       "        0.44000596, 0.442678  , 0.44392344, 0.4364055 , 0.42662317,\n",
       "        0.418992  , 0.428797  , 0.43420902, 0.43484306, 0.43330324,\n",
       "        0.43319002, 0.43217102, 0.4290461 , 0.4228642 , 0.41570857,\n",
       "        0.40846238, 0.403073  , 0.40083122, 0.402756  , 0.40945873,\n",
       "        0.4222528 , 0.42850265, 0.4287291 , 0.4218905 ], dtype=float32),\n",
       " array([0.5711621 , 0.56996197, 0.5681504 , 0.56536514, 0.5606551 ,\n",
       "        0.5555828 , 0.5531146 , 0.54084134, 0.53923357, 0.5339348 ,\n",
       "        0.52927005, 0.52442414, 0.5188989 , 0.5118792 , 0.5037725 ,\n",
       "        0.49643573, 0.49043497, 0.4882611 , 0.4860193 , 0.48323405,\n",
       "        0.47936186, 0.4710061 , 0.46627343, 0.46527708, 0.4674736 ,\n",
       "        0.46890017, 0.47030413, 0.4720251 , 0.467066  , 0.46794912,\n",
       "        0.4728403 , 0.47863725, 0.47358757, 0.46541294, 0.45637783,\n",
       "        0.45332086, 0.45372847, 0.4546116 , 0.45212072, 0.44700307,\n",
       "        0.44102496, 0.4353186 , 0.43574885, 0.43350706, 0.43076706,\n",
       "        0.4290461 , 0.43314472, 0.4345034 , 0.43355232, 0.43314472,\n",
       "        0.43468454, 0.43577147, 0.4352733 , 0.4338014 , 0.43063122,\n",
       "        0.4234756 , 0.4061753 , 0.39077714, 0.3818326 , 0.38137972,\n",
       "        0.39686847, 0.4118817 , 0.4221622 , 0.42080355], dtype=float32),\n",
       " array([0.5602249 , 0.55714524, 0.5528202 , 0.5492877 , 0.51987267,\n",
       "        0.5167477 , 0.5203482 , 0.520869  , 0.5216163 , 0.5227485 ,\n",
       "        0.5199179 , 0.514121  , 0.506988  , 0.5002173 , 0.49371842,\n",
       "        0.48817053, 0.48380017, 0.481264  , 0.47981477, 0.47788998,\n",
       "        0.47415367, 0.47241005, 0.4749915 , 0.4796336 , 0.47788998,\n",
       "        0.47114196, 0.46577525, 0.4648242 , 0.47168544, 0.47816172,\n",
       "        0.48169425, 0.47573876, 0.46792647, 0.46215215, 0.45938954,\n",
       "        0.45637783, 0.4535926 , 0.45107907, 0.44897315, 0.44535005,\n",
       "        0.44086647, 0.43595263, 0.43269184, 0.4292046 , 0.42877436,\n",
       "        0.4346619 , 0.4343449 , 0.43051797, 0.42544565, 0.42666844,\n",
       "        0.42723456, 0.42673638, 0.42490217, 0.42333972, 0.41971663,\n",
       "        0.41369322, 0.4039788 , 0.39569095, 0.39256603, 0.39578155,\n",
       "        0.403073  , 0.41047773, 0.41566327, 0.414916  ], dtype=float32),\n",
       " array([0.5397544 , 0.5345915 , 0.52816045, 0.5025497 , 0.50205153,\n",
       "        0.50166655, 0.50214213, 0.5021874 , 0.50261766, 0.5035234 ,\n",
       "        0.50205153, 0.49890396, 0.4949412 , 0.4911596 , 0.48814788,\n",
       "        0.48622313, 0.48522675, 0.48341522, 0.48275852, 0.4818754 ,\n",
       "        0.47958833, 0.4794751 , 0.48121873, 0.48291704, 0.4773918 ,\n",
       "        0.47114196, 0.4654809 , 0.46111053, 0.46758682, 0.474833  ,\n",
       "        0.47854668, 0.4681982 , 0.45827997, 0.45243773, 0.4515546 ,\n",
       "        0.44978833, 0.44883728, 0.44879198, 0.44990155, 0.44550854,\n",
       "        0.44172695, 0.4393493 , 0.43765095, 0.43253332, 0.42895553,\n",
       "        0.43110675, 0.42995188, 0.42825356, 0.42696282, 0.42943105,\n",
       "        0.42601177, 0.4208715 , 0.41568592, 0.41403288, 0.41156465,\n",
       "        0.40671876, 0.39537394, 0.39451346, 0.40012926, 0.41063625,\n",
       "        0.41136086, 0.409187  , 0.40524688, 0.40042362], dtype=float32),\n",
       " array([0.4879441 , 0.4870383 , 0.48454744, 0.4839134 , 0.4870383 ,\n",
       "        0.49158984, 0.49265411, 0.4915219 , 0.49048024, 0.49000472,\n",
       "        0.48807997, 0.48511353, 0.4818754 , 0.47920337, 0.4798827 ,\n",
       "        0.4820339 , 0.4849324 , 0.48490974, 0.48404926, 0.4822377 ,\n",
       "        0.47920337, 0.48133194, 0.48380017, 0.48552114, 0.48368695,\n",
       "        0.4816716 , 0.47752768, 0.47016826, 0.47032678, 0.47367814,\n",
       "        0.47639546, 0.469738  , 0.4614049 , 0.45370582, 0.44729745,\n",
       "        0.4425648 , 0.4426327 , 0.44498774, 0.44720688, 0.44383287,\n",
       "        0.44082117, 0.43916813, 0.43989274, 0.43717542, 0.43178606,\n",
       "        0.42365673, 0.4133762 , 0.41034186, 0.414599  , 0.4256268 ,\n",
       "        0.42662317, 0.42238867, 0.41448578, 0.41233456, 0.41369322,\n",
       "        0.41573122, 0.41249308, 0.4099116 , 0.40728486, 0.40461284,\n",
       "        0.40504307, 0.40178227, 0.3964835 , 0.39057332], dtype=float32),\n",
       " array([0.46280885, 0.46638665, 0.46430337, 0.46951157, 0.4764181 ,\n",
       "        0.48282647, 0.48552114, 0.48416248, 0.48257738, 0.481264  ,\n",
       "        0.47940716, 0.47530854, 0.47193453, 0.47066644, 0.47295353,\n",
       "        0.4783655 , 0.484321  , 0.48780823, 0.48774028, 0.48443422,\n",
       "        0.48151308, 0.48248678, 0.48400396, 0.4854985 , 0.4839813 ,\n",
       "        0.48087904, 0.47696158, 0.4786599 , 0.47709745, 0.47057587,\n",
       "        0.4591631 , 0.45628726, 0.45454365, 0.4505356 , 0.44145522,\n",
       "        0.437266  , 0.43912286, 0.44317618, 0.44539532, 0.44442162,\n",
       "        0.44337997, 0.4425195 , 0.4420213 , 0.4399607 , 0.43697163,\n",
       "        0.42999718, 0.4165917 , 0.4045449 , 0.40257484, 0.410523  ,\n",
       "        0.41620675, 0.41670492, 0.41602558, 0.41772392, 0.42207164,\n",
       "        0.4251739 , 0.4206224 , 0.41450843, 0.4060168 , 0.40110296,\n",
       "        0.39838564, 0.3940379 , 0.38964492, 0.38366678], dtype=float32),\n",
       " array([0.44473866, 0.4476824 , 0.4492675 , 0.45565322, 0.46299   ,\n",
       "        0.46953422, 0.47354227, 0.47254592, 0.47091553, 0.469421  ,\n",
       "        0.4688096 , 0.46708864, 0.46683955, 0.468402  , 0.4720251 ,\n",
       "        0.47974682, 0.48635897, 0.49027646, 0.49002737, 0.48620048,\n",
       "        0.48280382, 0.4806073 , 0.48042616, 0.48316613, 0.4790222 ,\n",
       "        0.47087023, 0.46169928, 0.47290823, 0.47048527, 0.45769122,\n",
       "        0.43780947, 0.44143257, 0.442678  , 0.44000596, 0.43192193,\n",
       "        0.4351148 , 0.44061738, 0.44548592, 0.44682193, 0.44641432,\n",
       "        0.44555384, 0.4445575 , 0.44371966, 0.44050413, 0.4401192 ,\n",
       "        0.43973425, 0.43654138, 0.42712134, 0.42019215, 0.41514248,\n",
       "        0.4112929 , 0.40468076, 0.40696785, 0.41588974, 0.4292046 ,\n",
       "        0.43377876, 0.4300651 , 0.4206224 , 0.4079642 , 0.40085387,\n",
       "        0.39630234, 0.39299628, 0.38964492, 0.38964492], dtype=float32),\n",
       " array([0.4403909 , 0.44181752, 0.44439897, 0.4486561 , 0.45356995,\n",
       "        0.45791766, 0.46040854, 0.4594575 , 0.4569666 , 0.4552456 ,\n",
       "        0.45658165, 0.45984244, 0.4634882 , 0.46797177, 0.47383666,\n",
       "        0.48112813, 0.4859061 , 0.48792145, 0.48694775, 0.48296234,\n",
       "        0.47958833, 0.47745976, 0.47721067, 0.47492358, 0.4650733 ,\n",
       "        0.45463422, 0.45060354, 0.46618286, 0.4618578 , 0.44720688,\n",
       "        0.431854  , 0.43366554, 0.43192193, 0.42988396, 0.4307897 ,\n",
       "        0.44014183, 0.44478393, 0.4459841 , 0.4450783 , 0.4456897 ,\n",
       "        0.44546327, 0.44514623, 0.4455312 , 0.44485188, 0.44448957,\n",
       "        0.44331205, 0.44014183, 0.43880582, 0.43842086, 0.43760568,\n",
       "        0.4350695 , 0.42503804, 0.4227736 , 0.42773274, 0.43953043,\n",
       "        0.4410476 , 0.4383982 , 0.4314917 , 0.42035067, 0.40896055,\n",
       "        0.40554124, 0.4049072 , 0.40189552, 0.401035  ], dtype=float32),\n",
       " array([0.44385552, 0.4449198 , 0.44347057, 0.44539532, 0.44849762,\n",
       "        0.45116964, 0.45180368, 0.4496298 , 0.4462558 , 0.445735  ,\n",
       "        0.45212072, 0.45705718, 0.4631485 , 0.4699871 , 0.47714272,\n",
       "        0.48248678, 0.48518148, 0.4852494 , 0.48282647, 0.47940716,\n",
       "        0.4783655 , 0.4776409 , 0.47517267, 0.46206158, 0.4479315 ,\n",
       "        0.4417043 , 0.45234716, 0.4615181 , 0.44842967, 0.43099353,\n",
       "        0.42703074, 0.42834413, 0.42825356, 0.43099353, 0.4407306 ,\n",
       "        0.4436517 , 0.44403666, 0.44376493, 0.44473866, 0.4460973 ,\n",
       "        0.4456218 , 0.44514623, 0.4465955 , 0.44999215, 0.44679928,\n",
       "        0.44018713, 0.4332806 , 0.42968014, 0.4297707 , 0.431854  ,\n",
       "        0.43411845, 0.42524186, 0.416954  , 0.41358   , 0.41942224,\n",
       "        0.43223897, 0.43968895, 0.43973425, 0.43031418, 0.41942224,\n",
       "        0.41416875, 0.41136086, 0.4077604 , 0.40119353], dtype=float32),\n",
       " array([0.44784093, 0.4476371 , 0.44091174, 0.44041356, 0.44294974,\n",
       "        0.44582558, 0.44627845, 0.4425195 , 0.44324413, 0.44673136,\n",
       "        0.45128286, 0.4593669 , 0.46663573, 0.47338375, 0.47990534,\n",
       "        0.48253208, 0.48212448, 0.47981477, 0.47668985, 0.4804035 ,\n",
       "        0.4816263 , 0.47956568, 0.47351962, 0.46346554, 0.45302647,\n",
       "        0.4492449 , 0.45923105, 0.4604991 , 0.4487014 , 0.43769625,\n",
       "        0.44138727, 0.44331205, 0.4476824 , 0.4512602 , 0.44994685,\n",
       "        0.43740186, 0.42761952, 0.41869763, 0.41638792, 0.41727102,\n",
       "        0.41964868, 0.4218452 , 0.4222528 , 0.42173198, 0.4155727 ,\n",
       "        0.4082586 , 0.40418258, 0.39134324, 0.3795455 , 0.37091804,\n",
       "        0.36765724, 0.36450967, 0.36598155, 0.37046513, 0.3764206 ,\n",
       "        0.40098974, 0.42195842, 0.43300885, 0.42791387, 0.41969398,\n",
       "        0.41208547, 0.4056092 , 0.40085387, 0.39548716], dtype=float32),\n",
       " array([0.4499695 , 0.4482938 , 0.4429724 , 0.43993804, 0.43957573,\n",
       "        0.44061738, 0.44177222, 0.44516888, 0.4479768 , 0.4525736 ,\n",
       "        0.46138224, 0.46760947, 0.4734517 , 0.47752768, 0.47838816,\n",
       "        0.47451597, 0.4732932 , 0.47399515, 0.47587463, 0.4830529 ,\n",
       "        0.48341522, 0.4776862 , 0.46663573, 0.45621935, 0.4472748 ,\n",
       "        0.44247422, 0.4445122 , 0.43984747, 0.4407306 , 0.4483391 ,\n",
       "        0.46391842, 0.44944867, 0.44000596, 0.43285036, 0.424087  ,\n",
       "        0.4043411 , 0.3882636 , 0.37950024, 0.38432348, 0.38767484,\n",
       "        0.39175084, 0.39458138, 0.39419642, 0.39002988, 0.3907545 ,\n",
       "        0.39127532, 0.3864747 , 0.36752138, 0.3493153 , 0.33473232,\n",
       "        0.32658035, 0.3389442 , 0.36084127, 0.38470843, 0.40298244,\n",
       "        0.41595766, 0.42361146, 0.42596647, 0.4231133 , 0.41545948,\n",
       "        0.4056092 , 0.3979101 , 0.39666465, 0.395306  ], dtype=float32),\n",
       " array([0.44901842, 0.44412723, 0.441659  , 0.44417253, 0.4462558 ,\n",
       "        0.44775033, 0.44845232, 0.45121494, 0.45465687, 0.46009153,\n",
       "        0.4687643 , 0.4744254 , 0.4798827 , 0.48307556, 0.48194334,\n",
       "        0.47164014, 0.47127783, 0.4763049 , 0.4820792 , 0.48336992,\n",
       "        0.4810149 , 0.47204775, 0.45352465, 0.43468454, 0.42895553,\n",
       "        0.43375614, 0.44643697, 0.44587088, 0.44566706, 0.44770506,\n",
       "        0.4539549 , 0.42780066, 0.41462165, 0.40726224, 0.39863473,\n",
       "        0.36992168, 0.34913415, 0.33692884, 0.3338945 , 0.33020344,\n",
       "        0.33717793, 0.34424296, 0.34082365, 0.31865484, 0.31405804,\n",
       "        0.32128158, 0.33459646, 0.33984995, 0.33996317, 0.3338492 ,\n",
       "        0.32044375, 0.33271697, 0.37540162, 0.41795036, 0.4298613 ,\n",
       "        0.4316955 , 0.42816296, 0.42263776, 0.4184259 , 0.40891525,\n",
       "        0.40468076, 0.40207666, 0.397344  , 0.39965373], dtype=float32),\n",
       " array([0.4370622 , 0.4381265 , 0.44188544, 0.44684458, 0.4519169 ,\n",
       "        0.45547208, 0.4559023 , 0.4547701 , 0.45474744, 0.4585517 ,\n",
       "        0.46896812, 0.47770885, 0.48343787, 0.48633635, 0.4865628 ,\n",
       "        0.48194334, 0.48151308, 0.48357373, 0.48642692, 0.48633635,\n",
       "        0.47582936, 0.4563552 , 0.42931783, 0.4344581 , 0.44806737,\n",
       "        0.4496298 , 0.41860706, 0.4161841 , 0.40126148, 0.3806551 ,\n",
       "        0.36127153, 0.3550217 , 0.35456878, 0.35989022, 0.37094066,\n",
       "        0.35359508, 0.33235466, 0.3105255 , 0.29141366, 0.33319253,\n",
       "        0.36188293, 0.36822334, 0.3428843 , 0.32141745, 0.31702444,\n",
       "        0.33437002, 0.37809628, 0.3828969 , 0.3699443 , 0.3617244 ,\n",
       "        0.38072303, 0.36767986, 0.38572744, 0.4133762 , 0.42906874,\n",
       "        0.42773274, 0.42816296, 0.427461  , 0.42272833, 0.42191312,\n",
       "        0.42671373, 0.42367938, 0.39942726, 0.3984309 ], dtype=float32),\n",
       " array([0.44408196, 0.44324413, 0.44718423, 0.45105642, 0.4549739 ,\n",
       "        0.4593669 , 0.46219745, 0.4591178 , 0.45572117, 0.4585517 ,\n",
       "        0.46496007, 0.47211567, 0.4770748 , 0.48303026, 0.485974  ,\n",
       "        0.4868798 , 0.48547584, 0.48017707, 0.4872874 , 0.48617783,\n",
       "        0.46996447, 0.44580293, 0.43491098, 0.45857435, 0.45943484,\n",
       "        0.4199657 , 0.35767108, 0.32494998, 0.317115  , 0.31453356,\n",
       "        0.32420272, 0.34041607, 0.34458262, 0.34619036, 0.331698  ,\n",
       "        0.31457886, 0.2959199 , 0.26439893, 0.311386  , 0.38233078,\n",
       "        0.39695904, 0.3497229 , 0.3098688 , 0.32637656, 0.36555132,\n",
       "        0.40207666, 0.4182221 , 0.40366176, 0.357739  , 0.3594147 ,\n",
       "        0.36618534, 0.36163384, 0.35536134, 0.38946375, 0.41068152,\n",
       "        0.41987514, 0.42223015, 0.42739305, 0.4205771 , 0.41068152,\n",
       "        0.40461284, 0.40305036, 0.40042362, 0.400718  ], dtype=float32),\n",
       " array([0.45640048, 0.45837054, 0.4589593 , 0.45483804, 0.45472482,\n",
       "        0.45336616, 0.45035446, 0.45006007, 0.45105642, 0.45551735,\n",
       "        0.45943484, 0.46271828, 0.46923983, 0.47822964, 0.47619167,\n",
       "        0.4744707 , 0.47530854, 0.47179866, 0.4865175 , 0.48382282,\n",
       "        0.46708864, 0.44392344, 0.42610234, 0.39931405, 0.35819188,\n",
       "        0.32544816, 0.31376365, 0.32569724, 0.31641304, 0.34003112,\n",
       "        0.37648854, 0.40232575, 0.39079976, 0.36471346, 0.32576516,\n",
       "        0.29512733, 0.27762324, 0.26186278, 0.3117483 , 0.37424675,\n",
       "        0.38002107, 0.33941972, 0.3425899 , 0.40689993, 0.4350242 ,\n",
       "        0.44349322, 0.43916813, 0.41917315, 0.36532485, 0.3730013 ,\n",
       "        0.3915244 , 0.39868   , 0.4006727 , 0.40945873, 0.41151938,\n",
       "        0.4128554 , 0.41478014, 0.41391966, 0.41308182, 0.41645584,\n",
       "        0.4143952 , 0.4072396 , 0.40529215, 0.40284657], dtype=float32),\n",
       " array([0.457895  , 0.46133697, 0.46052176, 0.45538148, 0.45010537,\n",
       "        0.44616523, 0.4450783 , 0.44845232, 0.44433105, 0.44439897,\n",
       "        0.44428575, 0.44611996, 0.4584385 , 0.46690747, 0.4595707 ,\n",
       "        0.46029532, 0.4716628 , 0.47519532, 0.48751384, 0.48486444,\n",
       "        0.4711646 , 0.4543172 , 0.4463011 , 0.37150678, 0.30823842,\n",
       "        0.28851518, 0.29999587, 0.28593373, 0.2724377 , 0.328958  ,\n",
       "        0.3924528 , 0.424087  , 0.40909642, 0.3933133 , 0.36047897,\n",
       "        0.34331456, 0.34689236, 0.34868127, 0.41068152, 0.42141494,\n",
       "        0.41896936, 0.42487955, 0.44419518, 0.45809883, 0.46124637,\n",
       "        0.46233332, 0.46158606, 0.44913164, 0.42168668, 0.41022864,\n",
       "        0.4043411 , 0.40207666, 0.40615264, 0.40762454, 0.4083265 ,\n",
       "        0.40984368, 0.41244778, 0.4151651 , 0.41568592, 0.41534626,\n",
       "        0.41575387, 0.41661435, 0.41575387, 0.4099569 ], dtype=float32),\n",
       " array([0.46203893, 0.46034062, 0.45569852, 0.4523698 , 0.4476824 ,\n",
       "        0.44555384, 0.4463011 , 0.44668606, 0.4417043 , 0.442678  ,\n",
       "        0.4401192 , 0.43599793, 0.44381022, 0.45388696, 0.45105642,\n",
       "        0.45304912, 0.46260506, 0.4674736 , 0.48275852, 0.4842304 ,\n",
       "        0.47422162, 0.4579856 , 0.44371966, 0.3565162 , 0.31177095,\n",
       "        0.29256853, 0.28486943, 0.27755532, 0.33215088, 0.397344  ,\n",
       "        0.43362027, 0.4353639 , 0.43090293, 0.43069914, 0.43031418,\n",
       "        0.43056327, 0.43559033, 0.4529359 , 0.45751005, 0.44396874,\n",
       "        0.43620172, 0.44193074, 0.4526189 , 0.4654809 , 0.47363284,\n",
       "        0.5092071 , 0.51434743, 0.50562936, 0.4381265 , 0.4139876 ,\n",
       "        0.3935171 , 0.383146  , 0.39578155, 0.40585828, 0.41278744,\n",
       "        0.41267422, 0.40997955, 0.41742954, 0.4314917 , 0.42515126,\n",
       "        0.41783714, 0.41731632, 0.41969398, 0.41706723], dtype=float32),\n",
       " array([0.4655488 , 0.45674017, 0.45166782, 0.45198485, 0.4502186 ,\n",
       "        0.45044503, 0.45230186, 0.45105642, 0.44861084, 0.44867876,\n",
       "        0.44147786, 0.42968014, 0.42841205, 0.444716  , 0.45026386,\n",
       "        0.44881463, 0.44707102, 0.4546116 , 0.4769842 , 0.4772333 ,\n",
       "        0.4608388 , 0.4320578 , 0.39392468, 0.3328755 , 0.31125012,\n",
       "        0.28849253, 0.2790725 , 0.35259873, 0.41774657, 0.44313088,\n",
       "        0.43722072, 0.42010158, 0.42345294, 0.438285  , 0.44086647,\n",
       "        0.44249687, 0.44906372, 0.46126902, 0.45026386, 0.44156843,\n",
       "        0.43597528, 0.43479776, 0.4399154 , 0.5097053 , 0.51892155,\n",
       "        0.5241298 , 0.52494496, 0.5117886 , 0.4499695 , 0.42804974,\n",
       "        0.4508979 , 0.4069452 , 0.40155584, 0.40624323, 0.41145143,\n",
       "        0.41410083, 0.41473487, 0.41767862, 0.43085766, 0.42544565,\n",
       "        0.41951284, 0.4185165 , 0.41534626, 0.416637  ], dtype=float32),\n",
       " array([0.4572157 , 0.456242  , 0.45723835, 0.45447573, 0.45424926,\n",
       "        0.4551324 , 0.45506448, 0.45144138, 0.44439897, 0.4410929 ,\n",
       "        0.43529594, 0.42700812, 0.42254716, 0.4334844 , 0.43851143,\n",
       "        0.4374698 , 0.43823972, 0.4568534 , 0.47949773, 0.46996447,\n",
       "        0.43851143, 0.39358503, 0.34193325, 0.29940712, 0.2691316 ,\n",
       "        0.26666337, 0.30801198, 0.40968516, 0.43151432, 0.42352086,\n",
       "        0.415618  , 0.41838062, 0.42295477, 0.43805856, 0.4371075 ,\n",
       "        0.43309945, 0.43217102, 0.43352968, 0.4327145 , 0.4333259 ,\n",
       "        0.43183136, 0.4291593 , 0.43074444, 0.4674736 , 0.5214351 ,\n",
       "        0.5272094 , 0.52630365, 0.52012175, 0.50307053, 0.4994248 ,\n",
       "        0.46389577, 0.47811642, 0.40701315, 0.39043745, 0.4023031 ,\n",
       "        0.41478014, 0.4179277 , 0.41962606, 0.42723456, 0.42689487,\n",
       "        0.4211885 , 0.41502923, 0.41564065, 0.41543683], dtype=float32),\n",
       " array([0.45157725, 0.45112434, 0.4573742 , 0.45270947, 0.45200747,\n",
       "        0.45284534, 0.45284534, 0.44953924, 0.44254214, 0.43599793,\n",
       "        0.43497893, 0.43660933, 0.42992923, 0.42755157, 0.4298613 ,\n",
       "        0.43855673, 0.4548154 , 0.4793166 , 0.48438892, 0.457895  ,\n",
       "        0.42732513, 0.4023031 , 0.3745864 , 0.3051135 , 0.26879194,\n",
       "        0.26904103, 0.30699298, 0.3814703 , 0.38991663, 0.4030051 ,\n",
       "        0.4241323 , 0.44249687, 0.4331221 , 0.42832148, 0.42356616,\n",
       "        0.42795917, 0.43823972, 0.43862468, 0.4344581 , 0.43325797,\n",
       "        0.42963487, 0.42585325, 0.43187666, 0.5004664 , 0.5185819 ,\n",
       "        0.5282284 , 0.5285228 , 0.53065133, 0.5186046 , 0.52039343,\n",
       "        0.51600045, 0.50057966, 0.42019215, 0.37051043, 0.3732051 ,\n",
       "        0.39199993, 0.39695904, 0.36450967, 0.3772358 , 0.402054  ,\n",
       "        0.41446313, 0.41237986, 0.41611618, 0.4178145 ], dtype=float32),\n",
       " array([0.45438513, 0.45193955, 0.45411342, 0.45255095, 0.45039973,\n",
       "        0.44908637, 0.44759184, 0.4423157 , 0.43620172, 0.42956692,\n",
       "        0.42929518, 0.43300885, 0.42918196, 0.43160492, 0.4408891 ,\n",
       "        0.457578  , 0.47920337, 0.50028527, 0.49113694, 0.45707983,\n",
       "        0.43167284, 0.42478895, 0.42254716, 0.36149797, 0.30740058,\n",
       "        0.28391838, 0.29671246, 0.33344162, 0.34322396, 0.40121618,\n",
       "        0.45162252, 0.53201   , 0.467383  , 0.4554947 , 0.4515546 ,\n",
       "        0.44116083, 0.42492482, 0.41982985, 0.4283894 , 0.43167284,\n",
       "        0.42870644, 0.42410964, 0.42809504, 0.445033  , 0.5014401 ,\n",
       "        0.52757174, 0.53096837, 0.5286134 , 0.52757174, 0.5248544 ,\n",
       "        0.52091426, 0.51405305, 0.4477277 , 0.39804596, 0.38772014,\n",
       "        0.388173  , 0.37195966, 0.2927044 , 0.32397625, 0.3623811 ,\n",
       "        0.38074568, 0.38400647, 0.40925494, 0.41385174], dtype=float32),\n",
       " array([0.45520034, 0.45433986, 0.4557438 , 0.45501918, 0.45540413,\n",
       "        0.45547208, 0.45341143, 0.44693515, 0.4340958 , 0.43561298,\n",
       "        0.43656403, 0.43314472, 0.4327145 , 0.4387379 , 0.4451236 ,\n",
       "        0.45662692, 0.47607845, 0.5043386 , 0.49342403, 0.4584385 ,\n",
       "        0.43194458, 0.4255815 , 0.43015566, 0.3991329 , 0.3633548 ,\n",
       "        0.34927002, 0.3590524 , 0.37069157, 0.39560038, 0.43651873,\n",
       "        0.5462986 , 0.55796045, 0.56024754, 0.5552205 , 0.5502387 ,\n",
       "        0.4787052 , 0.44276857, 0.42530978, 0.42784595, 0.42999718,\n",
       "        0.42723456, 0.42150554, 0.42125645, 0.4277554 , 0.48543057,\n",
       "        0.52942854, 0.537105  , 0.53069663, 0.52990407, 0.52723205,\n",
       "        0.525262  , 0.5205067 , 0.5033876 , 0.4467087 , 0.43298623,\n",
       "        0.42069033, 0.3918414 , 0.3068345 , 0.31555256, 0.31849632,\n",
       "        0.3246103 , 0.3452393 , 0.39421907, 0.39537394], dtype=float32),\n",
       " array([0.46337494, 0.4601368 , 0.4584385 , 0.4591178 , 0.46081614,\n",
       "        0.46346554, 0.4654356 , 0.4636014 , 0.45479274, 0.44661814,\n",
       "        0.43948516, 0.43586206, 0.4402777 , 0.4495166 , 0.4508979 ,\n",
       "        0.45710248, 0.474833  , 0.5047915 , 0.4939222 , 0.4585517 ,\n",
       "        0.430835  , 0.4228189 , 0.4266458 , 0.41810888, 0.41976193,\n",
       "        0.43269184, 0.4478862 , 0.53309697, 0.54663825, 0.5600664 ,\n",
       "        0.56330454, 0.5598852 , 0.5555375 , 0.5555149 , 0.5539977 ,\n",
       "        0.54401153, 0.5262357 , 0.4403683 , 0.42727983, 0.42598912,\n",
       "        0.4245625 , 0.41982985, 0.41742954, 0.4242455 , 0.44439897,\n",
       "        0.46362403, 0.52397126, 0.5279793 , 0.5322138 , 0.52999467,\n",
       "        0.52748114, 0.5238128 , 0.5109734 , 0.5029573 , 0.49138603,\n",
       "        0.4555853 , 0.42254716, 0.37936437, 0.36090922, 0.33249053,\n",
       "        0.310367  , 0.3143524 , 0.36783838, 0.36086392], dtype=float32),\n",
       " array([0.4752859 , 0.47392723, 0.46772268, 0.46699804, 0.46788117,\n",
       "        0.47059852, 0.47422162, 0.47659928, 0.47211567, 0.45664957,\n",
       "        0.44523683, 0.44464806, 0.4535473 , 0.46987388, 0.4747198 ,\n",
       "        0.52236354, 0.5322138 , 0.5277529 , 0.49659422, 0.46199363,\n",
       "        0.44686723, 0.43534124, 0.4277101 , 0.4364961 , 0.47265914,\n",
       "        0.5363351 , 0.555062  , 0.56350833, 0.5651387 , 0.5644594 ,\n",
       "        0.56097215, 0.55694145, 0.55728114, 0.55479026, 0.5491291 ,\n",
       "        0.54176974, 0.5332328 , 0.48314348, 0.43432224, 0.4194449 ,\n",
       "        0.41665962, 0.41550478, 0.41675022, 0.41566327, 0.41901466,\n",
       "        0.42528713, 0.43488833, 0.4548833 , 0.49215594, 0.53212327,\n",
       "        0.5339121 , 0.5300173 , 0.52028024, 0.51595515, 0.5173818 ,\n",
       "        0.51172066, 0.4972962 , 0.48654014, 0.4342996 , 0.40146527,\n",
       "        0.37811893, 0.37479022, 0.37173322, 0.32112306], dtype=float32),\n",
       " array([0.4644166 , 0.4643713 , 0.45470217, 0.466047  , 0.47012296,\n",
       "        0.47394988, 0.4790222 , 0.48117343, 0.48001856, 0.47383666,\n",
       "        0.47021356, 0.47073436, 0.4712099 , 0.4924956 , 0.5316477 ,\n",
       "        0.5418377 , 0.5449626 , 0.5369238 , 0.52222764, 0.5240392 ,\n",
       "        0.4878988 , 0.49075198, 0.49969652, 0.47555763, 0.50472355,\n",
       "        0.56224024, 0.5687392 , 0.5614024 , 0.5626478 , 0.5599758 ,\n",
       "        0.5581869 , 0.5575982 , 0.5539524 , 0.5511898 , 0.54702324,\n",
       "        0.5441474 , 0.54181504, 0.5124906 , 0.45504183, 0.43167284,\n",
       "        0.42694017, 0.4324654 , 0.44700307, 0.4205318 , 0.411225  ,\n",
       "        0.40504307, 0.40551862, 0.43375614, 0.47358757, 0.53262144,\n",
       "        0.53850895, 0.5365842 , 0.5303117 , 0.52295226, 0.5238354 ,\n",
       "        0.52537525, 0.5230655 , 0.51532114, 0.4945336 , 0.43681312,\n",
       "        0.40780568, 0.40280128, 0.39981222, 0.374994  ], dtype=float32),\n",
       " array([0.41428196, 0.39870265, 0.38298747, 0.39804596, 0.40508837,\n",
       "        0.416637  , 0.4304274 , 0.42934048, 0.43269184, 0.44442162,\n",
       "        0.45979714, 0.47295353, 0.49278998, 0.5243336 , 0.5428793 ,\n",
       "        0.5501934 , 0.5496273 , 0.5460722 , 0.53964114, 0.5431963 ,\n",
       "        0.5544506 , 0.5667918 , 0.5697129 , 0.55162   , 0.55834544,\n",
       "        0.5666559 , 0.5677428 , 0.56491226, 0.5647538 , 0.55995315,\n",
       "        0.56033814, 0.563146  , 0.5528881 , 0.547929  , 0.5405243 ,\n",
       "        0.5389165 , 0.535067  , 0.52324665, 0.47909015, 0.45608348,\n",
       "        0.43622437, 0.42617026, 0.4262382 , 0.42580795, 0.41142878,\n",
       "        0.4033221 , 0.40563184, 0.4063791 , 0.4539096 , 0.5250582 ,\n",
       "        0.5370371 , 0.54206413, 0.53737676, 0.53287053, 0.53316486,\n",
       "        0.535769  , 0.5361539 , 0.5277982 , 0.520869  , 0.4998324 ,\n",
       "        0.48096964, 0.43060857, 0.40952665, 0.39845356], dtype=float32),\n",
       " array([0.4409344 , 0.42100736, 0.402054  , 0.37587714, 0.36516637,\n",
       "        0.35975435, 0.35148916, 0.33536637, 0.32877687, 0.35035694,\n",
       "        0.39360768, 0.44136465, 0.47607845, 0.53545195, 0.549967  ,\n",
       "        0.5549261 , 0.5537033 , 0.55148417, 0.550352  , 0.55465436,\n",
       "        0.5615383 , 0.5686486 , 0.573653  , 0.5759174 , 0.57394737,\n",
       "        0.5718867 , 0.5695544 , 0.56642944, 0.56228554, 0.5635763 ,\n",
       "        0.5650708 , 0.55372596, 0.47628224, 0.4714137 , 0.5368333 ,\n",
       "        0.54224527, 0.53660685, 0.5297682 , 0.52634895, 0.5103847 ,\n",
       "        0.46224272, 0.44673136, 0.43457133, 0.42857057, 0.4208715 ,\n",
       "        0.40794155, 0.39396998, 0.39951786, 0.44070795, 0.51045257,\n",
       "        0.5277302 , 0.5383731 , 0.5412036 , 0.53855425, 0.53638035,\n",
       "        0.5389165 , 0.54489464, 0.5393015 , 0.5308778 , 0.52406186,\n",
       "        0.5192839 , 0.5171327 , 0.5045877 , 0.43092558], dtype=float32),\n",
       " array([0.46525443, 0.46955687, 0.47881842, 0.46106523, 0.42958957,\n",
       "        0.40984368, 0.40486193, 0.40135205, 0.3953966 , 0.40078592,\n",
       "        0.41838062, 0.44555384, 0.47542176, 0.54335487, 0.55356747,\n",
       "        0.5575076 , 0.5563301 , 0.55363536, 0.55626214, 0.56199116,\n",
       "        0.5676975 , 0.57224905, 0.5745135 , 0.5732907 , 0.571932  ,\n",
       "        0.57093567, 0.5713659 , 0.5712074 , 0.5680825 , 0.57550985,\n",
       "        0.5578925 , 0.42598912, 0.40420523, 0.41625205, 0.5389618 ,\n",
       "        0.544555  , 0.54034317, 0.53570104, 0.53558785, 0.5349538 ,\n",
       "        0.52197856, 0.4681529 , 0.44806737, 0.42958957, 0.43484306,\n",
       "        0.42431343, 0.4010803 , 0.39967635, 0.41482544, 0.42569473,\n",
       "        0.47193453, 0.5190348 , 0.53167033, 0.54269814, 0.5471817 ,\n",
       "        0.54863095, 0.5472044 , 0.54290193, 0.5369691 , 0.5314892 ,\n",
       "        0.5297003 , 0.5322591 , 0.53748995, 0.52714145], dtype=float32),\n",
       " array([0.44897315, 0.45008272, 0.45304912, 0.47286293, 0.47317997,\n",
       "        0.4645298 , 0.45112434, 0.43713015, 0.43255597, 0.45832527,\n",
       "        0.44827116, 0.45728362, 0.48099226, 0.5532731 , 0.5609495 ,\n",
       "        0.5593644 , 0.5591606 , 0.5595003 , 0.56169677, 0.5657728 ,\n",
       "        0.5668371 , 0.5749437 , 0.5779328 , 0.5784536 , 0.577729  ,\n",
       "        0.57614386, 0.57408327, 0.57618916, 0.5724302 , 0.5775705 ,\n",
       "        0.5681957 , 0.47961095, 0.42422286, 0.45112434, 0.543536  ,\n",
       "        0.5471591 , 0.54210943, 0.54396623, 0.5397091 , 0.54079604,\n",
       "        0.5424717 , 0.5388713 , 0.50028527, 0.46697542, 0.43787742,\n",
       "        0.42848   , 0.42012423, 0.4086888 , 0.39809126, 0.39664203,\n",
       "        0.41342148, 0.46926248, 0.5251714 , 0.52304286, 0.5251714 ,\n",
       "        0.52349573, 0.5462986 , 0.5492197 , 0.5428567 , 0.53744465,\n",
       "        0.5349991 , 0.5340933 , 0.53486323, 0.5420868 ], dtype=float32),\n",
       " array([0.4634882 , 0.4621748 , 0.46484685, 0.47415367, 0.4691719 ,\n",
       "        0.454521  , 0.44448957, 0.4487014 , 0.4579403 , 0.45703453,\n",
       "        0.45741948, 0.4793845 , 0.54790634, 0.56169677, 0.5637121 ,\n",
       "        0.5623761 , 0.56233084, 0.5629422 , 0.56554633, 0.56996197,\n",
       "        0.5712527 , 0.578748  , 0.5809218 , 0.57969904, 0.5780687 ,\n",
       "        0.57759315, 0.57623446, 0.57827246, 0.57347184, 0.57288307,\n",
       "        0.5674258 , 0.5197594 , 0.48368695, 0.48282647, 0.52553374,\n",
       "        0.54779315, 0.54706854, 0.54473615, 0.545257  , 0.550986  ,\n",
       "        0.55055577, 0.54770255, 0.5441474 , 0.51579666, 0.4747424 ,\n",
       "        0.44152313, 0.4182221 , 0.39779687, 0.38493487, 0.38624826,\n",
       "        0.40352592, 0.42098472, 0.45418134, 0.47603315, 0.479928  ,\n",
       "        0.4756935 , 0.52646214, 0.5442153 , 0.543151  , 0.54025257,\n",
       "        0.5405696 , 0.5418377 , 0.53914297, 0.5391656 ], dtype=float32),\n",
       " array([0.46996447, 0.47050792, 0.47560292, 0.4648242 , 0.46255976,\n",
       "        0.46101993, 0.46618286, 0.4832567 , 0.50209683, 0.49933422,\n",
       "        0.5560357 , 0.56244403, 0.5663389 , 0.56787866, 0.5680825 ,\n",
       "        0.5667465 , 0.567222  , 0.5687618 , 0.5701431 , 0.57089037,\n",
       "        0.5722717 , 0.5801066 , 0.58305043, 0.5820541 , 0.58042365,\n",
       "        0.5799481 , 0.57750255, 0.57677794, 0.57258874, 0.56708616,\n",
       "        0.5626478 , 0.5583907 , 0.54693264, 0.53964114, 0.54758936,\n",
       "        0.5507822 , 0.548948  , 0.5485857 , 0.54998964, 0.5555602 ,\n",
       "        0.55388445, 0.54867625, 0.54677415, 0.550352  , 0.5491291 ,\n",
       "        0.48250943, 0.45259625, 0.43214837, 0.4222528 , 0.413263  ,\n",
       "        0.40708107, 0.42238867, 0.44138727, 0.46172193, 0.47607845,\n",
       "        0.4806526 , 0.5121509 , 0.5202123 , 0.53515756, 0.5425623 ,\n",
       "        0.54249436, 0.5415886 , 0.5437398 , 0.54274344], dtype=float32),\n",
       " array([0.46081614, 0.46697542, 0.46781325, 0.4670207 , 0.47490093,\n",
       "        0.4874912 , 0.5483593 , 0.56559163, 0.577027  , 0.5752381 ,\n",
       "        0.575691  , 0.57580423, 0.57541925, 0.5749437 , 0.57460403,\n",
       "        0.57215846, 0.5717509 , 0.57224905, 0.57258874, 0.5732001 ,\n",
       "        0.57754785, 0.5843185 , 0.5843864 , 0.5824843 , 0.5810577 ,\n",
       "        0.58012927, 0.5772308 , 0.5750796 , 0.5705281 , 0.56647474,\n",
       "        0.56228554, 0.55626214, 0.49901718, 0.47954303, 0.53948265,\n",
       "        0.5530693 , 0.55211824, 0.5524352 , 0.5548808 , 0.5591153 ,\n",
       "        0.55825484, 0.5515068 , 0.548246  , 0.5545412 , 0.5597267 ,\n",
       "        0.5539071 , 0.5434001 , 0.53719556, 0.52105016, 0.46423545,\n",
       "        0.42857057, 0.43321267, 0.437266  , 0.4439461 , 0.4518716 ,\n",
       "        0.45744213, 0.45710248, 0.4605444 , 0.4790222 , 0.53176093,\n",
       "        0.543536  , 0.5470006 , 0.54591364, 0.5431737 ], dtype=float32),\n",
       " array([0.42080355, 0.4276648 , 0.4291593 , 0.45239243, 0.4857023 ,\n",
       "        0.5658407 , 0.5773214 , 0.5845676 , 0.58327687, 0.5798123 ,\n",
       "        0.5799028 , 0.5812615 , 0.58221257, 0.58160114, 0.57868004,\n",
       "        0.5768459 , 0.57627976, 0.575691  , 0.5756457 , 0.5776384 ,\n",
       "        0.58332217, 0.5867188 , 0.5852243 , 0.5841373 , 0.5832542 ,\n",
       "        0.5811709 , 0.5796764 , 0.57584953, 0.5708225 , 0.5621044 ,\n",
       "        0.5155249 , 0.47261384, 0.45470217, 0.45103377, 0.48121873,\n",
       "        0.55162   , 0.5571679 , 0.555379  , 0.5584586 , 0.5619232 ,\n",
       "        0.5613345 , 0.55356747, 0.54978585, 0.5566018 , 0.5571226 ,\n",
       "        0.5544279 , 0.54953676, 0.5448041 , 0.540864  , 0.53074193,\n",
       "        0.46208423, 0.44519153, 0.43289563, 0.42694017, 0.42467573,\n",
       "        0.42596647, 0.42857057, 0.44487453, 0.45809883, 0.4752859 ,\n",
       "        0.48719683, 0.48925745, 0.52727735, 0.5436492 ], dtype=float32),\n",
       " array([0.3961212 , 0.40932286, 0.43355232, 0.46337494, 0.5605646 ,\n",
       "        0.5801972 , 0.58393353, 0.58440906, 0.5862433 , 0.584477  ,\n",
       "        0.5859942 , 0.5866735 , 0.5859036 , 0.58436376, 0.5816691 ,\n",
       "        0.5797217 , 0.57847625, 0.5780234 , 0.5799028 , 0.5846355 ,\n",
       "        0.5893003 , 0.58848506, 0.5862659 , 0.5856092 , 0.58474874,\n",
       "        0.5823937 , 0.58259755, 0.5768459 , 0.5751475 , 0.5579831 ,\n",
       "        0.4754444 , 0.44548592, 0.4270987 , 0.4463464 , 0.48303026,\n",
       "        0.55329573, 0.5605193 , 0.55805105, 0.56337243, 0.56382537,\n",
       "        0.5632819 , 0.55678296, 0.55250317, 0.55714524, 0.56122124,\n",
       "        0.5566244 , 0.5502161 , 0.5467515 , 0.54489464, 0.5417924 ,\n",
       "        0.53753525, 0.52243143, 0.4523698 , 0.422049  , 0.4019408 ,\n",
       "        0.40977573, 0.41416875, 0.44412723, 0.4598198 , 0.510679  ,\n",
       "        0.4728403 , 0.47012296, 0.47777677, 0.49691126], dtype=float32),\n",
       " array([0.41987514, 0.4433347 , 0.47795793, 0.50961477, 0.57220376,\n",
       "        0.5866735 , 0.58660555, 0.58853036, 0.5889606 , 0.588553  ,\n",
       "        0.58941346, 0.5889153 , 0.587534  , 0.586198  , 0.5833448 ,\n",
       "        0.58051425, 0.58071804, 0.5826881 , 0.58606213, 0.58954936,\n",
       "        0.5893003 , 0.58737546, 0.5864697 , 0.5864244 , 0.5856545 ,\n",
       "        0.583843  , 0.58459026, 0.57969904, 0.5800387 , 0.5678108 ,\n",
       "        0.5455287 , 0.44806737, 0.43069914, 0.44852024, 0.47788998,\n",
       "        0.55682826, 0.56740314, 0.56097215, 0.5674711 , 0.5666559 ,\n",
       "        0.56291956, 0.5585266 , 0.55703205, 0.55979466, 0.5623535 ,\n",
       "        0.5590927 , 0.5544959 , 0.55189174, 0.5498538 , 0.54691   ,\n",
       "        0.5463666 , 0.54090923, 0.47123256, 0.43316737, 0.40948138,\n",
       "        0.39711756, 0.3984762 , 0.4542719 , 0.48246416, 0.53033435,\n",
       "        0.5339348 , 0.5293833 , 0.5019836 , 0.4931523 ], dtype=float32),\n",
       " array([0.46926248, 0.49247295, 0.57376623, 0.5883266 , 0.58839446,\n",
       "        0.58766985, 0.5881907 , 0.5893455 , 0.5884171 , 0.59194964,\n",
       "        0.58640176, 0.58055955, 0.5776837 , 0.58284664, 0.5849752 ,\n",
       "        0.58271074, 0.5844317 , 0.588236  , 0.58889264, 0.5882813 ,\n",
       "        0.5860848 , 0.58461285, 0.58420527, 0.58255225, 0.5838656 ,\n",
       "        0.58305043, 0.58454496, 0.58357126, 0.58110297, 0.577095  ,\n",
       "        0.5498085 , 0.46317115, 0.43817177, 0.43724337, 0.4668169 ,\n",
       "        0.5622176 , 0.57127535, 0.5663389 , 0.57025635, 0.568241  ,\n",
       "        0.56355363, 0.5606551 , 0.5607457 , 0.56334984, 0.56407446,\n",
       "        0.562829  , 0.55931914, 0.5564433 , 0.55524313, 0.55490345,\n",
       "        0.55198234, 0.5481781 , 0.54050165, 0.5283643 , 0.4859514 ,\n",
       "        0.4110212 , 0.40948138, 0.46740565, 0.5327573 , 0.5399808 ,\n",
       "        0.54464555, 0.54847246, 0.5361087 , 0.5088222 ], dtype=float32),\n",
       " array([0.5055161 , 0.55689615, 0.5893455 , 0.59407824, 0.59102124,\n",
       "        0.5893455 , 0.58970785, 0.5903193 , 0.5905004 , 0.5917685 ,\n",
       "        0.5852243 , 0.5473176 , 0.5473403 , 0.55422413, 0.5851563 ,\n",
       "        0.5866282 , 0.5886662 , 0.5907495 , 0.58889264, 0.58791894,\n",
       "        0.58674145, 0.5841373 , 0.5838656 , 0.5808765 , 0.5822805 ,\n",
       "        0.58142   , 0.58291453, 0.5846808 , 0.58230317, 0.57729876,\n",
       "        0.5373088 , 0.4645298 , 0.45576644, 0.46169928, 0.4794751 ,\n",
       "        0.57005256, 0.5762571 , 0.57233965, 0.573336  , 0.5696223 ,\n",
       "        0.5649349 , 0.56287426, 0.56305546, 0.5658633 , 0.56631625,\n",
       "        0.56534255, 0.5635763 , 0.5620591 , 0.56110805, 0.56015694,\n",
       "        0.5598852 , 0.55499405, 0.549967  , 0.54448706, 0.5229296 ,\n",
       "        0.45327556, 0.42694017, 0.4306765 , 0.4769842 , 0.54233587,\n",
       "        0.54779315, 0.54940087, 0.54808754, 0.5463439 ], dtype=float32),\n",
       " array([0.5118792 , 0.56393856, 0.59568596, 0.59441787, 0.5923572 ,\n",
       "        0.5921761 , 0.591293  , 0.59063625, 0.5937159 , 0.59149677,\n",
       "        0.5899343 , 0.58429587, 0.58042365, 0.58250695, 0.58660555,\n",
       "        0.5906589 , 0.5918817 , 0.590591  , 0.588236  , 0.5881227 ,\n",
       "        0.5881454 , 0.5863339 , 0.5853375 , 0.58076334, 0.57983494,\n",
       "        0.58026516, 0.58241636, 0.58445436, 0.5830957 , 0.57535136,\n",
       "        0.48875928, 0.47487828, 0.5027535 , 0.5151626 , 0.5099091 ,\n",
       "        0.57288307, 0.58212197, 0.5763024 , 0.57469463, 0.5701884 ,\n",
       "        0.5667691 , 0.5662936 , 0.5661577 , 0.56753904, 0.5690562 ,\n",
       "        0.5688071 , 0.5671767 , 0.5658181 , 0.56504816, 0.56350833,\n",
       "        0.56181   , 0.5604287 , 0.55796045, 0.55580926, 0.55227673,\n",
       "        0.5426302 , 0.44698045, 0.40982103, 0.4502865 , 0.48538527,\n",
       "        0.55085015, 0.5507369 , 0.5508275 , 0.5510766 ], dtype=float32)]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(real_img[0][:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.60583067, 0.5260038 , 0.5254352 , 0.52581936, 0.52461094,\n",
       "        0.52681446, 0.52753824, 0.5257369 , 0.5257905 , 0.5294059 ,\n",
       "        0.5310618 , 0.5272046 , 0.52880555, 0.529532  , 0.52752566,\n",
       "        0.5266587 , 0.52646095, 0.5261761 , 0.5289267 , 0.5248511 ,\n",
       "        0.5280221 , 0.527828  , 0.5307122 , 0.52752084, 0.5275937 ,\n",
       "        0.526298  , 0.53089595, 0.5263666 , 0.5290129 , 0.5276999 ,\n",
       "        0.53065884, 0.524562  , 0.52875054, 0.5279408 , 0.52553576,\n",
       "        0.52646583, 0.52612406, 0.52639866, 0.52589744, 0.5256294 ,\n",
       "        0.52622545, 0.5260795 , 0.5287689 , 0.5257502 , 0.5259412 ,\n",
       "        0.52692443, 0.5260022 , 0.52579075, 0.5261981 , 0.5259677 ,\n",
       "        0.52737284, 0.5258965 , 0.5264288 , 0.5251645 , 0.5281703 ,\n",
       "        0.5246728 , 0.5274922 , 0.5259515 , 0.5277095 , 0.5239311 ,\n",
       "        0.52596587, 0.52565426, 0.52816695, 0.5264233 ], dtype=float32),\n",
       " array([0.60209954, 0.5767369 , 0.57665586, 0.57688797, 0.5775436 ,\n",
       "        0.57643133, 0.5745925 , 0.5756515 , 0.5804485 , 0.5779313 ,\n",
       "        0.571759  , 0.57435226, 0.57582736, 0.58001596, 0.5788409 ,\n",
       "        0.5792201 , 0.57660836, 0.5782891 , 0.5763417 , 0.57652   ,\n",
       "        0.5782021 , 0.57738626, 0.57642555, 0.57384443, 0.5797329 ,\n",
       "        0.5796576 , 0.57168084, 0.5740181 , 0.57729185, 0.58081996,\n",
       "        0.5779684 , 0.57858056, 0.57896197, 0.5794377 , 0.5842303 ,\n",
       "        0.5799006 , 0.5779771 , 0.5769165 , 0.5812233 , 0.5774609 ,\n",
       "        0.5785752 , 0.57876444, 0.5726233 , 0.5750244 , 0.5761032 ,\n",
       "        0.5764841 , 0.5761642 , 0.5771603 , 0.577545  , 0.5774547 ,\n",
       "        0.5762483 , 0.57580626, 0.5764985 , 0.5784275 , 0.5785339 ,\n",
       "        0.5763851 , 0.57576466, 0.58110756, 0.5785511 , 0.57911605,\n",
       "        0.5788027 , 0.57646215, 0.57731783, 0.5741822 ], dtype=float32),\n",
       " array([0.60261095, 0.57787544, 0.57739586, 0.5770668 , 0.5759958 ,\n",
       "        0.5771945 , 0.5765136 , 0.5785831 , 0.57596374, 0.58236974,\n",
       "        0.5747739 , 0.5797809 , 0.5784865 , 0.5839999 , 0.5777586 ,\n",
       "        0.578538  , 0.5763111 , 0.5783593 , 0.5774905 , 0.5784398 ,\n",
       "        0.5770725 , 0.58430153, 0.5782477 , 0.5786315 , 0.5772884 ,\n",
       "        0.5865118 , 0.5750772 , 0.5785484 , 0.5761143 , 0.582909  ,\n",
       "        0.5772891 , 0.5793793 , 0.5778682 , 0.5773603 , 0.57736486,\n",
       "        0.5748033 , 0.57579577, 0.5769727 , 0.57706076, 0.5771767 ,\n",
       "        0.57636154, 0.5861372 , 0.5744635 , 0.57967526, 0.5765124 ,\n",
       "        0.581521  , 0.57762074, 0.57913655, 0.57697034, 0.5796207 ,\n",
       "        0.57696015, 0.5775175 , 0.57624024, 0.5781325 , 0.57715875,\n",
       "        0.5779024 , 0.5769485 , 0.58062994, 0.57605386, 0.5784013 ,\n",
       "        0.5763722 , 0.5783527 , 0.57711256, 0.5769954 ], dtype=float32),\n",
       " array([0.6022425 , 0.57692194, 0.5759545 , 0.5777235 , 0.57706535,\n",
       "        0.5768677 , 0.57544196, 0.57716316, 0.57674295, 0.5790585 ,\n",
       "        0.57321584, 0.5774506 , 0.57626957, 0.57785434, 0.57482505,\n",
       "        0.57934386, 0.57683414, 0.57711595, 0.57782733, 0.5753135 ,\n",
       "        0.5765263 , 0.5796047 , 0.574553  , 0.5763822 , 0.57653093,\n",
       "        0.580336  , 0.5764592 , 0.57397044, 0.57617056, 0.5789727 ,\n",
       "        0.5781698 , 0.57444286, 0.5760685 , 0.5786382 , 0.57653123,\n",
       "        0.57947874, 0.5764653 , 0.5783551 , 0.5765892 , 0.577051  ,\n",
       "        0.5765031 , 0.5800473 , 0.5762257 , 0.5741112 , 0.57670504,\n",
       "        0.5777631 , 0.57484543, 0.5772208 , 0.57678974, 0.5779183 ,\n",
       "        0.5764925 , 0.57633334, 0.5767027 , 0.5775966 , 0.5789597 ,\n",
       "        0.5745739 , 0.5764016 , 0.5775892 , 0.57978517, 0.5747335 ,\n",
       "        0.57679605, 0.5786058 , 0.5763538 , 0.57594913], dtype=float32),\n",
       " array([0.608276  , 0.5789003 , 0.58375704, 0.57792896, 0.57995695,\n",
       "        0.57709086, 0.5791641 , 0.5758839 , 0.57683486, 0.57787776,\n",
       "        0.5791263 , 0.5782666 , 0.57828385, 0.5767939 , 0.5797145 ,\n",
       "        0.57542145, 0.57786506, 0.58090407, 0.580754  , 0.58020437,\n",
       "        0.57906634, 0.5767277 , 0.5786892 , 0.5760356 , 0.58070344,\n",
       "        0.57648104, 0.578626  , 0.57693696, 0.577119  , 0.5778083 ,\n",
       "        0.5788711 , 0.57744735, 0.58099926, 0.5772625 , 0.57960063,\n",
       "        0.5771398 , 0.5785263 , 0.57880247, 0.5764216 , 0.57820463,\n",
       "        0.5775562 , 0.5783226 , 0.5836654 , 0.5783498 , 0.57854545,\n",
       "        0.5799048 , 0.58042544, 0.5798295 , 0.57983047, 0.577372  ,\n",
       "        0.57866454, 0.577396  , 0.5757083 , 0.57933176, 0.58018166,\n",
       "        0.5774663 , 0.5779749 , 0.57739633, 0.5772875 , 0.57637775,\n",
       "        0.5882189 , 0.5807932 , 0.5809267 , 0.5794209 ], dtype=float32),\n",
       " array([0.6040122 , 0.57913685, 0.58465326, 0.5765265 , 0.57617104,\n",
       "        0.57998127, 0.5796897 , 0.5789386 , 0.57823056, 0.5760172 ,\n",
       "        0.57728654, 0.5742706 , 0.57551676, 0.5801485 , 0.5768331 ,\n",
       "        0.57776326, 0.57890797, 0.5759546 , 0.5720978 , 0.5736559 ,\n",
       "        0.5759382 , 0.5784215 , 0.5780531 , 0.57789594, 0.5766547 ,\n",
       "        0.57704747, 0.5806298 , 0.57774043, 0.5775655 , 0.5770858 ,\n",
       "        0.579314  , 0.575742  , 0.5767273 , 0.5767693 , 0.57976246,\n",
       "        0.5775947 , 0.57622904, 0.57577986, 0.5776533 , 0.57772475,\n",
       "        0.5809862 , 0.57862   , 0.57992506, 0.5720962 , 0.57739204,\n",
       "        0.57492447, 0.57952994, 0.5738479 , 0.57815254, 0.577853  ,\n",
       "        0.58153653, 0.57746255, 0.577685  , 0.5759233 , 0.5733054 ,\n",
       "        0.5751052 , 0.5763911 , 0.5772379 , 0.58050567, 0.57799864,\n",
       "        0.5782857 , 0.580371  , 0.5871197 , 0.5814444 ], dtype=float32),\n",
       " array([0.6024203 , 0.5773959 , 0.58160144, 0.57523763, 0.5774161 ,\n",
       "        0.57831925, 0.578239  , 0.576647  , 0.5761998 , 0.57858837,\n",
       "        0.5767084 , 0.5777683 , 0.5765803 , 0.58032936, 0.5762084 ,\n",
       "        0.5788317 , 0.5775561 , 0.58406526, 0.57715374, 0.578945  ,\n",
       "        0.5767448 , 0.5801957 , 0.57823163, 0.5778052 , 0.5780222 ,\n",
       "        0.57551414, 0.5818393 , 0.57440174, 0.57600254, 0.5772695 ,\n",
       "        0.57658607, 0.5777272 , 0.5778397 , 0.5759927 , 0.58247685,\n",
       "        0.57495624, 0.5775609 , 0.5809443 , 0.5792254 , 0.57754433,\n",
       "        0.5743704 , 0.5815328 , 0.57362473, 0.57915807, 0.57693845,\n",
       "        0.57934487, 0.5799046 , 0.57772195, 0.5773942 , 0.5760651 ,\n",
       "        0.57911223, 0.5749316 , 0.57509434, 0.57828534, 0.576196  ,\n",
       "        0.5801407 , 0.5752181 , 0.58151615, 0.57695085, 0.57920486,\n",
       "        0.5815574 , 0.57948256, 0.58643687, 0.5708781 ], dtype=float32),\n",
       " array([0.6015009 , 0.57910293, 0.5785327 , 0.5757029 , 0.5765054 ,\n",
       "        0.5772877 , 0.5796681 , 0.57524776, 0.57683   , 0.5783145 ,\n",
       "        0.57544047, 0.5768146 , 0.5766357 , 0.5773342 , 0.5798413 ,\n",
       "        0.5738741 , 0.5768858 , 0.57868665, 0.5711614 , 0.579374  ,\n",
       "        0.576574  , 0.577809  , 0.57853204, 0.5746756 , 0.5767611 ,\n",
       "        0.5769241 , 0.57827735, 0.5764404 , 0.5767057 , 0.57789546,\n",
       "        0.5768573 , 0.5765311 , 0.5767899 , 0.57688653, 0.5774609 ,\n",
       "        0.5766852 , 0.57667303, 0.5776537 , 0.5738369 , 0.5789124 ,\n",
       "        0.57620686, 0.5814972 , 0.5774558 , 0.57349384, 0.57677394,\n",
       "        0.5781301 , 0.5731778 , 0.5790192 , 0.5765317 , 0.5779482 ,\n",
       "        0.577843  , 0.576891  , 0.57707334, 0.5771408 , 0.5743657 ,\n",
       "        0.577031  , 0.57624584, 0.5792061 , 0.57712024, 0.57501596,\n",
       "        0.57580775, 0.57860696, 0.5763102 , 0.5806412 ], dtype=float32),\n",
       " array([0.6024641 , 0.5779963 , 0.5804319 , 0.5762164 , 0.58149177,\n",
       "        0.57785404, 0.5758366 , 0.5763336 , 0.57829255, 0.57678753,\n",
       "        0.5790644 , 0.5758684 , 0.578742  , 0.57801217, 0.5773091 ,\n",
       "        0.57737815, 0.57851875, 0.57797843, 0.57766956, 0.5777042 ,\n",
       "        0.5784531 , 0.57761323, 0.57624936, 0.5768524 , 0.581941  ,\n",
       "        0.58016664, 0.5812376 , 0.5804803 , 0.57870436, 0.5804488 ,\n",
       "        0.5777677 , 0.5790381 , 0.5777186 , 0.5768858 , 0.5773628 ,\n",
       "        0.57693356, 0.5814328 , 0.5795277 , 0.57574576, 0.5785536 ,\n",
       "        0.5796314 , 0.5814212 , 0.57909006, 0.57843053, 0.5775467 ,\n",
       "        0.5783483 , 0.5787843 , 0.57867116, 0.5793311 , 0.5796505 ,\n",
       "        0.5798967 , 0.5784223 , 0.57931274, 0.5788036 , 0.5780417 ,\n",
       "        0.5777601 , 0.5793836 , 0.5797015 , 0.5774108 , 0.5779209 ,\n",
       "        0.5763415 , 0.57795656, 0.5791896 , 0.5773927 ], dtype=float32),\n",
       " array([0.6017604 , 0.57872885, 0.57495534, 0.57649755, 0.576342  ,\n",
       "        0.57727975, 0.5825427 , 0.58117586, 0.5759048 , 0.5792266 ,\n",
       "        0.5772202 , 0.5776178 , 0.57863903, 0.57859176, 0.5812559 ,\n",
       "        0.57834953, 0.5789653 , 0.5780224 , 0.57911587, 0.57737094,\n",
       "        0.5774836 , 0.5784407 , 0.58035934, 0.57921   , 0.57886875,\n",
       "        0.5767902 , 0.5744847 , 0.57494396, 0.57676774, 0.5767276 ,\n",
       "        0.5767152 , 0.577445  , 0.5768798 , 0.57698977, 0.57755476,\n",
       "        0.57708883, 0.57539207, 0.57405937, 0.580977  , 0.5795397 ,\n",
       "        0.5765851 , 0.57752657, 0.57639015, 0.578267  , 0.5797108 ,\n",
       "        0.5752508 , 0.57266206, 0.57438153, 0.5784773 , 0.57877403,\n",
       "        0.57841605, 0.57659495, 0.5773172 , 0.5782145 , 0.58102727,\n",
       "        0.578175  , 0.5765319 , 0.5784806 , 0.57887584, 0.57905895,\n",
       "        0.5776539 , 0.5762628 , 0.57622385, 0.5752348 ], dtype=float32),\n",
       " array([0.60124433, 0.5794974 , 0.57590556, 0.57961327, 0.5757163 ,\n",
       "        0.58753693, 0.5797401 , 0.5789338 , 0.5768296 , 0.5791361 ,\n",
       "        0.57694876, 0.57796764, 0.57714236, 0.5768888 , 0.5765995 ,\n",
       "        0.5756004 , 0.5770403 , 0.5790416 , 0.5763983 , 0.576252  ,\n",
       "        0.57747006, 0.5762632 , 0.5770624 , 0.57561576, 0.5797813 ,\n",
       "        0.58472335, 0.5812951 , 0.5757364 , 0.57831126, 0.5804764 ,\n",
       "        0.5786973 , 0.5774162 , 0.57718086, 0.57658595, 0.5779483 ,\n",
       "        0.57640123, 0.5773933 , 0.5846221 , 0.5835523 , 0.5777086 ,\n",
       "        0.5765898 , 0.5878767 , 0.57785016, 0.5809007 , 0.5757762 ,\n",
       "        0.5865736 , 0.57618713, 0.5794848 , 0.5769707 , 0.58372754,\n",
       "        0.57628345, 0.5783155 , 0.5775259 , 0.5780245 , 0.57812357,\n",
       "        0.57631075, 0.5780852 , 0.58074284, 0.5779312 , 0.5772634 ,\n",
       "        0.57582074, 0.57664895, 0.5767112 , 0.5781997 ], dtype=float32),\n",
       " array([0.6021683 , 0.577159  , 0.5777292 , 0.57504374, 0.57553774,\n",
       "        0.58143115, 0.57593435, 0.57480335, 0.57670844, 0.57718545,\n",
       "        0.57912683, 0.57475144, 0.57639503, 0.5782593 , 0.57731134,\n",
       "        0.5776767 , 0.5764376 , 0.578829  , 0.57640946, 0.57725495,\n",
       "        0.5765536 , 0.57727396, 0.5775419 , 0.5778911 , 0.57667226,\n",
       "        0.57899517, 0.5722804 , 0.5793237 , 0.57676864, 0.5770584 ,\n",
       "        0.5729122 , 0.58061403, 0.5769021 , 0.5768696 , 0.5771844 ,\n",
       "        0.5768641 , 0.576179  , 0.57914776, 0.57203925, 0.5791205 ,\n",
       "        0.5761478 , 0.5796255 , 0.57233644, 0.578214  , 0.5764966 ,\n",
       "        0.58097035, 0.5726764 , 0.57580566, 0.57622564, 0.5797531 ,\n",
       "        0.5752022 , 0.5771254 , 0.5764656 , 0.57774085, 0.5764524 ,\n",
       "        0.5782848 , 0.576465  , 0.5775264 , 0.5751357 , 0.57919633,\n",
       "        0.57699716, 0.5771977 , 0.57600224, 0.5767292 ], dtype=float32),\n",
       " array([0.608706  , 0.5808688 , 0.5790618 , 0.5799931 , 0.5772288 ,\n",
       "        0.57854325, 0.58125937, 0.5784561 , 0.57724136, 0.5784138 ,\n",
       "        0.57945776, 0.5762375 , 0.5794959 , 0.57915497, 0.58130604,\n",
       "        0.57667494, 0.57795596, 0.57910424, 0.5822947 , 0.5789058 ,\n",
       "        0.58090454, 0.5816649 , 0.5815868 , 0.5784736 , 0.57910377,\n",
       "        0.5770098 , 0.58110064, 0.5781737 , 0.57993245, 0.5801606 ,\n",
       "        0.5809754 , 0.57782775, 0.5777588 , 0.5786137 , 0.5788739 ,\n",
       "        0.57716787, 0.5794841 , 0.5776644 , 0.5804097 , 0.57816136,\n",
       "        0.58316594, 0.57760555, 0.57861936, 0.57759404, 0.57744163,\n",
       "        0.57738054, 0.5776929 , 0.57748747, 0.57998943, 0.5794856 ,\n",
       "        0.5797974 , 0.57938594, 0.57920873, 0.57757354, 0.58055335,\n",
       "        0.5783064 , 0.5790796 , 0.5776056 , 0.5791606 , 0.57750595,\n",
       "        0.5791128 , 0.5796069 , 0.5779332 , 0.57905966], dtype=float32),\n",
       " array([0.6026983 , 0.57722515, 0.57975066, 0.5785071 , 0.5793622 ,\n",
       "        0.5753207 , 0.5755979 , 0.57322955, 0.5763689 , 0.57689434,\n",
       "        0.5743288 , 0.57673323, 0.5756801 , 0.5798893 , 0.57634217,\n",
       "        0.5776789 , 0.5802477 , 0.578663  , 0.5696825 , 0.57308203,\n",
       "        0.5786983 , 0.57985663, 0.5798111 , 0.5783389 , 0.5786555 ,\n",
       "        0.5755017 , 0.5814583 , 0.5736784 , 0.5765345 , 0.57888937,\n",
       "        0.576109  , 0.57739717, 0.57587045, 0.5782687 , 0.57548016,\n",
       "        0.57704663, 0.5778129 , 0.57614994, 0.58246046, 0.57507116,\n",
       "        0.57742316, 0.5778385 , 0.582564  , 0.57934   , 0.5780907 ,\n",
       "        0.5773496 , 0.57609797, 0.57640994, 0.57878804, 0.57710713,\n",
       "        0.5778094 , 0.57571113, 0.57797265, 0.5758133 , 0.58081585,\n",
       "        0.57445693, 0.5767682 , 0.5769651 , 0.5794307 , 0.5764392 ,\n",
       "        0.5770625 , 0.57649267, 0.57621646, 0.5767925 ], dtype=float32),\n",
       " array([0.6055151 , 0.5828018 , 0.5831978 , 0.57478416, 0.5751242 ,\n",
       "        0.5804531 , 0.577185  , 0.57897073, 0.5739328 , 0.58768666,\n",
       "        0.5757843 , 0.5829916 , 0.5771061 , 0.5818909 , 0.5777082 ,\n",
       "        0.5793078 , 0.57705706, 0.5874511 , 0.5740203 , 0.579548  ,\n",
       "        0.57738125, 0.5807783 , 0.5779234 , 0.57758427, 0.57581896,\n",
       "        0.57698876, 0.57993084, 0.5763331 , 0.5774976 , 0.5831289 ,\n",
       "        0.57837135, 0.5789635 , 0.5770982 , 0.58140546, 0.5767198 ,\n",
       "        0.5790948 , 0.5766381 , 0.575513  , 0.580444  , 0.57572126,\n",
       "        0.5789392 , 0.57788134, 0.58319634, 0.5733814 , 0.5771499 ,\n",
       "        0.57878745, 0.57638377, 0.57683027, 0.5781732 , 0.5811998 ,\n",
       "        0.57893336, 0.5762238 , 0.57658553, 0.57683367, 0.580181  ,\n",
       "        0.57617164, 0.57715344, 0.5777158 , 0.5794758 , 0.57659745,\n",
       "        0.57846785, 0.58152497, 0.5791008 , 0.5770219 ], dtype=float32),\n",
       " array([0.6016857 , 0.57828385, 0.5726922 , 0.5810286 , 0.57675755,\n",
       "        0.579412  , 0.5743992 , 0.57576853, 0.5762728 , 0.5802821 ,\n",
       "        0.5751936 , 0.57330894, 0.5765962 , 0.5773344 , 0.5774072 ,\n",
       "        0.57583886, 0.5766503 , 0.58039826, 0.5741554 , 0.57539904,\n",
       "        0.57621   , 0.5786011 , 0.57502383, 0.5788961 , 0.576624  ,\n",
       "        0.57914364, 0.5769975 , 0.5751682 , 0.57653576, 0.5779212 ,\n",
       "        0.5752336 , 0.5773718 , 0.5767635 , 0.57724273, 0.57611585,\n",
       "        0.57686365, 0.57666606, 0.57802963, 0.57704157, 0.57667506,\n",
       "        0.57634723, 0.57803667, 0.5774039 , 0.57747406, 0.5768006 ,\n",
       "        0.57785046, 0.57630527, 0.57693017, 0.57656443, 0.57880294,\n",
       "        0.5740729 , 0.5786875 , 0.57671916, 0.57830274, 0.5765142 ,\n",
       "        0.5763796 , 0.576733  , 0.57748306, 0.5769304 , 0.57670087,\n",
       "        0.57675326, 0.577631  , 0.57323897, 0.5796694 ], dtype=float32),\n",
       " array([0.6046522 , 0.57682896, 0.5762761 , 0.57692784, 0.5762557 ,\n",
       "        0.5798815 , 0.58209926, 0.5784879 , 0.584914  , 0.57942337,\n",
       "        0.5793133 , 0.5777961 , 0.5806129 , 0.57773215, 0.58330107,\n",
       "        0.5765641 , 0.58008015, 0.5765688 , 0.5783033 , 0.5769045 ,\n",
       "        0.58086056, 0.576828  , 0.5753794 , 0.5766106 , 0.5779678 ,\n",
       "        0.57849944, 0.57613474, 0.57775414, 0.57655764, 0.5801675 ,\n",
       "        0.5783574 , 0.57809997, 0.579072  , 0.5788574 , 0.57785136,\n",
       "        0.57909685, 0.5788242 , 0.57919544, 0.58074105, 0.5766949 ,\n",
       "        0.5785348 , 0.5776912 , 0.5763931 , 0.57690495, 0.57889235,\n",
       "        0.57668465, 0.5788133 , 0.57568425, 0.5802161 , 0.57834744,\n",
       "        0.57819575, 0.57843626, 0.5789473 , 0.5793256 , 0.58040446,\n",
       "        0.57971936, 0.57827723, 0.5806081 , 0.57987994, 0.57860005,\n",
       "        0.57829535, 0.5778369 , 0.5773275 , 0.5783411 ], dtype=float32),\n",
       " array([0.6014499 , 0.5755294 , 0.57981074, 0.578307  , 0.5798061 ,\n",
       "        0.57626903, 0.5774569 , 0.5734388 , 0.57721364, 0.57670665,\n",
       "        0.5886971 , 0.58075476, 0.5759711 , 0.5796746 , 0.5810985 ,\n",
       "        0.57594067, 0.57667184, 0.57724816, 0.5796738 , 0.5777352 ,\n",
       "        0.5761651 , 0.5757949 , 0.5830338 , 0.5802134 , 0.5764246 ,\n",
       "        0.5756141 , 0.57782227, 0.5778726 , 0.5768409 , 0.5737096 ,\n",
       "        0.57450235, 0.5760869 , 0.5800381 , 0.5748212 , 0.5800108 ,\n",
       "        0.5756054 , 0.5771868 , 0.57756144, 0.578933  , 0.5774582 ,\n",
       "        0.57765466, 0.5784963 , 0.5809924 , 0.57917416, 0.5755371 ,\n",
       "        0.57889265, 0.5780353 , 0.5781313 , 0.5786461 , 0.576908  ,\n",
       "        0.577541  , 0.5770737 , 0.5790753 , 0.5763835 , 0.5746315 ,\n",
       "        0.5739684 , 0.57804316, 0.577209  , 0.57650095, 0.57642907,\n",
       "        0.5793258 , 0.57565266, 0.5750581 , 0.5758463 ], dtype=float32),\n",
       " array([0.60215497, 0.57932276, 0.5806531 , 0.5766732 , 0.5744828 ,\n",
       "        0.5771014 , 0.57557213, 0.5793057 , 0.57707083, 0.5793379 ,\n",
       "        0.5856017 , 0.5748309 , 0.57634413, 0.58021426, 0.57925355,\n",
       "        0.5783777 , 0.5780442 , 0.5755937 , 0.5809209 , 0.5746833 ,\n",
       "        0.576787  , 0.57970315, 0.5818768 , 0.57594633, 0.5767603 ,\n",
       "        0.5808467 , 0.5785478 , 0.57808757, 0.5746258 , 0.58280003,\n",
       "        0.57824713, 0.58141786, 0.57500684, 0.5869371 , 0.577424  ,\n",
       "        0.5789546 , 0.5749811 , 0.58005327, 0.5781521 , 0.57960725,\n",
       "        0.5773583 , 0.57606834, 0.57702863, 0.5755519 , 0.5765544 ,\n",
       "        0.5804482 , 0.5777819 , 0.5783062 , 0.57775223, 0.58273554,\n",
       "        0.5790147 , 0.5763477 , 0.57789195, 0.5829113 , 0.5780652 ,\n",
       "        0.57724977, 0.5764919 , 0.5820048 , 0.5770242 , 0.5791559 ,\n",
       "        0.5761793 , 0.58624583, 0.5766958 , 0.57852286], dtype=float32),\n",
       " array([0.60188615, 0.57803583, 0.57618904, 0.57653236, 0.5767693 ,\n",
       "        0.57866335, 0.5747186 , 0.57691133, 0.57569724, 0.5797687 ,\n",
       "        0.57614946, 0.57755536, 0.5764044 , 0.57835144, 0.579765  ,\n",
       "        0.5735116 , 0.57682157, 0.5767271 , 0.57813275, 0.57666135,\n",
       "        0.57618845, 0.5787892 , 0.57660514, 0.57648015, 0.57661086,\n",
       "        0.57798976, 0.5741429 , 0.57819885, 0.57672864, 0.5785434 ,\n",
       "        0.5715123 , 0.57778215, 0.5758462 , 0.5827633 , 0.57260704,\n",
       "        0.5761344 , 0.57640433, 0.57856274, 0.57639843, 0.5755264 ,\n",
       "        0.57650596, 0.5774252 , 0.5776228 , 0.5778802 , 0.5765518 ,\n",
       "        0.5777105 , 0.5790253 , 0.5742656 , 0.57639134, 0.5795047 ,\n",
       "        0.57464087, 0.5773773 , 0.57675105, 0.57907665, 0.57318014,\n",
       "        0.5781325 , 0.5765398 , 0.57857907, 0.5734774 , 0.5784279 ,\n",
       "        0.5763064 , 0.5810797 , 0.57346874, 0.57593817], dtype=float32),\n",
       " array([0.60434663, 0.57838565, 0.5745606 , 0.5771306 , 0.5800859 ,\n",
       "        0.5781514 , 0.5815626 , 0.5781948 , 0.5801303 , 0.5801022 ,\n",
       "        0.5808906 , 0.5803858 , 0.5788177 , 0.578036  , 0.57866895,\n",
       "        0.57714075, 0.57759655, 0.5775421 , 0.57910705, 0.577316  ,\n",
       "        0.5789688 , 0.57809913, 0.5769482 , 0.5772677 , 0.5815411 ,\n",
       "        0.57901406, 0.57901305, 0.57719475, 0.578207  , 0.57914895,\n",
       "        0.58170253, 0.5795222 , 0.5781439 , 0.5768495 , 0.5785461 ,\n",
       "        0.57712966, 0.57834476, 0.57987607, 0.5774591 , 0.579092  ,\n",
       "        0.57841986, 0.57857424, 0.5774129 , 0.5773439 , 0.57775396,\n",
       "        0.57735246, 0.57436776, 0.57710564, 0.581124  , 0.57703733,\n",
       "        0.58324635, 0.57601696, 0.58106667, 0.5781564 , 0.58177835,\n",
       "        0.578291  , 0.58311933, 0.5775342 , 0.5797734 , 0.5770904 ,\n",
       "        0.579534  , 0.5782436 , 0.5768019 , 0.57706666], dtype=float32),\n",
       " array([0.60197204, 0.57594085, 0.5814928 , 0.5802297 , 0.5802535 ,\n",
       "        0.57881194, 0.58128893, 0.57529   , 0.5818538 , 0.57841015,\n",
       "        0.5727239 , 0.57440543, 0.577455  , 0.57753074, 0.5785594 ,\n",
       "        0.57768   , 0.5782772 , 0.5782994 , 0.5760274 , 0.57591164,\n",
       "        0.5777527 , 0.57771987, 0.5783334 , 0.5783997 , 0.5782763 ,\n",
       "        0.57888985, 0.58171076, 0.5798328 , 0.5809453 , 0.5776273 ,\n",
       "        0.5750884 , 0.57289785, 0.5772014 , 0.57671016, 0.5790252 ,\n",
       "        0.5762471 , 0.5762837 , 0.57613087, 0.5757863 , 0.5767731 ,\n",
       "        0.5760644 , 0.5763918 , 0.58027405, 0.5776936 , 0.5757752 ,\n",
       "        0.57412577, 0.5788411 , 0.5784144 , 0.57682157, 0.5813669 ,\n",
       "        0.57637906, 0.57659465, 0.5789188 , 0.57676446, 0.5761892 ,\n",
       "        0.5753702 , 0.5771089 , 0.57934684, 0.5820863 , 0.57932645,\n",
       "        0.57843256, 0.5797638 , 0.5811099 , 0.5798759 ], dtype=float32),\n",
       " array([0.60151595, 0.5813685 , 0.57888955, 0.577742  , 0.57655877,\n",
       "        0.5794514 , 0.57714665, 0.5760617 , 0.57868254, 0.5869411 ,\n",
       "        0.5758412 , 0.5765885 , 0.5771686 , 0.57607585, 0.578735  ,\n",
       "        0.57619834, 0.57669395, 0.58040637, 0.57548785, 0.5777612 ,\n",
       "        0.57659394, 0.58345026, 0.5768734 , 0.57803696, 0.5773042 ,\n",
       "        0.5791595 , 0.5796931 , 0.57581705, 0.5766232 , 0.5840354 ,\n",
       "        0.57500917, 0.5780891 , 0.5768053 , 0.5759074 , 0.5786745 ,\n",
       "        0.57623833, 0.5784577 , 0.5809708 , 0.5789319 , 0.57753307,\n",
       "        0.57557327, 0.5833755 , 0.57799   , 0.5796982 , 0.57566494,\n",
       "        0.5827578 , 0.5791701 , 0.578945  , 0.5772758 , 0.5836336 ,\n",
       "        0.57778805, 0.578204  , 0.5776713 , 0.580019  , 0.58114   ,\n",
       "        0.57585084, 0.57906944, 0.57740945, 0.58230275, 0.57363415,\n",
       "        0.57779175, 0.5777976 , 0.5764986 , 0.5752875 ], dtype=float32),\n",
       " array([0.60146356, 0.57908386, 0.5747023 , 0.57788193, 0.5762242 ,\n",
       "        0.580172  , 0.5775711 , 0.5755108 , 0.57637906, 0.58105814,\n",
       "        0.5725095 , 0.5782319 , 0.57677823, 0.5769542 , 0.57691056,\n",
       "        0.57742935, 0.5766601 , 0.57853144, 0.57693374, 0.57578   ,\n",
       "        0.5762059 , 0.57966274, 0.57566494, 0.576399  , 0.5761399 ,\n",
       "        0.57875043, 0.5768982 , 0.57729167, 0.5764762 , 0.58076096,\n",
       "        0.5742415 , 0.576345  , 0.57685333, 0.5772251 , 0.5775138 ,\n",
       "        0.57635236, 0.5768918 , 0.5769173 , 0.57280463, 0.58032495,\n",
       "        0.5762212 , 0.579384  , 0.5751412 , 0.57632047, 0.5764062 ,\n",
       "        0.5790429 , 0.57407045, 0.576776  , 0.576399  , 0.5788722 ,\n",
       "        0.5802753 , 0.5723605 , 0.5767261 , 0.5786087 , 0.5756558 ,\n",
       "        0.5762298 , 0.57639974, 0.5775363 , 0.5788075 , 0.5767844 ,\n",
       "        0.57627535, 0.5781631 , 0.5776424 , 0.57796824], dtype=float32),\n",
       " array([0.6056987 , 0.5789751 , 0.57914567, 0.57914495, 0.58023524,\n",
       "        0.5786515 , 0.5824325 , 0.57882816, 0.57936144, 0.5799369 ,\n",
       "        0.5800053 , 0.57805985, 0.57812864, 0.5801377 , 0.5798994 ,\n",
       "        0.5782208 , 0.5767811 , 0.5767766 , 0.57602733, 0.5770743 ,\n",
       "        0.57705534, 0.57746345, 0.57753146, 0.57748175, 0.57785416,\n",
       "        0.5792391 , 0.58208466, 0.57763416, 0.57715684, 0.5789611 ,\n",
       "        0.57867956, 0.5773026 , 0.5796977 , 0.5776058 , 0.5785153 ,\n",
       "        0.5777709 , 0.57809395, 0.579048  , 0.57844216, 0.5781453 ,\n",
       "        0.57966715, 0.5773244 , 0.57810324, 0.57740307, 0.5786059 ,\n",
       "        0.57911384, 0.5793262 , 0.5783688 , 0.577057  , 0.57779825,\n",
       "        0.57779956, 0.57673246, 0.5778632 , 0.5776399 , 0.5826256 ,\n",
       "        0.5766892 , 0.57783085, 0.58047694, 0.57912904, 0.5796868 ,\n",
       "        0.57838356, 0.5792342 , 0.5821142 , 0.57819647], dtype=float32),\n",
       " array([0.603211  , 0.57629085, 0.57597387, 0.576051  , 0.5798125 ,\n",
       "        0.5771212 , 0.5739431 , 0.5742195 , 0.57891613, 0.5760782 ,\n",
       "        0.57708234, 0.57703066, 0.5758223 , 0.57784975, 0.57491314,\n",
       "        0.5763486 , 0.57676566, 0.573758  , 0.5805644 , 0.576323  ,\n",
       "        0.57720006, 0.57664275, 0.5768297 , 0.5762517 , 0.5796185 ,\n",
       "        0.57928663, 0.5778282 , 0.57515436, 0.57793987, 0.57746273,\n",
       "        0.5768587 , 0.5772033 , 0.5770802 , 0.57700014, 0.5778687 ,\n",
       "        0.57699007, 0.5764946 , 0.57745415, 0.57519567, 0.5765974 ,\n",
       "        0.5765848 , 0.5769918 , 0.57877266, 0.5775114 , 0.5781555 ,\n",
       "        0.5782817 , 0.5759134 , 0.5762243 , 0.57685006, 0.5765231 ,\n",
       "        0.5778714 , 0.5770724 , 0.57814264, 0.5806758 , 0.5728492 ,\n",
       "        0.5745391 , 0.5769366 , 0.57536614, 0.5764858 , 0.5749688 ,\n",
       "        0.5787746 , 0.5765462 , 0.57379395, 0.57457423], dtype=float32),\n",
       " array([0.6038127 , 0.58284634, 0.5803058 , 0.57647014, 0.57773745,\n",
       "        0.5811139 , 0.57938194, 0.5763693 , 0.57564175, 0.581748  ,\n",
       "        0.5789291 , 0.5786706 , 0.5773798 , 0.58304936, 0.57733333,\n",
       "        0.5797879 , 0.57426816, 0.5806086 , 0.5782189 , 0.5792403 ,\n",
       "        0.57692367, 0.57778233, 0.5770565 , 0.577183  , 0.57533264,\n",
       "        0.58073115, 0.57435864, 0.5791076 , 0.5763081 , 0.57674587,\n",
       "        0.5764692 , 0.57779455, 0.5782038 , 0.5780114 , 0.5800946 ,\n",
       "        0.5755435 , 0.5777836 , 0.58175457, 0.5774066 , 0.57826465,\n",
       "        0.57813215, 0.5768264 , 0.5804454 , 0.57534516, 0.5775621 ,\n",
       "        0.58249867, 0.5763931 , 0.5778436 , 0.5753295 , 0.57974046,\n",
       "        0.5768432 , 0.57912725, 0.576013  , 0.5859872 , 0.5733496 ,\n",
       "        0.5805354 , 0.5774728 , 0.5807402 , 0.5787274 , 0.5783922 ,\n",
       "        0.5765259 , 0.5786335 , 0.5785676 , 0.5779442 ], dtype=float32),\n",
       " array([0.6019824 , 0.57863265, 0.57356465, 0.57833517, 0.57680917,\n",
       "        0.57887816, 0.5749173 , 0.57649   , 0.57639563, 0.5794541 ,\n",
       "        0.57358414, 0.57716817, 0.5767648 , 0.57736313, 0.5742421 ,\n",
       "        0.5781307 , 0.576415  , 0.5796224 , 0.57519406, 0.5753114 ,\n",
       "        0.5768986 , 0.57726806, 0.57613176, 0.5772478 , 0.5763708 ,\n",
       "        0.5796413 , 0.57687086, 0.57531637, 0.57681584, 0.5770997 ,\n",
       "        0.5758031 , 0.5778597 , 0.57681894, 0.57719415, 0.57633954,\n",
       "        0.57754534, 0.5767993 , 0.57743114, 0.5746523 , 0.5781735 ,\n",
       "        0.57683814, 0.5767715 , 0.57691187, 0.5774976 , 0.5765678 ,\n",
       "        0.578674  , 0.5750381 , 0.57754534, 0.576596  , 0.5782666 ,\n",
       "        0.5761691 , 0.5759021 , 0.57648224, 0.57983774, 0.5782688 ,\n",
       "        0.5725676 , 0.57688576, 0.5774911 , 0.5721815 , 0.580058  ,\n",
       "        0.57700664, 0.57763624, 0.5747533 , 0.57692796], dtype=float32),\n",
       " array([0.6037972 , 0.58153814, 0.57981247, 0.578785  , 0.5777283 ,\n",
       "        0.57766837, 0.57827485, 0.5778915 , 0.578852  , 0.57899445,\n",
       "        0.57939017, 0.5759613 , 0.5765903 , 0.57952195, 0.5814873 ,\n",
       "        0.5780171 , 0.57792884, 0.58295524, 0.5820962 , 0.5805879 ,\n",
       "        0.57977676, 0.57933474, 0.581168  , 0.5776319 , 0.57882506,\n",
       "        0.5790238 , 0.57760215, 0.577246  , 0.58273906, 0.5796807 ,\n",
       "        0.5845528 , 0.5773436 , 0.5780125 , 0.57798594, 0.5786535 ,\n",
       "        0.5788065 , 0.5794108 , 0.5769452 , 0.5796292 , 0.57573473,\n",
       "        0.5805612 , 0.5783444 , 0.580632  , 0.57821417, 0.57597125,\n",
       "        0.5800235 , 0.5825288 , 0.5778441 , 0.5746155 , 0.5812212 ,\n",
       "        0.58307874, 0.57810885, 0.57984275, 0.5765047 , 0.58134913,\n",
       "        0.5771726 , 0.5769612 , 0.5775236 , 0.57751685, 0.5771415 ,\n",
       "        0.58045924, 0.57922274, 0.57991624, 0.57865375], dtype=float32),\n",
       " array([0.60238266, 0.5776003 , 0.57559204, 0.5772106 , 0.5788894 ,\n",
       "        0.5775716 , 0.57532996, 0.57592434, 0.5771075 , 0.5811948 ,\n",
       "        0.5794325 , 0.5797257 , 0.57860607, 0.5762621 , 0.57263404,\n",
       "        0.57433295, 0.57774055, 0.5738692 , 0.57341623, 0.57358795,\n",
       "        0.57495093, 0.5755774 , 0.5825805 , 0.5755792 , 0.574579  ,\n",
       "        0.5759649 , 0.5785533 , 0.5778812 , 0.57525647, 0.57974243,\n",
       "        0.5801983 , 0.57683635, 0.580229  , 0.57511985, 0.5766085 ,\n",
       "        0.57423735, 0.57538474, 0.5795449 , 0.5779209 , 0.57812583,\n",
       "        0.5794533 , 0.5780402 , 0.5777815 , 0.57632893, 0.5784214 ,\n",
       "        0.5744656 , 0.57405186, 0.5729221 , 0.5786523 , 0.575484  ,\n",
       "        0.5701199 , 0.57328016, 0.57742614, 0.5766822 , 0.5828821 ,\n",
       "        0.57498354, 0.57738906, 0.57644945, 0.5782547 , 0.5766509 ,\n",
       "        0.5764484 , 0.57483125, 0.5804528 , 0.5760978 ], dtype=float32),\n",
       " array([0.60275376, 0.5812412 , 0.5776718 , 0.5790403 , 0.5772817 ,\n",
       "        0.58014536, 0.57599354, 0.5768336 , 0.57647216, 0.57922775,\n",
       "        0.57521373, 0.5783512 , 0.5757235 , 0.57846296, 0.576714  ,\n",
       "        0.5792834 , 0.5760958 , 0.58379346, 0.57959765, 0.58109605,\n",
       "        0.5736497 , 0.588994  , 0.5798383 , 0.5830424 , 0.575319  ,\n",
       "        0.5881252 , 0.57874304, 0.58182806, 0.57733965, 0.58308667,\n",
       "        0.58180034, 0.5787854 , 0.5752218 , 0.5860538 , 0.5763463 ,\n",
       "        0.57894135, 0.5769424 , 0.580546  , 0.57803446, 0.5781834 ,\n",
       "        0.5778346 , 0.57913625, 0.5791041 , 0.5753548 , 0.5719556 ,\n",
       "        0.5873616 , 0.57554954, 0.5846368 , 0.57416606, 0.5777047 ,\n",
       "        0.57539964, 0.5818541 , 0.5760909 , 0.575286  , 0.5807621 ,\n",
       "        0.5759162 , 0.57604927, 0.5773142 , 0.57697433, 0.5776026 ,\n",
       "        0.57666725, 0.58103305, 0.5823839 , 0.57779294], dtype=float32),\n",
       " array([0.60204935, 0.5772191 , 0.57289463, 0.5800171 , 0.5767331 ,\n",
       "        0.57848984, 0.5758338 , 0.5768837 , 0.5762925 , 0.577767  ,\n",
       "        0.57871896, 0.57615805, 0.5771028 , 0.5773784 , 0.5742452 ,\n",
       "        0.5771236 , 0.5768863 , 0.5783397 , 0.56890213, 0.5803562 ,\n",
       "        0.57578874, 0.5816353 , 0.57473236, 0.57350105, 0.57611   ,\n",
       "        0.57993877, 0.57401013, 0.5756187 , 0.5763197 , 0.5782345 ,\n",
       "        0.5777798 , 0.57497454, 0.57620317, 0.5820202 , 0.57338667,\n",
       "        0.57529074, 0.57656413, 0.5774874 , 0.5793268 , 0.5743022 ,\n",
       "        0.5765696 , 0.5786902 , 0.57628083, 0.5769379 , 0.5763528 ,\n",
       "        0.58150214, 0.57255214, 0.57350725, 0.57733977, 0.5767359 ,\n",
       "        0.5726357 , 0.5776407 , 0.57662976, 0.5781825 , 0.5789933 ,\n",
       "        0.5745331 , 0.5767577 , 0.5776706 , 0.57636493, 0.57679075,\n",
       "        0.5765106 , 0.5786153 , 0.5739576 , 0.5775455 ], dtype=float32),\n",
       " array([0.6052139 , 0.57648146, 0.57660216, 0.57484883, 0.57961017,\n",
       "        0.57759666, 0.57317775, 0.5766187 , 0.5762869 , 0.5791402 ,\n",
       "        0.57986116, 0.5780273 , 0.57702494, 0.5788941 , 0.5819275 ,\n",
       "        0.5773164 , 0.57738376, 0.5773982 , 0.5778572 , 0.5764232 ,\n",
       "        0.5769144 , 0.57698685, 0.57722676, 0.57707274, 0.580371  ,\n",
       "        0.58116305, 0.5772343 , 0.57802945, 0.5780061 , 0.57823884,\n",
       "        0.5801409 , 0.57905054, 0.57549864, 0.5790632 , 0.5806561 ,\n",
       "        0.5777066 , 0.57701427, 0.5769131 , 0.57696307, 0.5769228 ,\n",
       "        0.5777551 , 0.57856756, 0.57789963, 0.5775957 , 0.58015585,\n",
       "        0.5764384 , 0.57621086, 0.5766882 , 0.5757279 , 0.5798926 ,\n",
       "        0.5816472 , 0.5766476 , 0.5768271 , 0.5774376 , 0.5782907 ,\n",
       "        0.5776977 , 0.5790182 , 0.5783126 , 0.5771466 , 0.57804793,\n",
       "        0.5778843 , 0.5771627 , 0.5798241 , 0.5767956 ], dtype=float32),\n",
       " array([0.5993461 , 0.57717794, 0.58063   , 0.58030003, 0.57672143,\n",
       "        0.57527834, 0.5855341 , 0.5812968 , 0.57726634, 0.5740188 ,\n",
       "        0.5781601 , 0.57415694, 0.5776844 , 0.5767938 , 0.575396  ,\n",
       "        0.5746895 , 0.5766682 , 0.57826626, 0.57724667, 0.5776448 ,\n",
       "        0.57719404, 0.5768828 , 0.57675433, 0.57656455, 0.57875234,\n",
       "        0.57755065, 0.5810394 , 0.58052874, 0.580939  , 0.57767206,\n",
       "        0.5719898 , 0.57377297, 0.5781257 , 0.5757954 , 0.574415  ,\n",
       "        0.5741906 , 0.5769161 , 0.57693267, 0.5770025 , 0.57694674,\n",
       "        0.57742864, 0.57376695, 0.58112866, 0.5764639 , 0.5759582 ,\n",
       "        0.57529503, 0.5810003 , 0.5787747 , 0.5767779 , 0.57612175,\n",
       "        0.57316494, 0.5752085 , 0.57775295, 0.5764081 , 0.5771606 ,\n",
       "        0.5752792 , 0.5765895 , 0.5754944 , 0.579902  , 0.5773097 ,\n",
       "        0.5774049 , 0.5786436 , 0.5758049 , 0.57592446], dtype=float32),\n",
       " array([0.59998727, 0.58702815, 0.5793405 , 0.581015  , 0.57509553,\n",
       "        0.5820668 , 0.5794865 , 0.5777286 , 0.57356924, 0.58184683,\n",
       "        0.57743675, 0.58148724, 0.5753212 , 0.57728714, 0.5773186 ,\n",
       "        0.57928425, 0.57656085, 0.5784348 , 0.5762486 , 0.57791966,\n",
       "        0.57685024, 0.5772566 , 0.5767822 , 0.5770043 , 0.5758884 ,\n",
       "        0.58459115, 0.57779217, 0.57879364, 0.5774634 , 0.58418536,\n",
       "        0.57484984, 0.57729346, 0.57495874, 0.5769945 , 0.57603484,\n",
       "        0.57967156, 0.5769556 , 0.57688504, 0.57703847, 0.5768588 ,\n",
       "        0.57386094, 0.58087987, 0.5791674 , 0.57979894, 0.5767654 ,\n",
       "        0.57934123, 0.58185875, 0.57628095, 0.5730646 , 0.5833947 ,\n",
       "        0.57555866, 0.583761  , 0.5764517 , 0.57779735, 0.5767242 ,\n",
       "        0.57741153, 0.57693774, 0.57996416, 0.5799754 , 0.57720125,\n",
       "        0.5766253 , 0.58061916, 0.5760482 , 0.5781867 ], dtype=float32),\n",
       " array([0.6011861 , 0.58023596, 0.5778316 , 0.5723851 , 0.5757032 ,\n",
       "        0.58055735, 0.57532406, 0.5767301 , 0.5765486 , 0.5795942 ,\n",
       "        0.57354164, 0.5757629 , 0.5769949 , 0.57723373, 0.5760436 ,\n",
       "        0.57600904, 0.5767224 , 0.57729894, 0.5776344 , 0.57612985,\n",
       "        0.57691056, 0.5771566 , 0.57678056, 0.5768187 , 0.57573533,\n",
       "        0.5806505 , 0.57304204, 0.5786405 , 0.57667106, 0.5801641 ,\n",
       "        0.5742971 , 0.5764198 , 0.577099  , 0.57723707, 0.5747999 ,\n",
       "        0.5768779 , 0.5769204 , 0.5769177 , 0.5769582 , 0.5769158 ,\n",
       "        0.5762844 , 0.5799432 , 0.57398444, 0.5760656 , 0.5764574 ,\n",
       "        0.5783005 , 0.57659376, 0.57602674, 0.576686  , 0.5787759 ,\n",
       "        0.57428527, 0.5745347 , 0.57687134, 0.57776064, 0.5761336 ,\n",
       "        0.5767774 , 0.5765498 , 0.5782103 , 0.5746906 , 0.5779337 ,\n",
       "        0.57670254, 0.57820904, 0.57782865, 0.5748386 ], dtype=float32),\n",
       " array([0.60709053, 0.578968  , 0.58038867, 0.5780832 , 0.58175826,\n",
       "        0.57827264, 0.57944876, 0.5789122 , 0.57721686, 0.57732266,\n",
       "        0.58226556, 0.57589793, 0.579305  , 0.57997507, 0.57599425,\n",
       "        0.57873356, 0.58010274, 0.5804734 , 0.58113223, 0.57868505,\n",
       "        0.5785663 , 0.57976675, 0.57725626, 0.5788795 , 0.5751221 ,\n",
       "        0.57944965, 0.5830796 , 0.57740396, 0.5759946 , 0.57962793,\n",
       "        0.5811535 , 0.57716477, 0.5766887 , 0.57882017, 0.57874185,\n",
       "        0.5778227 , 0.57536566, 0.58220434, 0.58434063, 0.57946914,\n",
       "        0.57715505, 0.5782644 , 0.57892245, 0.577563  , 0.5805755 ,\n",
       "        0.5764674 , 0.5777222 , 0.5768205 , 0.577851  , 0.5779176 ,\n",
       "        0.5770686 , 0.57699656, 0.5790077 , 0.580664  , 0.58013433,\n",
       "        0.5778993 , 0.57821363, 0.57870483, 0.5769578 , 0.5780231 ,\n",
       "        0.58006996, 0.578461  , 0.5760664 , 0.57708937], dtype=float32),\n",
       " array([0.6018245 , 0.5756772 , 0.57915306, 0.57742274, 0.58064175,\n",
       "        0.57730705, 0.57720727, 0.5764796 , 0.5764137 , 0.5794349 ,\n",
       "        0.5778757 , 0.57510364, 0.5757142 , 0.57501423, 0.57748264,\n",
       "        0.5782716 , 0.5801983 , 0.57663697, 0.57623816, 0.57643807,\n",
       "        0.57646984, 0.57654995, 0.5766758 , 0.5773102 , 0.5781387 ,\n",
       "        0.57663   , 0.5743216 , 0.57301265, 0.57767487, 0.57733274,\n",
       "        0.57332635, 0.5754261 , 0.5772916 , 0.57635313, 0.57473516,\n",
       "        0.57585716, 0.5800606 , 0.5755328 , 0.5677419 , 0.5718627 ,\n",
       "        0.578107  , 0.5761291 , 0.5738102 , 0.5755021 , 0.57636684,\n",
       "        0.5765633 , 0.58057845, 0.5782454 , 0.5775405 , 0.5779352 ,\n",
       "        0.5788313 , 0.5782894 , 0.5767649 , 0.57926786, 0.57814765,\n",
       "        0.5778353 , 0.57679385, 0.5770603 , 0.5775747 , 0.5776715 ,\n",
       "        0.5785943 , 0.5799979 , 0.58293545, 0.5809435 ], dtype=float32),\n",
       " array([0.6031066 , 0.5785728 , 0.58401954, 0.5760692 , 0.57777023,\n",
       "        0.5859153 , 0.57909805, 0.57586026, 0.5748035 , 0.5800517 ,\n",
       "        0.5752053 , 0.5804342 , 0.5771057 , 0.5868352 , 0.57978487,\n",
       "        0.5795418 , 0.57598794, 0.58342785, 0.57857895, 0.5783999 ,\n",
       "        0.578444  , 0.5804534 , 0.57878196, 0.57717854, 0.57380015,\n",
       "        0.5781549 , 0.57484895, 0.58149284, 0.57519287, 0.57839364,\n",
       "        0.5754597 , 0.58035946, 0.5765933 , 0.57829237, 0.57698804,\n",
       "        0.5783868 , 0.57483274, 0.5817565 , 0.57505476, 0.5820522 ,\n",
       "        0.5753652 , 0.5844634 , 0.5761323 , 0.58017135, 0.57773006,\n",
       "        0.5768033 , 0.5818641 , 0.57495147, 0.5770467 , 0.5765002 ,\n",
       "        0.57686603, 0.5764495 , 0.5770824 , 0.58167714, 0.57681006,\n",
       "        0.5790839 , 0.5779171 , 0.5787852 , 0.5780159 , 0.5767673 ,\n",
       "        0.57806987, 0.5766731 , 0.5768982 , 0.5744194 ], dtype=float32),\n",
       " array([0.6020397 , 0.57731   , 0.5749435 , 0.5778472 , 0.5760718 ,\n",
       "        0.58157444, 0.5743827 , 0.57621706, 0.5765982 , 0.57828695,\n",
       "        0.57964087, 0.57274985, 0.5762938 , 0.57930094, 0.5715452 ,\n",
       "        0.5789886 , 0.57628417, 0.58033156, 0.5730339 , 0.57720447,\n",
       "        0.57681   , 0.5769981 , 0.573319  , 0.5802386 , 0.57700956,\n",
       "        0.5778078 , 0.57558584, 0.5752475 , 0.57701474, 0.5770279 ,\n",
       "        0.5752653 , 0.5766702 , 0.5770218 , 0.576933  , 0.5747042 ,\n",
       "        0.5779554 , 0.5772429 , 0.5780758 , 0.57069457, 0.5781023 ,\n",
       "        0.5765673 , 0.5797017 , 0.57429075, 0.5753789 , 0.5766699 ,\n",
       "        0.5772885 , 0.5777341 , 0.5763844 , 0.5766839 , 0.5771726 ,\n",
       "        0.5769365 , 0.5777452 , 0.5764339 , 0.57786816, 0.5753061 ,\n",
       "        0.5782261 , 0.57677335, 0.5770469 , 0.5750095 , 0.57903814,\n",
       "        0.5761641 , 0.5780734 , 0.5777566 , 0.57874364], dtype=float32),\n",
       " array([0.60354125, 0.57832927, 0.5799262 , 0.57642317, 0.5813721 ,\n",
       "        0.5774677 , 0.57781446, 0.5770532 , 0.5776619 , 0.5826414 ,\n",
       "        0.5796579 , 0.5792987 , 0.5792351 , 0.5782122 , 0.581257  ,\n",
       "        0.57776934, 0.5788515 , 0.5788449 , 0.5800069 , 0.5795248 ,\n",
       "        0.5771512 , 0.57703197, 0.58073854, 0.5781017 , 0.57587117,\n",
       "        0.57750314, 0.57919   , 0.5776124 , 0.576393  , 0.57772887,\n",
       "        0.5805274 , 0.5780849 , 0.57869476, 0.57881033, 0.5786984 ,\n",
       "        0.5785261 , 0.57961136, 0.5780469 , 0.575262  , 0.5767504 ,\n",
       "        0.57898754, 0.5778694 , 0.5785693 , 0.5771065 , 0.5782787 ,\n",
       "        0.5772799 , 0.574402  , 0.57789016, 0.5788362 , 0.57718945,\n",
       "        0.57761246, 0.5772332 , 0.5800261 , 0.57786787, 0.5792589 ,\n",
       "        0.57667464, 0.57837427, 0.5782718 , 0.576633  , 0.57752705,\n",
       "        0.5876584 , 0.5815276 , 0.5848028 , 0.577774  ], dtype=float32),\n",
       " array([0.60128266, 0.5800253 , 0.57787114, 0.5774787 , 0.5774468 ,\n",
       "        0.57806134, 0.58210635, 0.57945716, 0.5778937 , 0.5738565 ,\n",
       "        0.57421166, 0.5763111 , 0.57872885, 0.5768735 , 0.5829878 ,\n",
       "        0.57549644, 0.57853687, 0.5739232 , 0.5794761 , 0.57349277,\n",
       "        0.5789357 , 0.57451344, 0.58125865, 0.5725123 , 0.5779646 ,\n",
       "        0.5747771 , 0.5791599 , 0.5739668 , 0.57840174, 0.5754447 ,\n",
       "        0.57930326, 0.5731691 , 0.5793589 , 0.57786596, 0.57879686,\n",
       "        0.5763849 , 0.57767993, 0.5789639 , 0.58314085, 0.5810776 ,\n",
       "        0.5773743 , 0.5775427 , 0.5787872 , 0.5777573 , 0.5777865 ,\n",
       "        0.57197773, 0.5777295 , 0.5769314 , 0.57654864, 0.5754419 ,\n",
       "        0.58003   , 0.5770138 , 0.57786125, 0.57990485, 0.57792276,\n",
       "        0.57828724, 0.57710636, 0.5777012 , 0.57888216, 0.578409  ,\n",
       "        0.5730331 , 0.5779455 , 0.58108735, 0.5798334 ], dtype=float32),\n",
       " array([0.6018062 , 0.58158916, 0.57563204, 0.5794615 , 0.5781031 ,\n",
       "        0.576698  , 0.5809673 , 0.5742561 , 0.57470506, 0.58564156,\n",
       "        0.5785089 , 0.58220553, 0.57579696, 0.5742104 , 0.5793936 ,\n",
       "        0.5760743 , 0.57562447, 0.58317876, 0.5797005 , 0.57854253,\n",
       "        0.5738405 , 0.5795018 , 0.57758874, 0.57886976, 0.57429355,\n",
       "        0.5773398 , 0.5767646 , 0.5790374 , 0.57501334, 0.5761071 ,\n",
       "        0.5770242 , 0.57809585, 0.5772476 , 0.5798023 , 0.57650393,\n",
       "        0.576433  , 0.5775292 , 0.5768148 , 0.5775114 , 0.57509357,\n",
       "        0.57728684, 0.57601047, 0.5789629 , 0.57598585, 0.57384354,\n",
       "        0.59118307, 0.57889646, 0.5811219 , 0.5762321 , 0.5790473 ,\n",
       "        0.5800574 , 0.57729685, 0.57683   , 0.58429986, 0.5764202 ,\n",
       "        0.5781162 , 0.5777501 , 0.57769674, 0.5776196 , 0.57623106,\n",
       "        0.57807267, 0.5902261 , 0.5889857 , 0.57971424], dtype=float32),\n",
       " array([0.6018003 , 0.57791764, 0.5782073 , 0.5752745 , 0.57641304,\n",
       "        0.5777171 , 0.57780886, 0.57732105, 0.5764789 , 0.5795146 ,\n",
       "        0.56898654, 0.57938665, 0.5765713 , 0.57819295, 0.5775254 ,\n",
       "        0.57640344, 0.57640845, 0.5805842 , 0.572941  , 0.57668495,\n",
       "        0.5764493 , 0.58059055, 0.5761706 , 0.5739497 , 0.5767569 ,\n",
       "        0.57868624, 0.5758215 , 0.5755672 , 0.57685953, 0.5782989 ,\n",
       "        0.576236  , 0.5759618 , 0.5764525 , 0.57905376, 0.575418  ,\n",
       "        0.5779037 , 0.5761968 , 0.5779474 , 0.5775727 , 0.5783759 ,\n",
       "        0.5767723 , 0.57694   , 0.5770768 , 0.57736605, 0.57581353,\n",
       "        0.58331805, 0.57136047, 0.5745183 , 0.57657886, 0.57829493,\n",
       "        0.57611895, 0.5762208 , 0.57611847, 0.5798458 , 0.577669  ,\n",
       "        0.5747255 , 0.5766663 , 0.57715625, 0.5761007 , 0.5785926 ,\n",
       "        0.5758316 , 0.5793663 , 0.57454234, 0.5756354 ], dtype=float32),\n",
       " array([0.6033055 , 0.57787615, 0.5817957 , 0.5773059 , 0.5772145 ,\n",
       "        0.5771679 , 0.57729906, 0.5771825 , 0.5814086 , 0.58031803,\n",
       "        0.5811584 , 0.58028144, 0.57818395, 0.5793431 , 0.57792115,\n",
       "        0.5789605 , 0.57795364, 0.5776167 , 0.57542497, 0.57806027,\n",
       "        0.57732457, 0.578499  , 0.5777541 , 0.5779194 , 0.57860494,\n",
       "        0.5766933 , 0.577185  , 0.5766303 , 0.57762825, 0.57928395,\n",
       "        0.57767797, 0.57848084, 0.5816914 , 0.5784805 , 0.58515424,\n",
       "        0.57898307, 0.57965744, 0.5789043 , 0.57917994, 0.57773465,\n",
       "        0.5813515 , 0.580087  , 0.5803394 , 0.57954437, 0.5779204 ,\n",
       "        0.5777139 , 0.578716  , 0.5774039 , 0.5798956 , 0.5782273 ,\n",
       "        0.58202565, 0.5783689 , 0.57740366, 0.5780077 , 0.58170533,\n",
       "        0.57692695, 0.57661396, 0.5794769 , 0.5831348 , 0.5766356 ,\n",
       "        0.57699096, 0.57691985, 0.57734036, 0.57665944], dtype=float32),\n",
       " array([0.6042151 , 0.5799558 , 0.5713165 , 0.57448244, 0.5775065 ,\n",
       "        0.577163  , 0.5769698 , 0.5767444 , 0.57714236, 0.57542855,\n",
       "        0.57993615, 0.5749031 , 0.5772975 , 0.57622635, 0.5755951 ,\n",
       "        0.5761088 , 0.5775679 , 0.5727159 , 0.5781102 , 0.5763902 ,\n",
       "        0.577749  , 0.5747773 , 0.5750579 , 0.5760003 , 0.576354  ,\n",
       "        0.57680446, 0.578673  , 0.5777943 , 0.57676506, 0.57560724,\n",
       "        0.57572544, 0.5763958 , 0.58005136, 0.5754924 , 0.580381  ,\n",
       "        0.57271767, 0.57565624, 0.5780971 , 0.57691556, 0.5775001 ,\n",
       "        0.5771555 , 0.5764326 , 0.5765598 , 0.57634234, 0.57774884,\n",
       "        0.57706887, 0.5763986 , 0.576393  , 0.57805943, 0.5774323 ,\n",
       "        0.57832706, 0.5743739 , 0.5774536 , 0.57879233, 0.5814533 ,\n",
       "        0.57483035, 0.57744724, 0.57899284, 0.5711432 , 0.57482713,\n",
       "        0.57668895, 0.57747453, 0.5767572 , 0.5770272 ], dtype=float32),\n",
       " array([0.60175735, 0.5875748 , 0.5734406 , 0.58022434, 0.5769753 ,\n",
       "        0.5775887 , 0.57668525, 0.5768232 , 0.5786579 , 0.58025354,\n",
       "        0.58304936, 0.5760059 , 0.57788324, 0.5816114 , 0.5780755 ,\n",
       "        0.5776309 , 0.5743966 , 0.587978  , 0.5787319 , 0.5804139 ,\n",
       "        0.5755051 , 0.5832636 , 0.57767224, 0.57958925, 0.5769319 ,\n",
       "        0.5781358 , 0.57902586, 0.57672465, 0.5770887 , 0.58098835,\n",
       "        0.5782607 , 0.5784246 , 0.5759858 , 0.5782305 , 0.58272266,\n",
       "        0.5760962 , 0.5782243 , 0.5812057 , 0.5792906 , 0.5776373 ,\n",
       "        0.5792507 , 0.5810852 , 0.58221555, 0.5759532 , 0.57700944,\n",
       "        0.5776174 , 0.57771516, 0.576859  , 0.5770637 , 0.5806104 ,\n",
       "        0.5792136 , 0.5771731 , 0.5746962 , 0.5790199 , 0.57526934,\n",
       "        0.57953924, 0.57464004, 0.58471113, 0.5740061 , 0.5827108 ,\n",
       "        0.5768016 , 0.5775968 , 0.5765789 , 0.5773823 ], dtype=float32),\n",
       " array([0.601801  , 0.58035463, 0.5767421 , 0.5733394 , 0.57684034,\n",
       "        0.57739186, 0.57671994, 0.57694304, 0.57670355, 0.577936  ,\n",
       "        0.57295835, 0.57981336, 0.57679194, 0.5778537 , 0.57326263,\n",
       "        0.5791502 , 0.5760604 , 0.58196026, 0.57212245, 0.5753716 ,\n",
       "        0.57660496, 0.57933104, 0.57324946, 0.5766204 , 0.576704  ,\n",
       "        0.57746124, 0.57732457, 0.57615316, 0.57682407, 0.57761323,\n",
       "        0.57326365, 0.5788019 , 0.57656306, 0.5798591 , 0.57593846,\n",
       "        0.57493156, 0.57672083, 0.57706714, 0.5757873 , 0.57776743,\n",
       "        0.5768035 , 0.5774036 , 0.57318854, 0.579739  , 0.57688004,\n",
       "        0.5773438 , 0.5763454 , 0.57696265, 0.5766142 , 0.57886463,\n",
       "        0.57643485, 0.5757661 , 0.5763816 , 0.57906467, 0.57873046,\n",
       "        0.5741205 , 0.5767074 , 0.5787659 , 0.576036  , 0.57382923,\n",
       "        0.57687813, 0.5770065 , 0.5773721 , 0.57639974], dtype=float32),\n",
       " array([0.6033742 , 0.57793885, 0.5799603 , 0.5783248 , 0.57962424,\n",
       "        0.5776233 , 0.57808244, 0.57686037, 0.57939297, 0.5816773 ,\n",
       "        0.5814248 , 0.5798776 , 0.57802653, 0.5779488 , 0.57652855,\n",
       "        0.576855  , 0.5794024 , 0.57958305, 0.5767805 , 0.57815224,\n",
       "        0.58241767, 0.5767279 , 0.5760694 , 0.57719636, 0.5844138 ,\n",
       "        0.5794946 , 0.5827291 , 0.5774629 , 0.5800628 , 0.5781382 ,\n",
       "        0.57424104, 0.57692325, 0.5792566 , 0.5815551 , 0.579691  ,\n",
       "        0.5811142 , 0.57685494, 0.5774985 , 0.57805413, 0.57740784,\n",
       "        0.5782315 , 0.5797547 , 0.5804197 , 0.57972884, 0.57714677,\n",
       "        0.57669836, 0.5753715 , 0.5766734 , 0.5850253 , 0.5787613 ,\n",
       "        0.58144486, 0.5792353 , 0.57892025, 0.5772223 , 0.5798981 ,\n",
       "        0.5749245 , 0.580172  , 0.5764543 , 0.5782739 , 0.57522   ,\n",
       "        0.57750607, 0.5769815 , 0.5777453 , 0.57573926], dtype=float32),\n",
       " array([0.60468537, 0.5771134 , 0.57359785, 0.574583  , 0.5761428 ,\n",
       "        0.57368076, 0.58098185, 0.5774783 , 0.57754487, 0.5774849 ,\n",
       "        0.5822565 , 0.57520753, 0.57533956, 0.5764067 , 0.5774448 ,\n",
       "        0.5781686 , 0.57650375, 0.57501113, 0.5844078 , 0.5781654 ,\n",
       "        0.57536197, 0.5728581 , 0.58513236, 0.5791702 , 0.5744324 ,\n",
       "        0.5805026 , 0.5793663 , 0.5788983 , 0.57780164, 0.5769308 ,\n",
       "        0.58613175, 0.581305  , 0.5784377 , 0.5761092 , 0.5719184 ,\n",
       "        0.5744805 , 0.57776535, 0.5768704 , 0.5753147 , 0.5759531 ,\n",
       "        0.57892984, 0.5762982 , 0.57374203, 0.5736406 , 0.57616675,\n",
       "        0.57417166, 0.580075  , 0.577386  , 0.5772307 , 0.57716477,\n",
       "        0.58003324, 0.5773001 , 0.57545817, 0.58193713, 0.57819915,\n",
       "        0.5791596 , 0.5746591 , 0.5782276 , 0.5798216 , 0.5793004 ,\n",
       "        0.57568336, 0.578078  , 0.57786393, 0.57796633], dtype=float32),\n",
       " array([0.6025516 , 0.5810785 , 0.57666403, 0.5771663 , 0.57438904,\n",
       "        0.5822292 , 0.58198845, 0.57939845, 0.5766754 , 0.58197045,\n",
       "        0.5780222 , 0.57895136, 0.5761342 , 0.58372194, 0.5779622 ,\n",
       "        0.5797106 , 0.5747484 , 0.585077  , 0.57931954, 0.58001775,\n",
       "        0.57585645, 0.58266616, 0.58589655, 0.5768239 , 0.57968694,\n",
       "        0.58367395, 0.5834667 , 0.57675534, 0.5757989 , 0.58046937,\n",
       "        0.57853234, 0.5765823 , 0.57921606, 0.58682424, 0.57831365,\n",
       "        0.5781457 , 0.5767605 , 0.57831484, 0.57641655, 0.57746714,\n",
       "        0.577068  , 0.5859607 , 0.57672703, 0.5791207 , 0.574488  ,\n",
       "        0.5819872 , 0.57832414, 0.5795241 , 0.5806222 , 0.57961917,\n",
       "        0.5863061 , 0.57279   , 0.57655513, 0.5812718 , 0.5752392 ,\n",
       "        0.57913387, 0.5759094 , 0.5833799 , 0.5795337 , 0.5791458 ,\n",
       "        0.575451  , 0.58193004, 0.5762285 , 0.5798099 ], dtype=float32),\n",
       " array([0.6021616 , 0.578749  , 0.5751838 , 0.5764793 , 0.5762477 ,\n",
       "        0.5798252 , 0.57487595, 0.57478625, 0.5762506 , 0.57919973,\n",
       "        0.57354254, 0.5792329 , 0.5764445 , 0.5785655 , 0.575238  ,\n",
       "        0.57622033, 0.57576185, 0.58105344, 0.57345355, 0.57702863,\n",
       "        0.5759734 , 0.58026046, 0.5749844 , 0.57545733, 0.57637537,\n",
       "        0.5772908 , 0.57763654, 0.5765656 , 0.57568717, 0.580324  ,\n",
       "        0.57608926, 0.5773952 , 0.57678026, 0.5788387 , 0.5697562 ,\n",
       "        0.5810053 , 0.57692945, 0.57747114, 0.5760605 , 0.5768549 ,\n",
       "        0.57660174, 0.57997966, 0.57240665, 0.57754046, 0.57633805,\n",
       "        0.5796248 , 0.5753062 , 0.5751367 , 0.5766241 , 0.5775751 ,\n",
       "        0.5755016 , 0.57865256, 0.57635725, 0.5777014 , 0.5808383 ,\n",
       "        0.57354724, 0.5762035 , 0.57884985, 0.578875  , 0.5731309 ,\n",
       "        0.5764394 , 0.5784645 , 0.57793766, 0.57425046], dtype=float32),\n",
       " array([0.6024301 , 0.5770082 , 0.5790418 , 0.5774346 , 0.5799538 ,\n",
       "        0.5833194 , 0.58255607, 0.5787185 , 0.5789105 , 0.579026  ,\n",
       "        0.57960784, 0.5787388 , 0.5785697 , 0.5774621 , 0.5810898 ,\n",
       "        0.57561654, 0.5803964 , 0.5772061 , 0.5781574 , 0.5772394 ,\n",
       "        0.5792316 , 0.5772347 , 0.57581764, 0.5754466 , 0.57676274,\n",
       "        0.5772605 , 0.5773184 , 0.5770072 , 0.5774704 , 0.5770979 ,\n",
       "        0.5776318 , 0.5763438 , 0.5815147 , 0.57792246, 0.5763625 ,\n",
       "        0.577541  , 0.5776679 , 0.57847   , 0.5772039 , 0.5780593 ,\n",
       "        0.58217275, 0.5791003 , 0.58023036, 0.579618  , 0.57851964,\n",
       "        0.5779324 , 0.5793837 , 0.57514584, 0.57941806, 0.5767226 ,\n",
       "        0.5801259 , 0.5772122 , 0.5801752 , 0.57927674, 0.58126426,\n",
       "        0.57777864, 0.57786405, 0.58058506, 0.5787512 , 0.5789854 ,\n",
       "        0.57955945, 0.57793325, 0.5806419 , 0.5786011 ], dtype=float32),\n",
       " array([0.60323095, 0.5765844 , 0.5781795 , 0.57496077, 0.5754726 ,\n",
       "        0.5799043 , 0.573343  , 0.57745856, 0.5808981 , 0.57870835,\n",
       "        0.57513124, 0.5759279 , 0.57575613, 0.5799827 , 0.57624507,\n",
       "        0.5773109 , 0.5766996 , 0.57740396, 0.5799918 , 0.57811505,\n",
       "        0.57539254, 0.57812274, 0.58125955, 0.58072466, 0.577028  ,\n",
       "        0.57672286, 0.57646805, 0.57669425, 0.576573  , 0.5784948 ,\n",
       "        0.5774765 , 0.57774705, 0.5770941 , 0.5749315 , 0.58773196,\n",
       "        0.57943726, 0.57658833, 0.5765082 , 0.57632774, 0.57684463,\n",
       "        0.5784577 , 0.57618874, 0.5763205 , 0.57583845, 0.5745892 ,\n",
       "        0.58067256, 0.577102  , 0.57906926, 0.57751685, 0.5769235 ,\n",
       "        0.5819713 , 0.5757754 , 0.5755171 , 0.57866395, 0.5779801 ,\n",
       "        0.576596  , 0.5769599 , 0.5762606 , 0.5750719 , 0.5764131 ,\n",
       "        0.57946074, 0.5777062 , 0.5739798 , 0.57468367], dtype=float32),\n",
       " array([0.60143864, 0.57711554, 0.5769783 , 0.5772477 , 0.5773079 ,\n",
       "        0.59043217, 0.57688415, 0.58286643, 0.5775716 , 0.58244276,\n",
       "        0.57517797, 0.57658625, 0.5763428 , 0.5801929 , 0.5768026 ,\n",
       "        0.5792116 , 0.57832235, 0.57620263, 0.5809927 , 0.5746738 ,\n",
       "        0.57545114, 0.5838232 , 0.57759666, 0.5794194 , 0.57665014,\n",
       "        0.5771552 , 0.5768651 , 0.5773773 , 0.57680887, 0.5781804 ,\n",
       "        0.57622814, 0.5775538 , 0.57557184, 0.58036536, 0.58244133,\n",
       "        0.57644075, 0.5777271 , 0.5790434 , 0.57797545, 0.5772427 ,\n",
       "        0.5789648 , 0.5845144 , 0.58208156, 0.5757709 , 0.5756851 ,\n",
       "        0.5856057 , 0.57532525, 0.5814994 , 0.5765691 , 0.5750405 ,\n",
       "        0.5800036 , 0.57559866, 0.5776635 , 0.58239514, 0.579376  ,\n",
       "        0.57860154, 0.57761854, 0.58029264, 0.5782232 , 0.57835984,\n",
       "        0.57799643, 0.58268017, 0.5777045 , 0.5764992 ], dtype=float32),\n",
       " array([0.60215265, 0.57797   , 0.577061  , 0.57588553, 0.5762862 ,\n",
       "        0.57874495, 0.5722911 , 0.5783999 , 0.576437  , 0.579889  ,\n",
       "        0.5748627 , 0.5774096 , 0.5766848 , 0.57726085, 0.5793707 ,\n",
       "        0.57392967, 0.57674915, 0.57681036, 0.5775124 , 0.5774201 ,\n",
       "        0.5759413 , 0.57953334, 0.57765573, 0.57457817, 0.57693756,\n",
       "        0.5769832 , 0.5765162 , 0.57695276, 0.57672983, 0.5771926 ,\n",
       "        0.57804   , 0.5760659 , 0.57576096, 0.5805311 , 0.575662  ,\n",
       "        0.57662755, 0.5769068 , 0.57692015, 0.574766  , 0.5787051 ,\n",
       "        0.57650614, 0.5794809 , 0.5732096 , 0.57802725, 0.5762016 ,\n",
       "        0.5786618 , 0.5788533 , 0.57334507, 0.5766841 , 0.57776767,\n",
       "        0.57853365, 0.575544  , 0.5765787 , 0.57768047, 0.5763463 ,\n",
       "        0.5766693 , 0.5769169 , 0.5769515 , 0.57260716, 0.5801202 ,\n",
       "        0.57670236, 0.57924527, 0.5753762 , 0.5762564 ], dtype=float32),\n",
       " array([0.6056144 , 0.5783005 , 0.5768101 , 0.5762708 , 0.5833292 ,\n",
       "        0.5767633 , 0.5828445 , 0.5741495 , 0.5788745 , 0.5819788 ,\n",
       "        0.5799399 , 0.57937145, 0.5784595 , 0.5781908 , 0.5773454 ,\n",
       "        0.5774164 , 0.58067906, 0.5797845 , 0.5792436 , 0.5768978 ,\n",
       "        0.5796632 , 0.57837415, 0.576719  , 0.5767553 , 0.5838657 ,\n",
       "        0.5779545 , 0.58302414, 0.5776069 , 0.58298516, 0.57694715,\n",
       "        0.5765975 , 0.57665443, 0.5799153 , 0.577886  , 0.5759492 ,\n",
       "        0.57678723, 0.58132184, 0.5790085 , 0.57722616, 0.57861364,\n",
       "        0.5836774 , 0.5779266 , 0.58129245, 0.57428664, 0.5823032 ,\n",
       "        0.5789208 , 0.5774831 , 0.5781462 , 0.57957405, 0.57873094,\n",
       "        0.58210105, 0.57713974, 0.5784847 , 0.57843703, 0.5775935 ,\n",
       "        0.5767371 , 0.5794142 , 0.58090353, 0.5788249 , 0.58015096,\n",
       "        0.58441484, 0.57603407, 0.580693  , 0.5756186 ], dtype=float32),\n",
       " array([0.60297084, 0.58121276, 0.5831492 , 0.581514  , 0.5742339 ,\n",
       "        0.58341575, 0.58090407, 0.5803869 , 0.5787098 , 0.5775854 ,\n",
       "        0.5759167 , 0.5771078 , 0.57728714, 0.5776265 , 0.5789571 ,\n",
       "        0.5780789 , 0.5762606 , 0.5801904 , 0.57731056, 0.5794147 ,\n",
       "        0.5778022 , 0.5800234 , 0.5832615 , 0.5805329 , 0.5773209 ,\n",
       "        0.5754248 , 0.5840456 , 0.57676995, 0.57650256, 0.57722497,\n",
       "        0.5851882 , 0.58107483, 0.5776447 , 0.5790833 , 0.58287364,\n",
       "        0.5806898 , 0.57647943, 0.57438135, 0.5777626 , 0.57775056,\n",
       "        0.5753155 , 0.58539224, 0.5842268 , 0.5828868 , 0.5767543 ,\n",
       "        0.5770919 , 0.58363944, 0.57973844, 0.57808375, 0.5776031 ,\n",
       "        0.57280344, 0.57542425, 0.5748794 , 0.5775168 , 0.57698   ,\n",
       "        0.57831126, 0.5782742 , 0.5768799 , 0.5756048 , 0.57606137,\n",
       "        0.574944  , 0.57895607, 0.5831684 , 0.57978934], dtype=float32),\n",
       " array([0.60312   , 0.5774713 , 0.576521  , 0.5753359 , 0.5772553 ,\n",
       "        0.58363676, 0.5797007 , 0.5784121 , 0.57754105, 0.5809781 ,\n",
       "        0.57740575, 0.57813764, 0.577472  , 0.577096  , 0.5778937 ,\n",
       "        0.5762498 , 0.5762101 , 0.59236026, 0.5760943 , 0.58172894,\n",
       "        0.5775157 , 0.5766419 , 0.5767972 , 0.5753712 , 0.5768144 ,\n",
       "        0.5754648 , 0.5869437 , 0.5746235 , 0.57802016, 0.57742023,\n",
       "        0.58360577, 0.573754  , 0.57784534, 0.576061  , 0.57806796,\n",
       "        0.5746465 , 0.57667726, 0.59021807, 0.5818418 , 0.5794164 ,\n",
       "        0.5779436 , 0.5812527 , 0.5780047 , 0.5768368 , 0.5784967 ,\n",
       "        0.57880795, 0.5826327 , 0.57466805, 0.5745843 , 0.59234583,\n",
       "        0.5766641 , 0.58264136, 0.5763164 , 0.5852137 , 0.5776658 ,\n",
       "        0.5804182 , 0.57875717, 0.5836952 , 0.5782112 , 0.57726926,\n",
       "        0.5782187 , 0.57894963, 0.58501035, 0.5747358 ], dtype=float32),\n",
       " array([0.60140735, 0.5779411 , 0.5791152 , 0.5775516 , 0.5759911 ,\n",
       "        0.57836276, 0.58311623, 0.57114506, 0.5766153 , 0.57792157,\n",
       "        0.57222354, 0.5806518 , 0.5766919 , 0.5771568 , 0.5763956 ,\n",
       "        0.57816434, 0.5756365 , 0.5814314 , 0.57543576, 0.5746068 ,\n",
       "        0.5761928 , 0.57787675, 0.5782952 , 0.5780181 , 0.5764962 ,\n",
       "        0.5781166 , 0.5773187 , 0.57560384, 0.57613575, 0.5782418 ,\n",
       "        0.5780044 , 0.5769315 , 0.5762985 , 0.5775923 , 0.577944  ,\n",
       "        0.578272  , 0.5759941 , 0.5812863 , 0.5718125 , 0.57660097,\n",
       "        0.57570547, 0.57817316, 0.5834919 , 0.57340086, 0.576249  ,\n",
       "        0.5780728 , 0.575633  , 0.57903695, 0.5760139 , 0.5822909 ,\n",
       "        0.5746235 , 0.57213014, 0.57637924, 0.5785743 , 0.57558674,\n",
       "        0.57588094, 0.5766155 , 0.5785486 , 0.5717673 , 0.5805892 ,\n",
       "        0.576292  , 0.57772875, 0.5807419 , 0.5737003 ], dtype=float32),\n",
       " array([0.60755527, 0.58370596, 0.58443433, 0.58249587, 0.5806687 ,\n",
       "        0.57663035, 0.5788963 , 0.5765682 , 0.57763726, 0.57867956,\n",
       "        0.5772624 , 0.5784183 , 0.58123636, 0.5793126 , 0.57814974,\n",
       "        0.57897604, 0.58182794, 0.57861876, 0.5824943 , 0.5793188 ,\n",
       "        0.58066744, 0.5774504 , 0.5794924 , 0.5786627 , 0.5797937 ,\n",
       "        0.57919574, 0.576629  , 0.57695854, 0.5826989 , 0.58026737,\n",
       "        0.57846254, 0.57915413, 0.58318794, 0.5818194 , 0.58533967,\n",
       "        0.57838565, 0.5819563 , 0.578745  , 0.58054256, 0.57826394,\n",
       "        0.57757366, 0.57815295, 0.5818382 , 0.57587373, 0.5802064 ,\n",
       "        0.5768556 , 0.58046466, 0.577631  , 0.5812588 , 0.5811886 ,\n",
       "        0.57896644, 0.57798415, 0.58063376, 0.57720405, 0.5802704 ,\n",
       "        0.5781132 , 0.57812905, 0.57958275, 0.57737297, 0.5786459 ,\n",
       "        0.5820664 , 0.5803587 , 0.5722278 , 0.5779902 ], dtype=float32),\n",
       " array([0.6048858 , 0.5756367 , 0.5754305 , 0.57307863, 0.57627285,\n",
       "        0.57758296, 0.5798981 , 0.5780675 , 0.5766829 , 0.5751397 ,\n",
       "        0.57785034, 0.57616204, 0.5761891 , 0.5757466 , 0.57845193,\n",
       "        0.57761854, 0.58054465, 0.5777946 , 0.57480735, 0.5745463 ,\n",
       "        0.5795439 , 0.57433254, 0.57850844, 0.5747477 , 0.57558477,\n",
       "        0.5784759 , 0.58016354, 0.580312  , 0.5772285 , 0.5780817 ,\n",
       "        0.5810079 , 0.5793308 , 0.5781385 , 0.5808609 , 0.5765122 ,\n",
       "        0.5773611 , 0.5798559 , 0.5789972 , 0.5792411 , 0.57764965,\n",
       "        0.57625496, 0.58088475, 0.5731124 , 0.57630664, 0.57791203,\n",
       "        0.5756328 , 0.58341944, 0.5753581 , 0.57668394, 0.581219  ,\n",
       "        0.58179325, 0.580478  , 0.57885236, 0.5774857 , 0.5765634 ,\n",
       "        0.5756937 , 0.5765949 , 0.57569295, 0.57723063, 0.5769197 ,\n",
       "        0.57632476, 0.5761469 , 0.58659333, 0.5839219 ], dtype=float32),\n",
       " array([0.60431737, 0.58581555, 0.5822122 , 0.57758033, 0.5777066 ,\n",
       "        0.57726675, 0.58125913, 0.57544696, 0.57666796, 0.58067834,\n",
       "        0.57852674, 0.5782453 , 0.5788622 , 0.5815796 , 0.5826314 ,\n",
       "        0.57611257, 0.5787034 , 0.58269936, 0.5800406 , 0.5751131 ,\n",
       "        0.5754195 , 0.5876827 , 0.58024055, 0.57831705, 0.57695216,\n",
       "        0.5841953 , 0.5779891 , 0.5789108 , 0.5799391 , 0.57984674,\n",
       "        0.5821747 , 0.5742941 , 0.57810724, 0.5844579 , 0.58012474,\n",
       "        0.5782645 , 0.578481  , 0.57923484, 0.579698  , 0.57433605,\n",
       "        0.57581186, 0.58525634, 0.57381314, 0.5815682 , 0.57603   ,\n",
       "        0.5759291 , 0.58157194, 0.575638  , 0.578413  , 0.5829206 ,\n",
       "        0.5773313 , 0.57756317, 0.578328  , 0.5797173 , 0.57991505,\n",
       "        0.574962  , 0.57726103, 0.58105034, 0.57871443, 0.5781667 ,\n",
       "        0.5771264 , 0.58515877, 0.5811671 , 0.57703453], dtype=float32),\n",
       " array([0.60191923, 0.57952666, 0.568788  , 0.58153623, 0.5766722 ,\n",
       "        0.577204  , 0.5784264 , 0.57577276, 0.5767052 , 0.57811093,\n",
       "        0.5737668 , 0.57823586, 0.5766352 , 0.577681  , 0.5734383 ,\n",
       "        0.5794175 , 0.5765971 , 0.5797229 , 0.5749432 , 0.5766416 ,\n",
       "        0.5759908 , 0.5827581 , 0.5736716 , 0.57410806, 0.576078  ,\n",
       "        0.5788211 , 0.5756428 , 0.57733274, 0.576403  , 0.577534  ,\n",
       "        0.5743834 , 0.580765  , 0.57627106, 0.5788018 , 0.5754774 ,\n",
       "        0.5770308 , 0.57636535, 0.57892895, 0.5765514 , 0.57746977,\n",
       "        0.5765381 , 0.5785848 , 0.57843155, 0.5730857 , 0.5765208 ,\n",
       "        0.5787468 , 0.5776689 , 0.57528645, 0.57597196, 0.57841426,\n",
       "        0.575971  , 0.57926446, 0.5767233 , 0.57850045, 0.5766247 ,\n",
       "        0.57623786, 0.57670623, 0.57773054, 0.5731469 , 0.57927823,\n",
       "        0.57539415, 0.5805547 , 0.5725856 , 0.5803977 ], dtype=float32)]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(pred_img[0][:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18,6))\n",
    "    gs = gridspec.GridSpec(1, 10)\n",
    "    gs.update(wspace = 0., hspace = 0.)\n",
    "    ts = [0,5,9,10,12,14,16,18,19]\n",
    "    xlables = [round(i,2) for i in list(np.linspace(np.min(lon),np.max(lon),5))]\n",
    "    ylabels = [round(i,2) for i  in list(np.linspace(np.max(lat),np.min(lat),5))] \n",
    "    for t in range(len(ts)):\n",
    "        #if t==0 : ax1=plt.subplot(gs[t])\n",
    "        ax1 = plt.subplot(gs[t])\n",
    "        input_image = input_images_[ts[t], :, :, 0] * (321.46630859375 - 235.2141571044922) + 235.2141571044922\n",
    "        plt.imshow(input_image, cmap = 'jet', vmin=270, vmax=300)\n",
    "        ax1.title.set_text(\"t = \" + str(ts[t]+1))\n",
    "        plt.setp([ax1], xticks = [], xticklabels = [], yticks = [], yticklabels = [])\n",
    "        if t == 0:\n",
    "            plt.setp([ax1], xticks = list(np.linspace(0, 64, 3)), xticklabels = xlables, yticks = list(np.linspace(0, 64, 3)), yticklabels = ylabels)\n",
    "            plt.ylabel(\"Ground Truth\", fontsize=10)\n",
    "    plt.savefig(os.path.join(args.output_png_dir, \"Ground_Truth_Sample_\" + str(name) + \".jpg\"))\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-bdb6a8305b7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_img\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(real_img[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(real_img).shape"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
