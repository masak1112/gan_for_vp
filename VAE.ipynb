{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial from https://github.com/shaohua0116/VAE-Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gongbing/anaconda3/envs/GAN_practice/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/gongbing/anaconda3/envs/GAN_practice/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/gongbing/anaconda3/envs/GAN_practice/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/gongbing/anaconda3/envs/GAN_practice/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/gongbing/anaconda3/envs/GAN_practice/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/gongbing/anaconda3/envs/GAN_practice/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'layer_def' from '/Users/gongbing/PycharmProjects/GAN_practice/layer_def.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import importlib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.slim import fully_connected as fc\n",
    "import matplotlib.pyplot as plt \n",
    "import glob\n",
    "from collections import OrderedDict\n",
    "%matplotlib inline\n",
    "from datetime import datetime\n",
    "import os\n",
    "from pathlib import Path\n",
    "import layer_def as ld\n",
    "importlib.reload(ld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = \"/Users/gongbing/PycharmProjects/video_prediction_savp/data/era5_size_64_64_3_3t_norm/train\"\n",
    "test_files = \"/Users/gongbing/PycharmProjects/video_prediction_savp/data/era5_size_64_64_3_3t_norm/test\"\n",
    "val_files = \"/Users/gongbing/PycharmProjects/video_prediction_savp/data/era5_size_64_64_3_3t_norm/train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "batch_size=40\n",
    "input_dim=3\n",
    "num_sample = 1500\n",
    "def make_dataset(type=\"train\"):\n",
    "    if type==\"train\": filenames = glob.glob(\"/Users/gongbing/PycharmProjects/video_prediction_savp/data/era5_size_64_64_3_3t_norm/train/*.tfrecords\")\n",
    "    if type==\"val\":filenames = glob.glob(\"/Users/gongbing/PycharmProjects/video_prediction_savp/data/era5_size_64_64_3_3t_norm/val/*.tfrecords\")\n",
    "    if type==\"test\":filenames = glob.glob(\"/Users/gongbing/PycharmProjects/video_prediction_savp/data/era5_size_64_64_3_3t_norm/test/*.tfrecords\")\n",
    "    \n",
    "    def parser(serialized_example):\n",
    "            seqs = OrderedDict()\n",
    "            keys_to_features = {\n",
    "                # 'width': tf.FixedLenFeature([], tf.int64),\n",
    "                # 'height': tf.FixedLenFeature([], tf.int64),\n",
    "                'sequence_length': tf.FixedLenFeature([], tf.int64),\n",
    "                # 'channels': tf.FixedLenFeature([],tf.int64),\n",
    "                # 'images/encoded':  tf.FixedLenFeature([], tf.string)\n",
    "                'images/encoded': tf.VarLenFeature(tf.float32)\n",
    "            }\n",
    "            parsed_features = tf.parse_single_example(serialized_example, keys_to_features)\n",
    "            seq = tf.sparse_tensor_to_dense(parsed_features[\"images/encoded\"])\n",
    "            print(\"Seq= \",seq.shape)\n",
    "            images = tf.reshape(seq, [20,64, 64,3], name = \"reshape_new\")\n",
    "            seqs[\"images\"] = images\n",
    "            return seqs\n",
    "    dataset = tf.data.TFRecordDataset(filenames, buffer_size = 8 * 1024 * 1024)\n",
    "    dataset = dataset.repeat(num_epochs)\n",
    "    dataset = dataset.apply(tf.contrib.data.map_and_batch(\n",
    "            parser, batch_size, drop_remainder = True, num_parallel_calls = None))\n",
    "    #dataset = dataset.map(parser)i\n",
    "    # num_parallel_calls = None if shuffle else 1  # for reproducibility (e.g. sampled subclips from the test set)\n",
    "    # dataset = dataset.apply(tf.contrib.data.map_and_batch(\n",
    "    #    _parser, batch_size, drop_remainder=True, num_parallel_calls=num_parallel_calls)) #  Bing: Parallel data mapping, num_parallel_calls normally depends on the hardware, however, normally should be equal to be the usalbe number of CPUs\n",
    "    dataset = dataset.prefetch(batch_size)  # Bing: Take the data to buffer inorder to save the waiting time for GPU\n",
    "    print(\"dataset\",dataset)\n",
    "    #dataset = dataset.repeat(max_step)\n",
    "    #dataset = dataset.batch(batch_size)\n",
    "    #iterator = dataset.make_one_shot_iterator() #One shot iterator will pool all the data once and memery issue\n",
    "    iterator = dataset.make_initializable_iterator()\n",
    "    return iterator\n",
    "\n",
    "class VariantionalAutoencoder(object):\n",
    "\n",
    "    def __init__(self, learning_rate=1e-4, batch_size=64, n_z=16):\n",
    "        # Set hyperparameters\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.n_z = n_z\n",
    "        # Build the graph\n",
    "        self.build()\n",
    "        # Initialize paramters\n",
    "        self.sess = tf.InteractiveSession()\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        # Summary op\n",
    "        self.loss_summary = tf.summary.scalar(\"recon_losses\", self.recon_loss)\n",
    "        self.loss_summary = tf.summary.scalar(\"latent_losses\", self.latent_loss)\n",
    "        self.summary_op = tf.summary.merge_all()\n",
    "        self.summary_dir = \"./\"\n",
    "        self.base_dir = \"VAE\"\n",
    "        self.checkpoint_dir =  \"VAE\" + \"/checkpoint\"\n",
    "        Path(self.checkpoint_dir).mkdir(parents=True, exist_ok=True)\n",
    "        self.train_log_file = self.base_dir + \"/train_\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        self.val_log_file = self.base_dir + \"/val_\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        self.train_writer = tf.summary.FileWriter(self.train_log_file, self.sess.graph)\n",
    "        self.val_writer = tf.summary.FileWriter(self.val_log_file, self.sess.graph)\n",
    "\n",
    "         \n",
    "    def vae_arc1(self):\n",
    "        \n",
    "        f1 = fc(self.x, 128, scope='enc_fc1', activation_fn=tf.nn.relu)\n",
    "        f2 = fc(f1, 64, scope='enc_fc2', activation_fn=tf.nn.relu)\n",
    "        f3 = fc(f2, 32, scope='enc_fc3', activation_fn=tf.nn.relu)\n",
    "        self.z_mu = fc(f3, self.n_z, scope='enc_fc4_mu', \n",
    "                       activation_fn=None)\n",
    "        self.z_log_sigma_sq = fc(f3, self.n_z, scope='enc_fc4_sigma', \n",
    "                                 activation_fn=None)\n",
    "        eps = tf.random_normal(shape=tf.shape(self.z_log_sigma_sq),mean=0, stddev=1, dtype=tf.float32)\n",
    "        \n",
    "        self.z = self.z_mu + tf.sqrt(tf.exp(self.z_log_sigma_sq)) * eps\n",
    "\n",
    "        g1 = fc(self.z, 32, scope='dec_fc1', activation_fn=tf.nn.relu)\n",
    "        g2 = fc(g1, 64, scope='dec_fc2', activation_fn=tf.nn.relu)\n",
    "        g3 = fc(g2, 128, scope='dec_fc3', activation_fn=tf.nn.relu)\n",
    "        self.x_hat = fc(g3, input_dim, scope='dec_fc4', activation_fn=tf.sigmoid)\n",
    "        return \n",
    "    \n",
    "\n",
    "    \n",
    "    def myModel(self, model_name=\"vanillaVAE1\",*args):\n",
    "        modelsDic = {\n",
    "             \"vanillaVAE1\": self.vae_arc_all(*args),\n",
    "             \"vanillaVAE2\": self.vae_arc1(*args)\n",
    "            \n",
    "               }\n",
    "        self.model = modelsDic[model_name]\n",
    "        return self.model\n",
    "        \n",
    "        \n",
    "    @staticmethod\n",
    "    def vae_cell(x, l_name=0):\n",
    "        seq_name = \"sq_\" + str(l_name) + \"_\"\n",
    "      \n",
    "        conv1 = ld.conv_layer(x, 3, 2, 8, seq_name + \"encode_1\")\n",
    "\n",
    "        conv2 = ld.conv_layer(conv1, 3, 1, 8, seq_name +\"encode_2\") \n",
    "\n",
    "        conv3 = ld.conv_layer(conv2, 3, 2, 8, seq_name +\"encode_3\")    \n",
    "\n",
    "        conv4 = tf.layers.Flatten()(conv3)\n",
    "        \n",
    "        conv3_shape = conv3.get_shape().as_list()\n",
    "      \n",
    "        z_mu = ld.fc_layer(conv4, hiddens=16, idx= seq_name + \"enc_fc4_m\")\n",
    "        z_log_sigma_sq = ld.fc_layer(conv4, hiddens=16, idx= seq_name + \"enc_fc4_m\"'enc_fc4_sigma')        \n",
    "        eps = tf.random_normal(shape=tf.shape(z_log_sigma_sq), mean=0, stddev=1, dtype=tf.float32)\n",
    "        z = z_mu + tf.sqrt(tf.exp(z_log_sigma_sq)) * eps\n",
    "      \n",
    "        z2 = ld.fc_layer(z, hiddens = conv3_shape[1] * conv3_shape[2] * conv3_shape[3], idx = seq_name + \"decode_fc1\")\n",
    "\n",
    "        z3 = tf.reshape(z2, [-1, conv3_shape[1], conv3_shape[2], conv3_shape[3]])\n",
    "\n",
    "        conv5 = ld.transpose_conv_layer(z3, 3, 2, 8, seq_name +\"decode_5\") \n",
    "       \n",
    "        conv6 = ld.transpose_conv_layer(z3, 3, 1, 8, seq_name +\"decode_6\") \n",
    "\n",
    "        x_hat = ld.transpose_conv_layer(conv6, 3, 2, 3, seq_name +\"decode_8\")  # set activation to linear\n",
    "\n",
    "        return x_hat, z_mu,z_log_sigma_sq, z\n",
    "    \n",
    "    \n",
    "    \n",
    "    def vae_arc_all(self):\n",
    "        X = []\n",
    "        z_log_sigma_sq_all = []\n",
    "        z_mu_all = []\n",
    "        for i in range(20):\n",
    "            q, z_mu, z_log_sigma_sq, z = VariantionalAutoencoder.vae_cell(self.x[:,i,:,:,:], l_name=i)\n",
    "            X.append(q)\n",
    "            z_log_sigma_sq_all.append(z_log_sigma_sq)\n",
    "            z_mu_all.append(z_mu)\n",
    "        x_hat = tf.stack(X,axis = 1)\n",
    "        z_log_sigma_sq_all = tf.stack(z_log_sigma_sq_all,axis = 1)\n",
    "        z_mu_all = tf.stack(z_mu_all,axis = 1)\n",
    "        print (\"X_hat\",x_hat.shape)\n",
    "        print (\"zlog_sigma_sq_all\",z_log_sigma_sq_all.shape)\n",
    "        return x_hat,z_log_sigma_sq_all,z_mu_all\n",
    "        \n",
    "        \n",
    "    # Build the netowrk and the loss functions\n",
    "    def build(self):\n",
    "        tf.reset_default_graph()\n",
    "        self.train_iterator = make_dataset(type=\"train\")\n",
    "        self.val_iterator = make_dataset(type=\"val\")\n",
    "        self.test_iterator = make_dataset(type=\"test\")\n",
    "        self.x = tf.placeholder(tf.float32, [None,20,64,64,3])\n",
    "        self.global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "        self.increment_global_step = tf.assign_add(self.global_step,1,name = 'increment_global_step')\n",
    "        \n",
    "        #ARCHITECTURE\n",
    "        self.x_hat,self.z_log_sigma_sq,self.z_mu = self.myModel()\n",
    "        #self.x_hat,self.z_log_sigma_sq,self.z_mu = self.vae_arc_all()\n",
    "        # Loss\n",
    "        # Reconstruction loss\n",
    "        # Minimize the cross-entropy loss\n",
    "#         epsilon = 1e-10\n",
    "#         recon_loss = -tf.reduce_sum(\n",
    "#             self.x[:,1:,:,:,:] * tf.log(epsilon+self.x_hat[:,:-1,:,:,:]) + \n",
    "#             (1-self.x[:,1:,:,:,:]) * tf.log(epsilon+1-self.x_hat[:,:-1,:,:,:]), \n",
    "#             axis=1\n",
    "#         )\n",
    "\n",
    "#        self.recon_loss = tf.reduce_mean(recon_loss)\n",
    "        self.recon_loss = tf.reduce_mean(tf.square(self.x[:,1:,:,:,0]  - self.x_hat[:,:-1,:,:,0]))\n",
    "\n",
    "        # Latent loss\n",
    "        # KL divergence: measure the difference between two distributions\n",
    "        # Here we measure the divergence between \n",
    "        # the latent distribution and N(0, 1)\n",
    "        latent_loss = -0.5 * tf.reduce_sum(\n",
    "            1 + self.z_log_sigma_sq - tf.square(self.z_mu) - \n",
    "            tf.exp(self.z_log_sigma_sq), axis=1)\n",
    "        self.latent_loss = tf.reduce_mean(latent_loss)\n",
    "\n",
    "        self.total_loss = self.recon_loss + self.latent_loss\n",
    "        self.train_op = tf.train.AdamOptimizer(\n",
    "            learning_rate=self.learning_rate).minimize(self.total_loss,global_step=self.global_step)\n",
    "        \n",
    "        # Build a saver\n",
    "        self.saver = tf.train.Saver(tf.global_variables())\n",
    "        \n",
    "        self.losses = {\n",
    "            'recon_loss': self.recon_loss,\n",
    "            'latent_loss': self.latent_loss,\n",
    "            'total_loss': self.total_loss,\n",
    "        }      # H(x, x_hat) = -\\Sigma x*log(x_hat) + (1-x)*log(1-x_hat)\n",
    "\n",
    "        \n",
    "        #self.ckpt = tf.train.Checkpoint(model=self.vae_arc2())\n",
    "        #self.manager = tf.train.CheckpointManager(self.ckpt,self.checkpoint_dir,max_to_keep=3)\n",
    "        return\n",
    "\n",
    "    # Execute the forward and the backward pass\n",
    "    def run_single_step(self):\n",
    "        global_step = self.sess.run(self.global_step)\n",
    "        try:\n",
    "            train_batch = self.sess.run(self.train_iterator.get_next())\n",
    "            print(\"Train_batch shape\", train_batch[\"images\"].shape)\n",
    "            x_hat, train_summary, _, train_losses = self.sess.run([self.x_hat, self.summary_op, self.train_op, self.losses], feed_dict={self.x: train_batch[\"images\"]})\n",
    "            self.train_writer.add_summary(train_summary, global_step)\n",
    "            print(\"x_hat.shape\", x_hat.shape)\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print(\"train out of range error\")\n",
    "        \n",
    "        try:\n",
    "            val_batch = self.sess.run(self.val_iterator.get_next())\n",
    "            val_summary, _, val_losses = self.sess.run([self.summary_op,self.train_op, self.losses], feed_dict={self.x: val_batch[\"images\"]})\n",
    "            self.val_writer.add_summary(val_summary, global_step)\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print(\"train out of range error\")\n",
    "        \n",
    "        return train_losses,val_losses\n",
    "\n",
    "    # x -> x_hat\n",
    "    def reconstructor(self, x):\n",
    "        x_hat = self.sess.run(self.x_hat, feed_dict={self.x: x})\n",
    "        return x_hat\n",
    "\n",
    "    # z -> x\n",
    "    def generator(self, z):\n",
    "        x_hat = self.sess.run(self.x_hat, feed_dict={self.z: z})\n",
    "        return x_hat\n",
    "    \n",
    "    \n",
    "    # x -> z\n",
    "    def transformer(self, x):\n",
    "        z = self.sess.run(self.z, feed_dict={self.x: x})\n",
    "        return z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(model_class, learning_rate=1e-4, \n",
    "            batch_size=64, num_epoch=100, n_z=16, log_step=5):\n",
    "    # Create a model    \n",
    "    model = model_class(learning_rate=learning_rate, batch_size=batch_size, n_z=n_z)\n",
    "\n",
    "    # Training loop    \n",
    "    for epoch in range(num_epoch):\n",
    "        start_time = time.time()\n",
    "        # Run an epoch\n",
    "        for iter in range(num_sample // batch_size):\n",
    "            # Get a batch\n",
    "            step = epoch*(num_sample // batch_size) +  iter\n",
    "            train_losses,val_losses = model.run_single_step()\n",
    "            print (\"Train_loss: {}; Val_loss{}\".format(train_losses,val_losses))\n",
    "            checkpoint_path = os.path.join(model.checkpoint_dir, 'model.ckpt')\n",
    "            model.saver.save(model.sess, model.checkpoint_path, global_step =step)\n",
    "        end_time = time.time()\n",
    "        \n",
    "        # Log the loss\n",
    "#         if epoch % log_step == 0:\n",
    "#             log_str = '[Epoch {}] '.format(epoch)\n",
    "#             for k, v in self.recon_loss.items():\n",
    "#                 log_str += '{}: {:.3f}  '.format(k, v)\n",
    "#             log_str += '({:.3f} sec/epoch)'.format(end_time - start_time)\n",
    "#             print(log_str)\n",
    "\n",
    "    print('Done!')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard.notebook\n",
    "%tensorboard --logdir=./ --host localhost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer_and_checkpoint(model_class, learning_rate=1e-4, \n",
    "            batch_size=64, num_epoch=100, n_z=16, log_step=5):\n",
    "    #restore the existing checkpoints  \n",
    "    \n",
    "    model = model_class(learning_rate=learning_rate, batch_size=batch_size, n_z=n_z)\n",
    "    ckpt = tf.train.get_checkpoint_state(model.checkpoint_dir)\n",
    "    \n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "        #Extract from checkpoint filename\n",
    "        global_step = int(os.path.basename(ckpt.model_checkpoint_path).split('-')[1])\n",
    "        sess = tf.Session()\n",
    "        print(\"Restore from {}\".format(ckpt.model_checkpoint_path))\n",
    "        graph = tf.get_default_graph()\n",
    "        saver = tf.train.Saver(tf.global_variables())\n",
    "        #saver = tf.train.import_meta_graph(os.path.join(model.checkpoint_dir,'model.ckpt-{}.meta'.format(global_step)))\n",
    "        saver.restore(sess,tf.train.latest_checkpoint(model.checkpoint_dir))\n",
    "        loaded_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=tf.get_variable_scope().name)\n",
    "        print(\"loaded_vars\",loaded_vars)\n",
    "        \n",
    "##        The following for extract global step does not work, it always reset to 0 \n",
    "#         increment_global_step = graph.get_tensor_by_name(\"increment_global_step:0\").eval()\n",
    "#         other_var = graph.get_tensor_by_name(\"enc_fc1/weights:0\").eval()\n",
    "#         print (\"Recover global step\",increment_global_step)\n",
    "#         print (\"other var\",other_var)\n",
    "    else:\n",
    "        print(\"Initializer from scratch\")\n",
    "        global_step = model.sess.run(model.global_step)\n",
    "    # Training loop    \n",
    "    for epoch in range(num_epoch):\n",
    "        model.sess.run(model.train_iterator.initializer)\n",
    "        model.sess.run(model.val_iterator.initializer)\n",
    "        start_time = time.time()\n",
    "        # Run an epoch\n",
    "        for iter in range(num_sample // batch_size):\n",
    "            # Get a batch\n",
    "            #step = epoch*(num_sample // batch_size) +  iter\n",
    "            print (\"global step\",model.global_step)\n",
    "            train_losses,val_losses = model.run_single_step()\n",
    "            print (\"Train_loss: {}; Val_loss{} for global step {}\".format(train_losses,val_losses,global_step))\n",
    "            checkpoint_path = os.path.join(model.checkpoint_dir, 'model_arc4.ckpt')\n",
    "            model.saver.save(model.sess,checkpoint_path, global_step = global_step)\n",
    "            global_step = global_step  +1\n",
    "        end_time = time.time()\n",
    "        \n",
    "        # Log the loss\n",
    "#         if epoch % log_step == 0:\n",
    "#             log_str = '[Epoch {}] '.format(epoch)\n",
    "#             for k, v in self.recon_lvoss.items():\n",
    "#                 log_str += '{}: {:.3f}  '.format(k, v)\n",
    "#             log_str += '({:.3f} sec/epoch)'.format(end_time - start_time)\n",
    "#             print(log_str)\n",
    "    print('Done!')\n",
    "    return model    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seq=  (?,)\n",
      "dataset <DatasetV1Adapter shapes: OrderedDict([(images, (40, 20, 64, 64, 3))]), types: OrderedDict([(images, tf.float32)])>\n",
      "Seq=  (?,)\n",
      "dataset <DatasetV1Adapter shapes: OrderedDict([(images, (40, 20, 64, 64, 3))]), types: OrderedDict([(images, tf.float32)])>\n",
      "Seq=  (?,)\n",
      "dataset <DatasetV1Adapter shapes: OrderedDict([(images, (40, 20, 64, 64, 3))]), types: OrderedDict([(images, tf.float32)])>\n",
      "DBBUG: INPUT Tensor(\"strided_slice:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 64, 64, 3)\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "Encode 4_shape,  (?, 2048)\n",
      "latend variables z  Tensor(\"add:0\", shape=(?, 16), dtype=float32)\n",
      "latend variables z2  Tensor(\"sq_0_deenc_fc1_fc/Relu:0\", shape=(?, 2048), dtype=float32)\n",
      "latend variables z3  Tensor(\"Reshape:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_0_decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 5 shape (?, 32, 32, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_0_decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 6 shape (?, 64, 64, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_0_decode_8_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "X_hat (?, 64, 64, 3)\n",
      "DBBUG: INPUT Tensor(\"strided_slice_1:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 64, 64, 3)\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "Encode 4_shape,  (?, 2048)\n",
      "latend variables z  Tensor(\"add_1:0\", shape=(?, 16), dtype=float32)\n",
      "latend variables z2  Tensor(\"sq_1_deenc_fc1_fc/Relu:0\", shape=(?, 2048), dtype=float32)\n",
      "latend variables z3  Tensor(\"Reshape_1:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_1_decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 5 shape (?, 32, 32, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_1_decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 6 shape (?, 64, 64, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_1_decode_8_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "X_hat (?, 64, 64, 3)\n",
      "DBBUG: INPUT Tensor(\"strided_slice_2:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 64, 64, 3)\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "Encode 4_shape,  (?, 2048)\n",
      "latend variables z  Tensor(\"add_2:0\", shape=(?, 16), dtype=float32)\n",
      "latend variables z2  Tensor(\"sq_2_deenc_fc1_fc/Relu:0\", shape=(?, 2048), dtype=float32)\n",
      "latend variables z3  Tensor(\"Reshape_2:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_2_decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 5 shape (?, 32, 32, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_2_decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 6 shape (?, 64, 64, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_2_decode_8_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "X_hat (?, 64, 64, 3)\n",
      "DBBUG: INPUT Tensor(\"strided_slice_3:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 64, 64, 3)\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "Encode 4_shape,  (?, 2048)\n",
      "latend variables z  Tensor(\"add_3:0\", shape=(?, 16), dtype=float32)\n",
      "latend variables z2  Tensor(\"sq_3_deenc_fc1_fc/Relu:0\", shape=(?, 2048), dtype=float32)\n",
      "latend variables z3  Tensor(\"Reshape_3:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_3_decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 5 shape (?, 32, 32, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_3_decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 6 shape (?, 64, 64, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_3_decode_8_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "X_hat (?, 64, 64, 3)\n",
      "DBBUG: INPUT Tensor(\"strided_slice_4:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 64, 64, 3)\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "Encode 4_shape,  (?, 2048)\n",
      "latend variables z  Tensor(\"add_4:0\", shape=(?, 16), dtype=float32)\n",
      "latend variables z2  Tensor(\"sq_4_deenc_fc1_fc/Relu:0\", shape=(?, 2048), dtype=float32)\n",
      "latend variables z3  Tensor(\"Reshape_4:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_4_decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 5 shape (?, 32, 32, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_4_decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 6 shape (?, 64, 64, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_4_decode_8_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "X_hat (?, 64, 64, 3)\n",
      "DBBUG: INPUT Tensor(\"strided_slice_5:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 64, 64, 3)\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "Encode 4_shape,  (?, 2048)\n",
      "latend variables z  Tensor(\"add_5:0\", shape=(?, 16), dtype=float32)\n",
      "latend variables z2  Tensor(\"sq_5_deenc_fc1_fc/Relu:0\", shape=(?, 2048), dtype=float32)\n",
      "latend variables z3  Tensor(\"Reshape_5:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_5_decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 5 shape (?, 32, 32, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_5_decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 6 shape (?, 64, 64, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_5_decode_8_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "X_hat (?, 64, 64, 3)\n",
      "DBBUG: INPUT Tensor(\"strided_slice_6:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 64, 64, 3)\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "Encode 4_shape,  (?, 2048)\n",
      "latend variables z  Tensor(\"add_6:0\", shape=(?, 16), dtype=float32)\n",
      "latend variables z2  Tensor(\"sq_6_deenc_fc1_fc/Relu:0\", shape=(?, 2048), dtype=float32)\n",
      "latend variables z3  Tensor(\"Reshape_6:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_6_decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 5 shape (?, 32, 32, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_6_decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 6 shape (?, 64, 64, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_6_decode_8_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "X_hat (?, 64, 64, 3)\n",
      "DBBUG: INPUT Tensor(\"strided_slice_7:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 64, 64, 3)\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "Encode 4_shape,  (?, 2048)\n",
      "latend variables z  Tensor(\"add_7:0\", shape=(?, 16), dtype=float32)\n",
      "latend variables z2  Tensor(\"sq_7_deenc_fc1_fc/Relu:0\", shape=(?, 2048), dtype=float32)\n",
      "latend variables z3  Tensor(\"Reshape_7:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_7_decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 5 shape (?, 32, 32, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_7_decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 6 shape (?, 64, 64, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_7_decode_8_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "X_hat (?, 64, 64, 3)\n",
      "DBBUG: INPUT Tensor(\"strided_slice_8:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 64, 64, 3)\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "Encode 4_shape,  (?, 2048)\n",
      "latend variables z  Tensor(\"add_8:0\", shape=(?, 16), dtype=float32)\n",
      "latend variables z2  Tensor(\"sq_8_deenc_fc1_fc/Relu:0\", shape=(?, 2048), dtype=float32)\n",
      "latend variables z3  Tensor(\"Reshape_8:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_8_decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 5 shape (?, 32, 32, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_8_decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 6 shape (?, 64, 64, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_8_decode_8_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "X_hat (?, 64, 64, 3)\n",
      "DBBUG: INPUT Tensor(\"strided_slice_9:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 64, 64, 3)\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "Encode 4_shape,  (?, 2048)\n",
      "latend variables z  Tensor(\"add_9:0\", shape=(?, 16), dtype=float32)\n",
      "latend variables z2  Tensor(\"sq_9_deenc_fc1_fc/Relu:0\", shape=(?, 2048), dtype=float32)\n",
      "latend variables z3  Tensor(\"Reshape_9:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_9_decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 5 shape (?, 32, 32, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_9_decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 6 shape (?, 64, 64, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_9_decode_8_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "X_hat (?, 64, 64, 3)\n",
      "DBBUG: INPUT Tensor(\"strided_slice_10:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 64, 64, 3)\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "Encode 4_shape,  (?, 2048)\n",
      "latend variables z  Tensor(\"add_10:0\", shape=(?, 16), dtype=float32)\n",
      "latend variables z2  Tensor(\"sq_10_deenc_fc1_fc/Relu:0\", shape=(?, 2048), dtype=float32)\n",
      "latend variables z3  Tensor(\"Reshape_10:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_10_decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 5 shape (?, 32, 32, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_10_decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 6 shape (?, 64, 64, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_10_decode_8_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "X_hat (?, 64, 64, 3)\n",
      "DBBUG: INPUT Tensor(\"strided_slice_11:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 64, 64, 3)\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "Encode 4_shape,  (?, 2048)\n",
      "latend variables z  Tensor(\"add_11:0\", shape=(?, 16), dtype=float32)\n",
      "latend variables z2  Tensor(\"sq_11_deenc_fc1_fc/Relu:0\", shape=(?, 2048), dtype=float32)\n",
      "latend variables z3  Tensor(\"Reshape_11:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_11_decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 5 shape (?, 32, 32, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_11_decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 6 shape (?, 64, 64, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_11_decode_8_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "X_hat (?, 64, 64, 3)\n",
      "DBBUG: INPUT Tensor(\"strided_slice_12:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 64, 64, 3)\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "Encode 4_shape,  (?, 2048)\n",
      "latend variables z  Tensor(\"add_12:0\", shape=(?, 16), dtype=float32)\n",
      "latend variables z2  Tensor(\"sq_12_deenc_fc1_fc/Relu:0\", shape=(?, 2048), dtype=float32)\n",
      "latend variables z3  Tensor(\"Reshape_12:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_12_decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 5 shape (?, 32, 32, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_12_decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 6 shape (?, 64, 64, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_12_decode_8_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "X_hat (?, 64, 64, 3)\n",
      "DBBUG: INPUT Tensor(\"strided_slice_13:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 64, 64, 3)\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "Encode 4_shape,  (?, 2048)\n",
      "latend variables z  Tensor(\"add_13:0\", shape=(?, 16), dtype=float32)\n",
      "latend variables z2  Tensor(\"sq_13_deenc_fc1_fc/Relu:0\", shape=(?, 2048), dtype=float32)\n",
      "latend variables z3  Tensor(\"Reshape_13:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_13_decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 5 shape (?, 32, 32, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_13_decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 6 shape (?, 64, 64, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_13_decode_8_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "X_hat (?, 64, 64, 3)\n",
      "DBBUG: INPUT Tensor(\"strided_slice_14:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 64, 64, 3)\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "Encode 4_shape,  (?, 2048)\n",
      "latend variables z  Tensor(\"add_14:0\", shape=(?, 16), dtype=float32)\n",
      "latend variables z2  Tensor(\"sq_14_deenc_fc1_fc/Relu:0\", shape=(?, 2048), dtype=float32)\n",
      "latend variables z3  Tensor(\"Reshape_14:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_14_decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 5 shape (?, 32, 32, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_14_decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 6 shape (?, 64, 64, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_14_decode_8_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "X_hat (?, 64, 64, 3)\n",
      "DBBUG: INPUT Tensor(\"strided_slice_15:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 64, 64, 3)\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "Encode 4_shape,  (?, 2048)\n",
      "latend variables z  Tensor(\"add_15:0\", shape=(?, 16), dtype=float32)\n",
      "latend variables z2  Tensor(\"sq_15_deenc_fc1_fc/Relu:0\", shape=(?, 2048), dtype=float32)\n",
      "latend variables z3  Tensor(\"Reshape_15:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_15_decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 5 shape (?, 32, 32, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_15_decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 6 shape (?, 64, 64, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_15_decode_8_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "X_hat (?, 64, 64, 3)\n",
      "DBBUG: INPUT Tensor(\"strided_slice_16:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 64, 64, 3)\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "Encode 4_shape,  (?, 2048)\n",
      "latend variables z  Tensor(\"add_16:0\", shape=(?, 16), dtype=float32)\n",
      "latend variables z2  Tensor(\"sq_16_deenc_fc1_fc/Relu:0\", shape=(?, 2048), dtype=float32)\n",
      "latend variables z3  Tensor(\"Reshape_16:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_16_decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 5 shape (?, 32, 32, 8)\n",
      "input_channel 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_shape Tensor(\"sq_16_decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 6 shape (?, 64, 64, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_16_decode_8_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "X_hat (?, 64, 64, 3)\n",
      "DBBUG: INPUT Tensor(\"strided_slice_17:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 64, 64, 3)\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "Encode 4_shape,  (?, 2048)\n",
      "latend variables z  Tensor(\"add_17:0\", shape=(?, 16), dtype=float32)\n",
      "latend variables z2  Tensor(\"sq_17_deenc_fc1_fc/Relu:0\", shape=(?, 2048), dtype=float32)\n",
      "latend variables z3  Tensor(\"Reshape_17:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_17_decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 5 shape (?, 32, 32, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_17_decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 6 shape (?, 64, 64, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_17_decode_8_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "X_hat (?, 64, 64, 3)\n",
      "DBBUG: INPUT Tensor(\"strided_slice_18:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 64, 64, 3)\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "Encode 4_shape,  (?, 2048)\n",
      "latend variables z  Tensor(\"add_18:0\", shape=(?, 16), dtype=float32)\n",
      "latend variables z2  Tensor(\"sq_18_deenc_fc1_fc/Relu:0\", shape=(?, 2048), dtype=float32)\n",
      "latend variables z3  Tensor(\"Reshape_18:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_18_decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 5 shape (?, 32, 32, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_18_decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 6 shape (?, 64, 64, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_18_decode_8_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "X_hat (?, 64, 64, 3)\n",
      "DBBUG: INPUT Tensor(\"strided_slice_19:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 64, 64, 3)\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "Encode 4_shape,  (?, 2048)\n",
      "latend variables z  Tensor(\"add_19:0\", shape=(?, 16), dtype=float32)\n",
      "latend variables z2  Tensor(\"sq_19_deenc_fc1_fc/Relu:0\", shape=(?, 2048), dtype=float32)\n",
      "latend variables z3  Tensor(\"Reshape_19:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_19_decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 5 shape (?, 32, 32, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_19_decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 6 shape (?, 64, 64, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_19_decode_8_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "X_hat (?, 64, 64, 3)\n",
      "X_hat (?, 20, 64, 64, 3)\n",
      "zlog_sigma_sq_all (?, 20, 16)\n",
      "WARNING:tensorflow:From /Users/gongbing/anaconda3/envs/GAN_practice/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Initializer from scratch\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.2406425, 'latent_loss': 0.52947295, 'total_loss': 0.77011544}; Val_loss{'recon_loss': 0.2302794, 'latent_loss': 0.42039537, 'total_loss': 0.65067476} for global step 0\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.25737196, 'latent_loss': 0.33428398, 'total_loss': 0.59165597}; Val_loss{'recon_loss': 0.2459262, 'latent_loss': 0.26677513, 'total_loss': 0.51270133} for global step 1\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.25517488, 'latent_loss': 0.21426196, 'total_loss': 0.46943682}; Val_loss{'recon_loss': 0.24418393, 'latent_loss': 0.17355861, 'total_loss': 0.41774255} for global step 2\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.1916578, 'latent_loss': 0.14252253, 'total_loss': 0.33418033}; Val_loss{'recon_loss': 0.22870317, 'latent_loss': 0.11885917, 'total_loss': 0.34756234} for global step 3\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.17507748, 'latent_loss': 0.100495875, 'total_loss': 0.27557337}; Val_loss{'recon_loss': 0.2249494, 'latent_loss': 0.08613758, 'total_loss': 0.31108698} for global step 4\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.17649183, 'latent_loss': 0.074972905, 'total_loss': 0.25146472}; Val_loss{'recon_loss': 0.22696663, 'latent_loss': 0.066217445, 'total_loss': 0.29318407} for global step 5\n",
      "WARNING:tensorflow:From /Users/gongbing/anaconda3/envs/GAN_practice/lib/python3.6/site-packages/tensorflow/python/training/saver.py:966: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.16930845, 'latent_loss': 0.059277494, 'total_loss': 0.22858594}; Val_loss{'recon_loss': 0.2456995, 'latent_loss': 0.05376308, 'total_loss': 0.2994626} for global step 6\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.16248302, 'latent_loss': 0.049387455, 'total_loss': 0.21187048}; Val_loss{'recon_loss': 0.26152337, 'latent_loss': 0.04588562, 'total_loss': 0.307409} for global step 7\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.15574743, 'latent_loss': 0.043018203, 'total_loss': 0.19876564}; Val_loss{'recon_loss': 0.27248022, 'latent_loss': 0.040603522, 'total_loss': 0.31308374} for global step 8\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.18391122, 'latent_loss': 0.038518745, 'total_loss': 0.22242996}; Val_loss{'recon_loss': 0.26045674, 'latent_loss': 0.036693696, 'total_loss': 0.29715043} for global step 9\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.24359523, 'latent_loss': 0.03508543, 'total_loss': 0.27868065}; Val_loss{'recon_loss': 0.24787962, 'latent_loss': 0.033659708, 'total_loss': 0.28153932} for global step 10\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.25610277, 'latent_loss': 0.0323809, 'total_loss': 0.28848368}; Val_loss{'recon_loss': 0.26781628, 'latent_loss': 0.031213652, 'total_loss': 0.29902992} for global step 11\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.24901333, 'latent_loss': 0.030147057, 'total_loss': 0.27916038}; Val_loss{'recon_loss': 0.25502533, 'latent_loss': 0.029172733, 'total_loss': 0.28419805} for global step 12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.15605575, 'latent_loss': 0.028286522, 'total_loss': 0.18434227}; Val_loss{'recon_loss': 0.20409034, 'latent_loss': 0.027481016, 'total_loss': 0.23157136} for global step 13\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.16299914, 'latent_loss': 0.026754523, 'total_loss': 0.18975367}; Val_loss{'recon_loss': 0.21124908, 'latent_loss': 0.026097376, 'total_loss': 0.23734646} for global step 14\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.166142, 'latent_loss': 0.0255006, 'total_loss': 0.1916426}; Val_loss{'recon_loss': 0.21676363, 'latent_loss': 0.02495693, 'total_loss': 0.24172056} for global step 15\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.17143832, 'latent_loss': 0.024465255, 'total_loss': 0.19590357}; Val_loss{'recon_loss': 0.2603185, 'latent_loss': 0.02401729, 'total_loss': 0.2843358} for global step 16\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.18260406, 'latent_loss': 0.023613203, 'total_loss': 0.20621726}; Val_loss{'recon_loss': 0.2616745, 'latent_loss': 0.023246208, 'total_loss': 0.2849207} for global step 17\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.18387714, 'latent_loss': 0.022916144, 'total_loss': 0.20679328}; Val_loss{'recon_loss': 0.2492336, 'latent_loss': 0.022614244, 'total_loss': 0.27184784} for global step 18\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.14615408, 'latent_loss': 0.022343755, 'total_loss': 0.16849783}; Val_loss{'recon_loss': 0.22621004, 'latent_loss': 0.022097494, 'total_loss': 0.24830754} for global step 19\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.13612488, 'latent_loss': 0.02188017, 'total_loss': 0.15800504}; Val_loss{'recon_loss': 0.21062417, 'latent_loss': 0.021683548, 'total_loss': 0.23230772} for global step 20\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.1340019, 'latent_loss': 0.021512274, 'total_loss': 0.15551417}; Val_loss{'recon_loss': 0.20682614, 'latent_loss': 0.021358673, 'total_loss': 0.2281848} for global step 21\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.14553499, 'latent_loss': 0.021225207, 'total_loss': 0.1667602}; Val_loss{'recon_loss': 0.24026462, 'latent_loss': 0.021104703, 'total_loss': 0.26136932} for global step 22\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.23107128, 'latent_loss': 0.021000382, 'total_loss': 0.25207165}; Val_loss{'recon_loss': 0.22091617, 'latent_loss': 0.020908285, 'total_loss': 0.24182445} for global step 23\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.2476797, 'latent_loss': 0.020826463, 'total_loss': 0.26850617}; Val_loss{'recon_loss': 0.2364594, 'latent_loss': 0.02075466, 'total_loss': 0.25721407} for global step 24\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.24550079, 'latent_loss': 0.02069104, 'total_loss': 0.26619184}; Val_loss{'recon_loss': 0.234701, 'latent_loss': 0.020635013, 'total_loss': 0.25533602} for global step 25\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.18327749, 'latent_loss': 0.02058611, 'total_loss': 0.20386359}; Val_loss{'recon_loss': 0.21954234, 'latent_loss': 0.02054207, 'total_loss': 0.24008441} for global step 26\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.16708606, 'latent_loss': 0.020504024, 'total_loss': 0.18759009}; Val_loss{'recon_loss': 0.2159607, 'latent_loss': 0.020469382, 'total_loss': 0.23643008} for global step 27\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.1684557, 'latent_loss': 0.020438608, 'total_loss': 0.18889432}; Val_loss{'recon_loss': 0.21801347, 'latent_loss': 0.020409428, 'total_loss': 0.2384229} for global step 28\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.16164422, 'latent_loss': 0.02038332, 'total_loss': 0.18202755}; Val_loss{'recon_loss': 0.23642553, 'latent_loss': 0.020358318, 'total_loss': 0.25678384} for global step 29\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.15493463, 'latent_loss': 0.020335972, 'total_loss': 0.1752706}; Val_loss{'recon_loss': 0.2521311, 'latent_loss': 0.020314077, 'total_loss': 0.27244517} for global step 30\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.14842018, 'latent_loss': 0.020294372, 'total_loss': 0.16871455}; Val_loss{'recon_loss': 0.2628784, 'latent_loss': 0.020274604, 'total_loss': 0.283153} for global step 31\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gongbing/anaconda3/envs/GAN_practice/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py:408: UserWarning: An unusually high number of `Iterator.get_next()` calls was detected. This often indicates that `Iterator.get_next()` is being called inside a training loop, which will cause gradual slowdown and eventual resource exhaustion. If this is the case, restructure your code to call `next_element = iterator.get_next()` once outside the loop, and use `next_element` as the input to some computation that is invoked inside the loop.\n",
      "  warnings.warn(GET_NEXT_CALL_WARNING_MESSAGE)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.17607036, 'latent_loss': 0.020256463, 'total_loss': 0.19632682}; Val_loss{'recon_loss': 0.2511554, 'latent_loss': 0.020238405, 'total_loss': 0.2713938} for global step 32\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.2345577, 'latent_loss': 0.020221315, 'total_loss': 0.254779}; Val_loss{'recon_loss': 0.23887496, 'latent_loss': 0.020204674, 'total_loss': 0.25907964} for global step 33\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.2470242, 'latent_loss': 0.020188458, 'total_loss': 0.26721266}; Val_loss{'recon_loss': 0.25845352, 'latent_loss': 0.02017264, 'total_loss': 0.27862614} for global step 34\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.24002351, 'latent_loss': 0.020157155, 'total_loss': 0.26018065}; Val_loss{'recon_loss': 0.24599473, 'latent_loss': 0.020141885, 'total_loss': 0.26613662} for global step 35\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.14895828, 'latent_loss': 0.02012697, 'total_loss': 0.16908525}; Val_loss{'recon_loss': 0.19597562, 'latent_loss': 0.020112047, 'total_loss': 0.21608767} for global step 36\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.15582319, 'latent_loss': 0.020097375, 'total_loss': 0.17592056}; Val_loss{'recon_loss': 0.20299883, 'latent_loss': 0.020082789, 'total_loss': 0.22308162} for global step 37\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.1588259, 'latent_loss': 0.020068277, 'total_loss': 0.17889418}; Val_loss{'recon_loss': 0.20852952, 'latent_loss': 0.020053763, 'total_loss': 0.22858328} for global step 38\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.16415699, 'latent_loss': 0.02003928, 'total_loss': 0.18419626}; Val_loss{'recon_loss': 0.25140518, 'latent_loss': 0.020024788, 'total_loss': 0.27142996} for global step 39\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.17503875, 'latent_loss': 0.020010328, 'total_loss': 0.19504908}; Val_loss{'recon_loss': 0.25270233, 'latent_loss': 0.019995863, 'total_loss': 0.2726982} for global step 40\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.17640635, 'latent_loss': 0.019981405, 'total_loss': 0.19638775}; Val_loss{'recon_loss': 0.24056187, 'latent_loss': 0.019966962, 'total_loss': 0.26052883} for global step 41\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.13968155, 'latent_loss': 0.01995253, 'total_loss': 0.15963408}; Val_loss{'recon_loss': 0.21796447, 'latent_loss': 0.019938108, 'total_loss': 0.23790258} for global step 42\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.12999113, 'latent_loss': 0.019923693, 'total_loss': 0.14991482}; Val_loss{'recon_loss': 0.20264627, 'latent_loss': 0.019909296, 'total_loss': 0.22255556} for global step 43\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.12798932, 'latent_loss': 0.01989491, 'total_loss': 0.14788423}; Val_loss{'recon_loss': 0.19904836, 'latent_loss': 0.019880528, 'total_loss': 0.21892889} for global step 44\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n",
      "Train_loss: {'recon_loss': 0.13915493, 'latent_loss': 0.019866157, 'total_loss': 0.15902108}; Val_loss{'recon_loss': 0.23198405, 'latent_loss': 0.019851778, 'total_loss': 0.25183582} for global step 45\n",
      "global step <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "Train_batch shape (40, 20, 64, 64, 3)\n",
      "x_hat.shape (40, 20, 64, 64, 3)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-cb3ff0ef0cab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_vae2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer_and_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariantionalAutoencoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-8382d8a88c36>\u001b[0m in \u001b[0;36mtrainer_and_checkpoint\u001b[0;34m(model_class, learning_rate, batch_size, num_epoch, n_z, log_step)\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;31m#step = epoch*(num_sample // batch_size) +  iter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"global step\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_single_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m             \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Train_loss: {}; Val_loss{} for global step {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_losses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mcheckpoint_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model_arc4.ckpt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-cc3194b18491>\u001b[0m in \u001b[0;36mrun_single_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0mval_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m             \u001b[0mval_summary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"images\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_summary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/GAN_practice/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/GAN_practice/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/GAN_practice/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/GAN_practice/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/GAN_practice/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/GAN_practice/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_vae2 = trainer_and_checkpoint(VariantionalAutoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seq=  (?,)\n",
      "dataset <DatasetV1Adapter shapes: OrderedDict([(images, (40, 20, 64, 64, 3))]), types: OrderedDict([(images, tf.float32)])>\n",
      "Seq=  (?,)\n",
      "dataset <DatasetV1Adapter shapes: OrderedDict([(images, (40, 20, 64, 64, 3))]), types: OrderedDict([(images, tf.float32)])>\n",
      "Seq=  (?,)\n",
      "dataset <DatasetV1Adapter shapes: OrderedDict([(images, (40, 20, 64, 64, 3))]), types: OrderedDict([(images, tf.float32)])>\n",
      "DBBUG: INPUT Tensor(\"strided_slice:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 64, 64, 3)\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "Encode 4_shape,  (?, 2048)\n",
      "latend variables z  Tensor(\"add:0\", shape=(?, 16), dtype=float32)\n",
      "latend variables z2  Tensor(\"sq_0_deenc_fc1_fc/Relu:0\", shape=(?, 2048), dtype=float32)\n",
      "latend variables z3  Tensor(\"Reshape:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_0_decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 5 shape (?, 32, 32, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_0_decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 6 shape (?, 64, 64, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_0_decode_8_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "X_hat (?, 64, 64, 3)\n",
      "DBBUG: INPUT Tensor(\"strided_slice_1:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 64, 64, 3)\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "Encode 4_shape,  (?, 2048)\n",
      "latend variables z  Tensor(\"add_1:0\", shape=(?, 16), dtype=float32)\n",
      "latend variables z2  Tensor(\"sq_1_deenc_fc1_fc/Relu:0\", shape=(?, 2048), dtype=float32)\n",
      "latend variables z3  Tensor(\"Reshape_1:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_1_decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 5 shape (?, 32, 32, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_1_decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 6 shape (?, 64, 64, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_1_decode_8_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "X_hat (?, 64, 64, 3)\n",
      "DBBUG: INPUT Tensor(\"strided_slice_2:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 64, 64, 3)\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "Encode 4_shape,  (?, 2048)\n",
      "latend variables z  Tensor(\"add_2:0\", shape=(?, 16), dtype=float32)\n",
      "latend variables z2  Tensor(\"sq_2_deenc_fc1_fc/Relu:0\", shape=(?, 2048), dtype=float32)\n",
      "latend variables z3  Tensor(\"Reshape_2:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_2_decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 5 shape (?, 32, 32, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_2_decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 6 shape (?, 64, 64, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_2_decode_8_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "X_hat (?, 64, 64, 3)\n",
      "DBBUG: INPUT Tensor(\"strided_slice_3:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 64, 64, 3)\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "Encode 4_shape,  (?, 2048)\n",
      "latend variables z  Tensor(\"add_3:0\", shape=(?, 16), dtype=float32)\n",
      "latend variables z2  Tensor(\"sq_3_deenc_fc1_fc/Relu:0\", shape=(?, 2048), dtype=float32)\n",
      "latend variables z3  Tensor(\"Reshape_3:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_3_decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 5 shape (?, 32, 32, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_3_decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 6 shape (?, 64, 64, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_3_decode_8_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "X_hat (?, 64, 64, 3)\n",
      "DBBUG: INPUT Tensor(\"strided_slice_4:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 64, 64, 3)\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "Encode 4_shape,  (?, 2048)\n",
      "latend variables z  Tensor(\"add_4:0\", shape=(?, 16), dtype=float32)\n",
      "latend variables z2  Tensor(\"sq_4_deenc_fc1_fc/Relu:0\", shape=(?, 2048), dtype=float32)\n",
      "latend variables z3  Tensor(\"Reshape_4:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_4_decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 5 shape (?, 32, 32, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_4_decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 6 shape (?, 64, 64, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_4_decode_8_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "X_hat (?, 64, 64, 3)\n",
      "DBBUG: INPUT Tensor(\"strided_slice_5:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 64, 64, 3)\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "Encode 4_shape,  (?, 2048)\n",
      "latend variables z  Tensor(\"add_5:0\", shape=(?, 16), dtype=float32)\n",
      "latend variables z2  Tensor(\"sq_5_deenc_fc1_fc/Relu:0\", shape=(?, 2048), dtype=float32)\n",
      "latend variables z3  Tensor(\"Reshape_5:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_5_decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 5 shape (?, 32, 32, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_5_decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 6 shape (?, 64, 64, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_5_decode_8_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "X_hat (?, 64, 64, 3)\n",
      "DBBUG: INPUT Tensor(\"strided_slice_6:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 64, 64, 3)\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "Encode 4_shape,  (?, 2048)\n",
      "latend variables z  Tensor(\"add_6:0\", shape=(?, 16), dtype=float32)\n",
      "latend variables z2  Tensor(\"sq_6_deenc_fc1_fc/Relu:0\", shape=(?, 2048), dtype=float32)\n",
      "latend variables z3  Tensor(\"Reshape_6:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_6_decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 5 shape (?, 32, 32, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_6_decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 6 shape (?, 64, 64, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_6_decode_8_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "X_hat (?, 64, 64, 3)\n",
      "DBBUG: INPUT Tensor(\"strided_slice_7:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 64, 64, 3)\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "Encode 4_shape,  (?, 2048)\n",
      "latend variables z  Tensor(\"add_7:0\", shape=(?, 16), dtype=float32)\n",
      "latend variables z2  Tensor(\"sq_7_deenc_fc1_fc/Relu:0\", shape=(?, 2048), dtype=float32)\n",
      "latend variables z3  Tensor(\"Reshape_7:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_7_decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 5 shape (?, 32, 32, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_7_decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 6 shape (?, 64, 64, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_7_decode_8_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "X_hat (?, 64, 64, 3)\n",
      "DBBUG: INPUT Tensor(\"strided_slice_8:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 64, 64, 3)\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "Encode 4_shape,  (?, 2048)\n",
      "latend variables z  Tensor(\"add_8:0\", shape=(?, 16), dtype=float32)\n",
      "latend variables z2  Tensor(\"sq_8_deenc_fc1_fc/Relu:0\", shape=(?, 2048), dtype=float32)\n",
      "latend variables z3  Tensor(\"Reshape_8:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_8_decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 5 shape (?, 32, 32, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_8_decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 6 shape (?, 64, 64, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_8_decode_8_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "X_hat (?, 64, 64, 3)\n",
      "DBBUG: INPUT Tensor(\"strided_slice_9:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 64, 64, 3)\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "Encode 4_shape,  (?, 2048)\n",
      "latend variables z  Tensor(\"add_9:0\", shape=(?, 16), dtype=float32)\n",
      "latend variables z2  Tensor(\"sq_9_deenc_fc1_fc/Relu:0\", shape=(?, 2048), dtype=float32)\n",
      "latend variables z3  Tensor(\"Reshape_9:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_9_decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 5 shape (?, 32, 32, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_9_decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 6 shape (?, 64, 64, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_9_decode_8_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "X_hat (?, 64, 64, 3)\n",
      "DBBUG: INPUT Tensor(\"strided_slice_10:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 64, 64, 3)\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "Encode 4_shape,  (?, 2048)\n",
      "latend variables z  Tensor(\"add_10:0\", shape=(?, 16), dtype=float32)\n",
      "latend variables z2  Tensor(\"sq_10_deenc_fc1_fc/Relu:0\", shape=(?, 2048), dtype=float32)\n",
      "latend variables z3  Tensor(\"Reshape_10:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_10_decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 5 shape (?, 32, 32, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_10_decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 6 shape (?, 64, 64, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_10_decode_8_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "X_hat (?, 64, 64, 3)\n",
      "DBBUG: INPUT Tensor(\"strided_slice_11:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 64, 64, 3)\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "Encode 4_shape,  (?, 2048)\n",
      "latend variables z  Tensor(\"add_11:0\", shape=(?, 16), dtype=float32)\n",
      "latend variables z2  Tensor(\"sq_11_deenc_fc1_fc/Relu:0\", shape=(?, 2048), dtype=float32)\n",
      "latend variables z3  Tensor(\"Reshape_11:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_11_decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 5 shape (?, 32, 32, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_11_decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 6 shape (?, 64, 64, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_11_decode_8_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "X_hat (?, 64, 64, 3)\n",
      "DBBUG: INPUT Tensor(\"strided_slice_12:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 64, 64, 3)\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "Encode 4_shape,  (?, 2048)\n",
      "latend variables z  Tensor(\"add_12:0\", shape=(?, 16), dtype=float32)\n",
      "latend variables z2  Tensor(\"sq_12_deenc_fc1_fc/Relu:0\", shape=(?, 2048), dtype=float32)\n",
      "latend variables z3  Tensor(\"Reshape_12:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_12_decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 5 shape (?, 32, 32, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_12_decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 6 shape (?, 64, 64, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_12_decode_8_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "X_hat (?, 64, 64, 3)\n",
      "DBBUG: INPUT Tensor(\"strided_slice_13:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 64, 64, 3)\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "Encode 4_shape,  (?, 2048)\n",
      "latend variables z  Tensor(\"add_13:0\", shape=(?, 16), dtype=float32)\n",
      "latend variables z2  Tensor(\"sq_13_deenc_fc1_fc/Relu:0\", shape=(?, 2048), dtype=float32)\n",
      "latend variables z3  Tensor(\"Reshape_13:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_13_decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 5 shape (?, 32, 32, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_13_decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 6 shape (?, 64, 64, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_13_decode_8_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "X_hat (?, 64, 64, 3)\n",
      "DBBUG: INPUT Tensor(\"strided_slice_14:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 64, 64, 3)\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "Encode 4_shape,  (?, 2048)\n",
      "latend variables z  Tensor(\"add_14:0\", shape=(?, 16), dtype=float32)\n",
      "latend variables z2  Tensor(\"sq_14_deenc_fc1_fc/Relu:0\", shape=(?, 2048), dtype=float32)\n",
      "latend variables z3  Tensor(\"Reshape_14:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_14_decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 5 shape (?, 32, 32, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_14_decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 6 shape (?, 64, 64, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_14_decode_8_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "X_hat (?, 64, 64, 3)\n",
      "DBBUG: INPUT Tensor(\"strided_slice_15:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 64, 64, 3)\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "Encode 4_shape,  (?, 2048)\n",
      "latend variables z  Tensor(\"add_15:0\", shape=(?, 16), dtype=float32)\n",
      "latend variables z2  Tensor(\"sq_15_deenc_fc1_fc/Relu:0\", shape=(?, 2048), dtype=float32)\n",
      "latend variables z3  Tensor(\"Reshape_15:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_15_decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 5 shape (?, 32, 32, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_15_decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 6 shape (?, 64, 64, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_15_decode_8_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "X_hat (?, 64, 64, 3)\n",
      "DBBUG: INPUT Tensor(\"strided_slice_16:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 64, 64, 3)\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "Encode 4_shape,  (?, 2048)\n",
      "latend variables z  Tensor(\"add_16:0\", shape=(?, 16), dtype=float32)\n",
      "latend variables z2  Tensor(\"sq_16_deenc_fc1_fc/Relu:0\", shape=(?, 2048), dtype=float32)\n",
      "latend variables z3  Tensor(\"Reshape_16:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_16_decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 5 shape (?, 32, 32, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_16_decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 6 shape (?, 64, 64, 8)\n",
      "input_channel 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_shape Tensor(\"sq_16_decode_8_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "X_hat (?, 64, 64, 3)\n",
      "DBBUG: INPUT Tensor(\"strided_slice_17:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 64, 64, 3)\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "Encode 4_shape,  (?, 2048)\n",
      "latend variables z  Tensor(\"add_17:0\", shape=(?, 16), dtype=float32)\n",
      "latend variables z2  Tensor(\"sq_17_deenc_fc1_fc/Relu:0\", shape=(?, 2048), dtype=float32)\n",
      "latend variables z3  Tensor(\"Reshape_17:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_17_decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 5 shape (?, 32, 32, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_17_decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 6 shape (?, 64, 64, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_17_decode_8_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "X_hat (?, 64, 64, 3)\n",
      "DBBUG: INPUT Tensor(\"strided_slice_18:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 64, 64, 3)\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "Encode 4_shape,  (?, 2048)\n",
      "latend variables z  Tensor(\"add_18:0\", shape=(?, 16), dtype=float32)\n",
      "latend variables z2  Tensor(\"sq_18_deenc_fc1_fc/Relu:0\", shape=(?, 2048), dtype=float32)\n",
      "latend variables z3  Tensor(\"Reshape_18:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_18_decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 5 shape (?, 32, 32, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_18_decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 6 shape (?, 64, 64, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_18_decode_8_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "X_hat (?, 64, 64, 3)\n",
      "DBBUG: INPUT Tensor(\"strided_slice_19:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 64, 64, 3)\n",
      "Encode_1_shape (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 2_shape, (?, 32, 32, 8)\n",
      "conv_layer activation function relu\n",
      "DEBUG input shape (?, 32, 32, 8)\n",
      "Encode 3_shape,  (?, 16, 16, 8)\n",
      "Encode 4_shape,  (?, 2048)\n",
      "latend variables z  Tensor(\"add_19:0\", shape=(?, 16), dtype=float32)\n",
      "latend variables z2  Tensor(\"sq_19_deenc_fc1_fc/Relu:0\", shape=(?, 2048), dtype=float32)\n",
      "latend variables z3  Tensor(\"Reshape_19:0\", shape=(?, 16, 16, 8), dtype=float32)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_19_decode_5_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 5 shape (?, 32, 32, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_19_decode_6_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "Decode 6 shape (?, 64, 64, 8)\n",
      "input_channel 8\n",
      "output_shape Tensor(\"sq_19_decode_8_trans_conv/stack:0\", shape=(4,), dtype=int32)\n",
      "X_hat (?, 64, 64, 3)\n",
      "X_hat (?, 20, 64, 64, 3)\n",
      "zlog_sigma_sq_all (?, 20, 16)\n",
      "INFO:tensorflow:Restoring parameters from VAE/checkpoint/model_arc4.ckpt-87\n",
      "Seq=  (?,)\n",
      "dataset <DatasetV1Adapter shapes: OrderedDict([(images, (40, 20, 64, 64, 3))]), types: OrderedDict([(images, tf.float32)])>\n",
      "recon_loss 0.1198711\n",
      "real_image (20, 64, 64, 3)\n",
      "predic image (20, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "#def model_prediction():\n",
    "model = VariantionalAutoencoder(learning_rate=1e-4, batch_size=64, n_z=16)\n",
    "ckpt = tf.train.get_checkpoint_state(model.checkpoint_dir)\n",
    "global_step = int(os.path.basename(ckpt.model_checkpoint_path).split('-')[1])\n",
    "#First let's load meta graph and restore weights\n",
    "sess = tf.Session()  \n",
    "saver = tf.train.Saver(tf.global_variables())\n",
    "saver.restore(sess,tf.train.latest_checkpoint(model.checkpoint_dir))\n",
    "#latest_checkpoints = saver.restore(sess,tf.train.latest_checkpoint('./'))\n",
    "graph = tf.get_default_graph()\n",
    "#op = sess.graph.get_operations()\n",
    "#graph.get_tensor_by_name(\"dec_fc4\")\n",
    "loaded_vars = tf.trainable_variables() \n",
    "#loaded_vars\n",
    "#op_to_restore = graph.get_tensor_by_name(\"dec_fc4/biases:0\")\n",
    "test_iterator = make_dataset(type=\"test\")\n",
    "sess.run(test_iterator.initializer)\n",
    "for i in range(1):\n",
    "    test_batch = sess.run(test_iterator.get_next())\n",
    "    # print(\"test_batch\",test_batch[\"images\"].shape)\n",
    "    #op_to_restore.eval(feed_dict={model.x: test_batch[\"images\"]})\n",
    "    predict_images,  recon_loss = sess.run([model.x_hat, model.recon_loss], feed_dict={model.x: test_batch[\"images\"]})\n",
    "    #plot real and predicted images\n",
    "    real_img = test_batch[\"images\"][0]\n",
    "    pred_img = predict_images[0]\n",
    "    #plt.figure(figsize=(8, 8))\n",
    "    #plt.imshow(real_img[0])\n",
    "    print(\"recon_loss\",recon_loss)\n",
    "    print(\"real_image\",real_img.shape)\n",
    "    print(\"predic image\", pred_img.shape)\n",
    "#https://jhui.github.io/2017/03/08/TensorFlow-variable-sharing/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(real_img[0][:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(pred_img[0][:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18,6))\n",
    "    gs = gridspec.GridSpec(1, 10)\n",
    "    gs.update(wspace = 0., hspace = 0.)\n",
    "    ts = [0,5,9,10,12,14,16,18,19]\n",
    "    xlables = [round(i,2) for i in list(np.linspace(np.min(lon),np.max(lon),5))]\n",
    "    ylabels = [round(i,2) for i  in list(np.linspace(np.max(lat),np.min(lat),5))] \n",
    "    for t in range(len(ts)):\n",
    "        #if t==0 : ax1=plt.subplot(gs[t])\n",
    "        ax1 = plt.subplot(gs[t])\n",
    "        input_image = input_images_[ts[t], :, :, 0] * (321.46630859375 - 235.2141571044922) + 235.2141571044922\n",
    "        plt.imshow(input_image, cmap = 'jet', vmin=270, vmax=300)\n",
    "        ax1.title.set_text(\"t = \" + str(ts[t]+1))\n",
    "        plt.setp([ax1], xticks = [], xticklabels = [], yticks = [], yticklabels = [])\n",
    "        if t == 0:\n",
    "            plt.setp([ax1], xticks = list(np.linspace(0, 64, 3)), xticklabels = xlables, yticks = list(np.linspace(0, 64, 3)), yticklabels = ylabels)\n",
    "            plt.ylabel(\"Ground Truth\", fontsize=10)\n",
    "    plt.savefig(os.path.join(args.output_png_dir, \"Ground_Truth_Sample_\" + str(name) + \".jpg\"))\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-bdb6a8305b7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_img\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(real_img[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(real_img).shape"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
