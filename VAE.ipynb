{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial from https://github.com/shaohua0116/VAE-Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gongbing/anaconda3/envs/GAN_practice/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/gongbing/anaconda3/envs/GAN_practice/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/gongbing/anaconda3/envs/GAN_practice/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/gongbing/anaconda3/envs/GAN_practice/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/gongbing/anaconda3/envs/GAN_practice/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/gongbing/anaconda3/envs/GAN_practice/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'layer_def' from '/Users/gongbing/PycharmProjects/GAN_practice/layer_def.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import importlib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.slim import fully_connected as fc\n",
    "import matplotlib.pyplot as plt \n",
    "import glob\n",
    "from collections import OrderedDict\n",
    "%matplotlib inline\n",
    "from datetime import datetime\n",
    "import os\n",
    "from pathlib import Path\n",
    "import layer_def as ld\n",
    "importlib.reload(ld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = \"/Users/gongbing/PycharmProjects/video_prediction_savp/data/era5_size_64_64_3_3t_norm/train\"\n",
    "test_files = \"/Users/gongbing/PycharmProjects/video_prediction_savp/data/era5_size_64_64_3_3t_norm/test\"\n",
    "val_files = \"/Users/gongbing/PycharmProjects/video_prediction_savp/data/era5_size_64_64_3_3t_norm/train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "batch_size=40\n",
    "input_dim=3\n",
    "num_sample = 1500\n",
    "def make_dataset(type=\"train\"):\n",
    "    if type==\"train\": filenames = glob.glob(\"/Users/gongbing/PycharmProjects/video_prediction_savp/data/era5_size_64_64_3_3t_norm/train/*.tfrecords\")\n",
    "    if type==\"val\":filenames = glob.glob(\"/Users/gongbing/PycharmProjects/video_prediction_savp/data/era5_size_64_64_3_3t_norm/val/*.tfrecords\")\n",
    "    if type==\"test\":filenames = glob.glob(\"/Users/gongbing/PycharmProjects/video_prediction_savp/data/era5_size_64_64_3_3t_norm/test/*.tfrecords\")\n",
    "    \n",
    "    def parser(serialized_example):\n",
    "            seqs = OrderedDict()\n",
    "            keys_to_features = {\n",
    "                # 'width': tf.FixedLenFeature([], tf.int64),\n",
    "                # 'height': tf.FixedLenFeature([], tf.int64),\n",
    "                'sequence_length': tf.FixedLenFeature([], tf.int64),\n",
    "                # 'channels': tf.FixedLenFeature([],tf.int64),\n",
    "                # 'images/encoded':  tf.FixedLenFeature([], tf.string)\n",
    "                'images/encoded': tf.VarLenFeature(tf.float32)\n",
    "            }\n",
    "            parsed_features = tf.parse_single_example(serialized_example, keys_to_features)\n",
    "            seq = tf.sparse_tensor_to_dense(parsed_features[\"images/encoded\"])\n",
    "            print(\"Seq= \",seq.shape)\n",
    "            images = tf.reshape(seq, [20,64, 64,3], name = \"reshape_new\")\n",
    "            seqs[\"images\"] = images\n",
    "            return seqs\n",
    "    dataset = tf.data.TFRecordDataset(filenames, buffer_size = 8 * 1024 * 1024)\n",
    "    dataset = dataset.repeat(num_epochs)\n",
    "    dataset = dataset.apply(tf.contrib.data.map_and_batch(\n",
    "            parser, batch_size, drop_remainder = True, num_parallel_calls = None))\n",
    "\n",
    "\n",
    "\n",
    "    iterator = dataset.make_initializable_iterator()\n",
    "    return iterator\n",
    "\n",
    "class VariantionalAutoencoder(object):\n",
    "\n",
    "    def __init__(self, learning_rate=1e-4, batch_size=64, n_z=16):\n",
    "        # Set hyperparameters\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.n_z = n_z\n",
    "        # Build the graph\n",
    "        self.build()\n",
    "        # Initialize paramters\n",
    "        self.sess = tf.InteractiveSession()\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        # Summary op\n",
    "        self.loss_summary = tf.summary.scalar(\"recon_losses\", self.recon_loss)\n",
    "        self.loss_summary = tf.summary.scalar(\"latent_losses\", self.latent_loss)\n",
    "        self.summary_op = tf.summary.merge_all()\n",
    "        self.summary_dir = \"./\"\n",
    "        self.base_dir = \"VAE\"\n",
    "        self.checkpoint_dir =  \"VAE\" + \"/checkpoint\"\n",
    "        Path(self.checkpoint_dir).mkdir(parents=True, exist_ok=True)\n",
    "        self.train_log_file = self.base_dir + \"/train_\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        self.val_log_file = self.base_dir + \"/val_\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        self.train_writer = tf.summary.FileWriter(self.train_log_file, self.sess.graph)\n",
    "        self.val_writer = tf.summary.FileWriter(self.val_log_file, self.sess.graph)\n",
    "\n",
    "         \n",
    "    def vae_arc1(self):\n",
    "        \n",
    "        f1 = fc(self.x, 128, scope='enc_fc1', activation_fn=tf.nn.relu)\n",
    "        f2 = fc(f1, 64, scope='enc_fc2', activation_fn=tf.nn.relu)\n",
    "        f3 = fc(f2, 32, scope='enc_fc3', activation_fn=tf.nn.relu)\n",
    "        self.z_mu = fc(f3, self.n_z, scope='enc_fc4_mu', \n",
    "                       activation_fn=None)\n",
    "        self.z_log_sigma_sq = fc(f3, self.n_z, scope='enc_fc4_sigma', \n",
    "                                 activation_fn=None)\n",
    "        eps = tf.random_normal(shape=tf.shape(self.z_log_sigma_sq),mean=0, stddev=1, dtype=tf.float32)\n",
    "        \n",
    "        self.z = self.z_mu + tf.sqrt(tf.exp(self.z_log_sigma_sq)) * eps\n",
    "\n",
    "        g1 = fc(self.z, 32, scope='dec_fc1', activation_fn=tf.nn.relu)\n",
    "        g2 = fc(g1, 64, scope='dec_fc2', activation_fn=tf.nn.relu)\n",
    "        g3 = fc(g2, 128, scope='dec_fc3', activation_fn=tf.nn.relu)\n",
    "        self.x_hat = fc(g3, input_dim, scope='dec_fc4', activation_fn=tf.sigmoid)\n",
    "        return \n",
    "    \n",
    "\n",
    "    \n",
    "    def myModel(self, model_name=\"vanillaVAE1\",*args):\n",
    "        modelsDic = {\n",
    "             \"vanillaVAE1\": self.vae_arc_all(*args),\n",
    "             \"vanillaVAE2\": self.vae_arc1(*args)\n",
    "            \n",
    "               }\n",
    "        self.model = modelsDic[model_name]\n",
    "        return self.model\n",
    "        \n",
    "        \n",
    "    @staticmethod\n",
    "    def vae_cell(x, l_name=0):\n",
    "        seq_name = \"sq_\" + str(l_name) + \"_\"\n",
    "      \n",
    "        conv1 = ld.conv_layer(x, 3, 2, 8, seq_name + \"encode_1\",activate=\"leaky_relu\")\n",
    "\n",
    "        conv2 = ld.conv_layer(conv1, 3, 1, 8, seq_name +\"encode_2\",activate=\"leaky_relu\") \n",
    "\n",
    "        conv3 = ld.conv_layer(conv2, 3, 2, 8, seq_name +\"encode_3\",activate=\"leaky_relu\")    \n",
    "\n",
    "        conv4 = tf.layers.Flatten()(conv3)\n",
    "        \n",
    "        conv3_shape = conv3.get_shape().as_list()\n",
    "      \n",
    "        z_mu = ld.fc_layer(conv4, hiddens=16, idx= seq_name + \"enc_fc4_m\")\n",
    "        z_log_sigma_sq = ld.fc_layer(conv4, hiddens=16, idx= seq_name + \"enc_fc4_m\"'enc_fc4_sigma')        \n",
    "        eps = tf.random_normal(shape=tf.shape(z_log_sigma_sq), mean=0, stddev=1, dtype=tf.float32)\n",
    "        z = z_mu + tf.sqrt(tf.exp(z_log_sigma_sq)) * eps\n",
    "      \n",
    "        z2 = ld.fc_layer(z, hiddens = conv3_shape[1] * conv3_shape[2] * conv3_shape[3], idx = seq_name + \"decode_fc1\")\n",
    "\n",
    "        z3 = tf.reshape(z2, [-1, conv3_shape[1], conv3_shape[2], conv3_shape[3]])\n",
    "\n",
    "        conv5 = ld.transpose_conv_layer(z3, 3, 2, 8, seq_name +\"decode_5\",activate=\"leaky_relu\") \n",
    "       \n",
    "        conv6 = ld.transpose_conv_layer(z3, 3, 1, 8, seq_name +\"decode_6\",activate=\"leaky_relu\") \n",
    "\n",
    "        x_hat = ld.transpose_conv_layer(conv6, 3, 2, 3, seq_name +\"decode_8\",activate=\"leaky_relu\")  # set activation to linear\n",
    "\n",
    "        return x_hat, z_mu,z_log_sigma_sq, z\n",
    "    \n",
    "    \n",
    "    \n",
    "    def vae_arc_all(self):\n",
    "        X = []\n",
    "        z_log_sigma_sq_all = []\n",
    "        z_mu_all = []\n",
    "        for i in range(20):\n",
    "            q, z_mu, z_log_sigma_sq, z = VariantionalAutoencoder.vae_cell(self.x[:,i,:,:,:], l_name=i)\n",
    "            X.append(q)\n",
    "            z_log_sigma_sq_all.append(z_log_sigma_sq)\n",
    "            z_mu_all.append(z_mu)\n",
    "        x_hat = tf.stack(X,axis = 1)\n",
    "        z_log_sigma_sq_all = tf.stack(z_log_sigma_sq_all,axis = 1)\n",
    "        z_mu_all = tf.stack(z_mu_all,axis = 1)\n",
    "        print (\"X_hat\",x_hat.shape)\n",
    "        print (\"zlog_sigma_sq_all\",z_log_sigma_sq_all.shape)\n",
    "        return x_hat,z_log_sigma_sq_all,z_mu_all\n",
    "        \n",
    "        \n",
    "    # Build the netowrk and the loss functions\n",
    "    def build(self):\n",
    "        tf.reset_default_graph()\n",
    "        self.train_iterator = make_dataset(type=\"train\")\n",
    "        self.val_iterator = make_dataset(type=\"val\")\n",
    "        self.test_iterator = make_dataset(type=\"test\")\n",
    "        self.x = tf.placeholder(tf.float32, [None,20,64,64,3])\n",
    "        self.global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "        self.increment_global_step = tf.assign_add(self.global_step,1,name = 'increment_global_step')\n",
    "        \n",
    "        #ARCHITECTURE\n",
    "        self.x_hat,self.z_log_sigma_sq,self.z_mu = self.myModel()\n",
    "        #self.x_hat,self.z_log_sigma_sq,self.z_mu = self.vae_arc_all()\n",
    "        # Loss\n",
    "        # Reconstruction loss\n",
    "        # Minimize the cross-entropy loss\n",
    "#         epsilon = 1e-10\n",
    "#         recon_loss = -tf.reduce_sum(\n",
    "#             self.x[:,1:,:,:,:] * tf.log(epsilon+self.x_hat[:,:-1,:,:,:]) + \n",
    "#             (1-self.x[:,1:,:,:,:]) * tf.log(epsilon+1-self.x_hat[:,:-1,:,:,:]), \n",
    "#             axis=1\n",
    "#         )\n",
    "\n",
    "#        self.recon_loss = tf.reduce_mean(recon_loss)\n",
    "        self.recon_loss = tf.reduce_mean(tf.square(self.x[:,1:,:,:,0]  - self.x_hat[:,:-1,:,:,0]))\n",
    "\n",
    "        # Latent loss\n",
    "        # KL divergence: measure the difference between two distributions\n",
    "        # Here we measure the divergence between \n",
    "        # the latent distribution and N(0, 1)\n",
    "        latent_loss = -0.5 * tf.reduce_sum(\n",
    "            1 + self.z_log_sigma_sq - tf.square(self.z_mu) - \n",
    "            tf.exp(self.z_log_sigma_sq), axis=1)\n",
    "        self.latent_loss = tf.reduce_mean(latent_loss)\n",
    "\n",
    "        self.total_loss = self.recon_loss + self.latent_loss\n",
    "        self.train_op = tf.train.AdamOptimizer(\n",
    "            learning_rate=self.learning_rate).minimize(self.total_loss,global_step=self.global_step)\n",
    "        \n",
    "        # Build a saver\n",
    "        self.saver = tf.train.Saver(tf.global_variables())\n",
    "        \n",
    "        self.losses = {\n",
    "            'recon_loss': self.recon_loss,\n",
    "            'latent_loss': self.latent_loss,\n",
    "            'total_loss': self.total_loss,\n",
    "        }     \n",
    "\n",
    "        \n",
    "        return\n",
    "\n",
    "    # Execute the forward and the backward pass\n",
    "    def run_single_step(selfï¼Œglobal_step):\n",
    "        try:\n",
    "            train_batch = self.sess.run(self.train_iterator.get_next())\n",
    "            print(\"Train_batch shape\", train_batch[\"images\"].shape)\n",
    "            x_hat, train_summary, _, train_losses = self.sess.run([self.x_hat, self.summary_op, self.train_op, self.losses], feed_dict={self.x: train_batch[\"images\"]})\n",
    "            self.train_writer.add_summary(train_summary, global_step)\n",
    "            print(\"x_hat.shape\", x_hat.shape)\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print(\"train out of range error\")\n",
    "        \n",
    "        try:\n",
    "            val_batch = self.sess.run(self.val_iterator.get_next())\n",
    "            val_summary, _, val_losses = self.sess.run([self.summary_op,self.train_op, self.losses], feed_dict={self.x: val_batch[\"images\"]})\n",
    "            self.val_writer.add_summary(val_summary, global_step)\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print(\"train out of range error\")\n",
    "        \n",
    "        return train_losses,val_losses\n",
    "\n",
    "    # x -> x_hat\n",
    "    def reconstructor(self, x):\n",
    "        x_hat = self.sess.run(self.x_hat, feed_dict={self.x: x})\n",
    "        return x_hat\n",
    "\n",
    "    # z -> x\n",
    "    def generator(self, z):\n",
    "        x_hat = self.sess.run(self.x_hat, feed_dict={self.z: z})\n",
    "        return x_hat\n",
    "    \n",
    "    \n",
    "    # x -> z\n",
    "    def transformer(self, x):\n",
    "        z = self.sess.run(self.z, feed_dict={self.x: x})\n",
    "        return z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(model_class, learning_rate=1e-4, \n",
    "            batch_size=64, num_epoch=100, n_z=16, log_step=5):\n",
    "    # Create a model    \n",
    "    model = model_class(learning_rate=learning_rate, batch_size=batch_size, n_z=n_z)\n",
    "\n",
    "    # Training loop    \n",
    "    for epoch in range(num_epoch):\n",
    "        start_time = time.time()\n",
    "        # Run an epoch\n",
    "        for iter in range(num_sample // batch_size): \n",
    "            step = epoch*(num_sample // batch_size) +  iter\n",
    "            train_losses,val_losses = model.run_single_step()\n",
    "            print (\"Train_loss: {}; Val_loss{}\".format(train_losses,val_losses))\n",
    "            checkpoint_path = os.path.join(model.checkpoint_dir, 'model.ckpt')\n",
    "            model.saver.save(model.sess, model.checkpoint_path, global_step =step)\n",
    "        end_time = time.time()\n",
    "\n",
    "    print('Done!')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard.notebook\n",
    "%tensorboard --logdir=./ --host localhost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer_and_checkpoint(model_class, learning_rate=1e-4, \n",
    "            batch_size=64, num_epoch=100, n_z=16, log_step=5):\n",
    "    \n",
    "    #restore the existing checkpoints   \n",
    "    model = model_class(learning_rate=learning_rate, batch_size=batch_size, n_z=n_z)\n",
    "    ckpt = tf.train.get_checkpoint_state(model.checkpoint_dir)\n",
    "    \n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "        #Extract from checkpoint filename\n",
    "        global_step = int(os.path.basename(ckpt.model_checkpoint_path).split('-')[1])\n",
    "        sess = tf.Session()\n",
    "        print(\"Restore from {}\".format(ckpt.model_checkpoint_path))\n",
    "        graph = tf.get_default_graph()\n",
    "        saver = tf.train.Saver(tf.global_variables())\n",
    "        #saver = tf.train.import_meta_graph(os.path.join(model.checkpoint_dir,'model.ckpt-{}.meta'.format(global_step)))\n",
    "        saver.restore(sess,tf.train.latest_checkpoint(model.checkpoint_dir))\n",
    "        loaded_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=tf.get_variable_scope().name)\n",
    "\n",
    "    else:\n",
    "\n",
    "        global_step = model.sess.run(model.global_step)\n",
    "    # Training loop    \n",
    "    for epoch in range(num_epoch):\n",
    "        model.sess.run(model.train_iterator.initializer)\n",
    "        model.sess.run(model.val_iterator.initializer)\n",
    "        start_time = time.time()\n",
    "        # Run an epoch\n",
    "        for iter in range(num_sample // batch_size):\n",
    "\n",
    "            print (\"global step\",model.global_step)\n",
    "            train_losses,val_losses = model.run_single_step(global_step)\n",
    "            print (\"Train_loss: {}; Val_loss{} for global step {}\".format(train_losses,val_losses,global_step))\n",
    "            checkpoint_path = os.path.join(model.checkpoint_dir, 'model_arc4.ckpt')\n",
    "            model.saver.save(model.sess,checkpoint_path, global_step = global_step)\n",
    "            global_step = global_step  +1\n",
    "        end_time = time.time()\n",
    "        \n",
    "        \n",
    "    print('Done!')\n",
    "    return model    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vae2 = trainer_and_checkpoint(VariantionalAutoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def model_prediction():\n",
    "model = VariantionalAutoencoder(learning_rate=1e-4, batch_size=64, n_z=16)\n",
    "ckpt = tf.train.get_checkpoint_state(model.checkpoint_dir)\n",
    "global_step = int(os.path.basename(ckpt.model_checkpoint_path).split('-')[1])\n",
    "#First let's load meta graph and restore weights\n",
    "sess = tf.Session()  \n",
    "saver = tf.train.Saver(tf.global_variables())\n",
    "saver.restore(sess,tf.train.latest_checkpoint(model.checkpoint_dir))\n",
    "#latest_checkpoints = saver.restore(sess,tf.train.latest_checkpoint('./'))\n",
    "graph = tf.get_default_graph()\n",
    "#op = sess.graph.get_operations()\n",
    "#graph.get_tensor_by_name(\"dec_fc4\")\n",
    "loaded_vars = tf.trainable_variables() \n",
    "#loaded_vars\n",
    "#op_to_restore = graph.get_tensor_by_name(\"dec_fc4/biases:0\")\n",
    "test_iterator = make_dataset(type=\"test\")\n",
    "sess.run(test_iterator.initializer)\n",
    "for i in range(1):\n",
    "    test_batch = sess.run(test_iterator.get_next())\n",
    "    # print(\"test_batch\",test_batch[\"images\"].shape)\n",
    "    #op_to_restore.eval(feed_dict={model.x: test_batch[\"images\"]})\n",
    "    predict_images,  recon_loss = sess.run([model.x_hat, model.recon_loss], feed_dict={model.x: test_batch[\"images\"]})\n",
    "    #plot real and predicted images\n",
    "    real_img = test_batch[\"images\"][0]\n",
    "    pred_img = predict_images[0]\n",
    "    #plt.figure(figsize=(8, 8))\n",
    "    #plt.imshow(real_img[0])\n",
    "    print(\"recon_loss\",recon_loss)\n",
    "    print(\"real_image\",real_img.shape)\n",
    "    print(\"predic image\", pred_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(real_img[0][:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(pred_img[0][:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18,6))\n",
    "    gs = gridspec.GridSpec(1, 10)\n",
    "    gs.update(wspace = 0., hspace = 0.)\n",
    "    ts = [0,5,9,10,12,14,16,18,19]\n",
    "    xlables = [round(i,2) for i in list(np.linspace(np.min(lon),np.max(lon),5))]\n",
    "    ylabels = [round(i,2) for i  in list(np.linspace(np.max(lat),np.min(lat),5))] \n",
    "    for t in range(len(ts)):\n",
    "        #if t==0 : ax1=plt.subplot(gs[t])\n",
    "        ax1 = plt.subplot(gs[t])\n",
    "        input_image = input_images_[ts[t], :, :, 0] * (321.46630859375 - 235.2141571044922) + 235.2141571044922\n",
    "        plt.imshow(input_image, cmap = 'jet', vmin=270, vmax=300)\n",
    "        ax1.title.set_text(\"t = \" + str(ts[t]+1))\n",
    "        plt.setp([ax1], xticks = [], xticklabels = [], yticks = [], yticklabels = [])\n",
    "        if t == 0:\n",
    "            plt.setp([ax1], xticks = list(np.linspace(0, 64, 3)), xticklabels = xlables, yticks = list(np.linspace(0, 64, 3)), yticklabels = ylabels)\n",
    "            plt.ylabel(\"Ground Truth\", fontsize=10)\n",
    "    plt.savefig(os.path.join(args.output_png_dir, \"Ground_Truth_Sample_\" + str(name) + \".jpg\"))\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(real_img[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(real_img).shape"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
